{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagaditya39/ESRGAN-ImageSR-Colab/blob/main/gan2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HflivmcCJQhl"
      },
      "outputs": [],
      "source": [
        "#utils.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "def read_image(img_path):\n",
        "    base=os.path.basename(img_path)\n",
        "    ext = os.path.splitext(base)[1]\n",
        "    assert ext in ['.png', '.jpg', '.jpeg', '.JPEG']\n",
        "    image = tf.io.read_file(img_path)\n",
        "    if ext == '.png':\n",
        "        image = tf.image.decode_png(image, channels=3)\n",
        "    else:\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "    return image\n",
        "\n",
        "def create_lr_hr_pair(img_path, scale):\n",
        "    image = read_image(img_path)\n",
        "    lr_height, lr_width = image.shape[0] // scale, image.shape[1] // scale\n",
        "    hr_height, hr_width = lr_height * scale, lr_width * scale\n",
        "    hr_image = image[:hr_height, :hr_width, :]\n",
        "    lr_shape = [lr_height, lr_width]\n",
        "    lr_image = tf.image.resize(hr_image, lr_shape, method=tf.image.ResizeMethod.BICUBIC)\n",
        "\n",
        "    return lr_image, hr_image\n",
        "\n",
        "def scale_image_0_1_range(image):\n",
        "    image = image / 255\n",
        "    red_max = tf.reduce_max(image, axis=None)\n",
        "    red_min = tf.reduce_min(image, axis=None)\n",
        "    if red_max > 1 or red_min < 0:\n",
        "        image = tf.clip_by_value(\n",
        "            image, 0, 1, name=None\n",
        "        )\n",
        "    return image\n",
        "\n",
        "\n",
        "def unscale_image_0_255_range(image):\n",
        "    image = image * 255\n",
        "    red_max = tf.reduce_max(image, axis=None)\n",
        "    red_min = tf.reduce_min(image, axis=None)\n",
        "    if red_max > 255 or red_min < 0:\n",
        "        image = tf.clip_by_value(\n",
        "            image, 0, 255, name=None\n",
        "        )\n",
        "    return image\n",
        "\n",
        "def tensor2img(tensor):\n",
        "    return (np.squeeze(tensor.numpy()).clip(0, 1) * 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "def save_image_grid(lr, hr, ref=None, save_path=None):\n",
        "    lr_title = \"lr: {}\".format(lr.shape)\n",
        "    hr_title = \"hr: {}\".format(hr.shape)\n",
        "    images = [lr, hr]\n",
        "    titles = [lr_title, hr_title]\n",
        "    if ref is not None:\n",
        "        ref_title = \"ref: {}\".format(ref.shape)\n",
        "        images += [ref]\n",
        "        titles += [ref_title]\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
        "    else:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "\n",
        "    for i, (img, title) in enumerate(zip(images, titles)):\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(title, fontsize = 20)\n",
        "        axes[i].axis('off')\n",
        "    # fig.savefig(save_path, bbox_inches = 'tight', pad_inches = 0.25)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quRvGoGgJJQI"
      },
      "outputs": [],
      "source": [
        "#metrics.py\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def calculate_psnr(img1, img2):\n",
        "    #img1 and img2 have range [0, 255]\n",
        "    #psnr = 20 * np.log10(255.0 / np.sqrt(np.mean((img1 - img2)**2)))\n",
        "    return tf.image.psnr(img1, img2, max_val=255)\n",
        "\n",
        "def calculate_ssim(hr, generated_hr):\n",
        "    #hr and generated_hr have range [0, 255]\n",
        "    return tf.image.ssim(hr, generated_hr, max_val=255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "WsyXyCB6I-v_",
        "outputId": "1373efe0-1d75-4717-ae84-18393bf50f24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-2e4effb2aace>:60: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels(labels)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAHJCAYAAACloWxtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWS0lEQVR4nO3deVxU5eIG8GeGRXYztxD3hNGUYGRTcb+4EympaYp6/aGSiYpW2IqammXh2nW/mlF2NQlxo+u9er1eyTU1ShTMBMUQRSOYQZaZ8/vDODoyA8wwCwPP9/PhI3POmfe88zIDj+/7nvdIBEEQQERERER6kVq6AkRERETWiCGKiIiIyAAMUUREREQGYIgiIiIiMgBDFBEREZEBGKKIiIiIDMAQRURERGQAhigiIiIiAzBEERERERnA1tIVICIyBQ8PD72f07NnT3zzzTcYPXo0vv/+e+zevRu9evXSq4zaPJeIrAtDFBHVS2PGjKm07c6dO/jPf/6jc3+nTp2qLPPTTz9FfHw85s2bh/nz5xulnkRkvRiiiKheWrVqVaVtqampYojStr/C6tWrUVxcbFBvFhE1HAxRRERPYHgioprgxHIioieMHj0aHh4eSE1NFbd5eHggPj4eABAfHw8PDw/xa+7cuTUu+/jx44iMjIRcLkf79u3x/PPP4//+7/9w9uxZY78MIjIx9kQREdXAmDFj8PPPP+PSpUt47rnn0LVrV3FfYGBgjcpYvHgxNm7cCKlUCh8fHwQGBiInJwffffcdDh8+jBUrVuDll1821UsgIiNjiCIiqoFVq1bh008/xaVLlzB06FC9J5Z/+eWX2LhxI9q3b4/NmzfjueeeE/edPHkSkydPxoIFCxAQEICOHTsau/pEZAIcziMiMjG1Wi0OBa5fv14jQAFAjx49MHfuXJSWliIhIcESVSQiAzBEERGZ2E8//YTc3FxxDpQ2PXv2BADOjSKyIhzOIyIysaysLADA9evXq73yLz8/3xxVIiIjYIgiIjIxtVoNAGjRogX69etX5bFPP/20OapEREbAEEVEZGKtWrUCADRp0qTKRT6JyLpwThQRUQ3Z2dkBAMrLy/V6nq+vL55++mlkZGTgypUrpqgaEVkAQxQRUQ25u7sDADIyMvR6np2dHebNmwdBEPB///d/OH36dKVjVCoV/ve//+HcuXNGqSsRmR6H84iIaqh///5wcnJCSkoKRo4ciQ4dOsDGxgYBAQHVLpL517/+FTk5OVi/fj1GjRoFmUyG9u3bw8HBAXl5ebh06RIKCgrw4Ycfws/Pz0yviIhqgyGKiKiGmjdvjoSEBKxcuRJpaWk4d+4c1Go1ysvLa7TS+LvvvoshQ4Zgx44dOH36NP7zn//Azs4OLVq0QM+ePRESEoJhw4aZ4ZUQkTFIBEEQLF0JIiIiImvDOVFEREREBmCIIiIiIjIAQxQRERGRARiiiIiIiAzAEEVERERkAIYoIiIiIgNwnSgTKS8vR0FBARo1agSplFmViIjIGqjVapSUlKBx48awta06JjFEmUhBQQGuX79u6WoQERGRAdq3b4+mTZtWeQxDlIk0atQIwMMfgqOjo1HLVqlUyMjIgJeXF2xsbIxaNj3CdjYPtrP5sK3Ng+1sHqZq5+LiYly/fl38O14VhigTqRjCc3R0hJOTk1HLVqlUAAAnJyd+QE2I7WwebGfzYVubB9vZPEzdzjWZisPJOkREREQGYIgiIiIiMgCH84iIyGjUajUa+n3tK4aZKv4l06hNO0skEqNcOc8QRUREtXb//n3cuXOHwQGAIAiwtbXF1atXIZFILF2dequ27ezg4IB27drVKkwxRBERUa3cv38feXl58PDwgIODQ4MPDoIgoLi4GI6Ojg2+LUypNu0sCAJycnKQl5eHZ555xuA6MEQREVGt3LlzBx4eHnBxcbF0VeoEQRAglUphY2PDEGVCtW3nli1b4vr162jZsqXBPydOLCciIoOp1WqoVCo4ODhYuipEerGzs4MgCLWaw8cQRUREBqv4A8QeF7JWDFFERERVGDhwIP773/9a5NwjRoxAamqqRc5dV8hkMvzyyy+WrobRcU4UERGRCR04cMDSVRCtXbsW165dw8qVKy1dlXrBYj1RpaWleOeddzBw4EDI5XKMGDEC+/bt03n86dOnERoaCh8fH7z00ku4fPlyrc6fkJCAPn36QC6XIzo6GgUFBVrrOHToUAQHB9fqXEREVD+Vl5dbugqiulSXhsJiIaq8vBwtWrTA559/jh9++AGLFi3CwoULcf78+UrH3r9/HzNnzkRkZCTOnDmD0NBQvPrqqygtLTXo3CdOnMDatWuxYcMGHD9+HFKpFHFxcZWO27RpU7V3cCYiIusiCAK2bduGIUOGIDAwENOmTUNubq64/8MPP0T//v0hl8sxatQonD59Wty3du1azJo1C2+99Rb8/f2xdetWLFiwAAsXLsSsWbMgl8sRFhaGK1euiM95fChx7dq1iI6Oxrvvvgs/Pz8MGjRIY6jv1q1bmDRpEuRyOcaPH4/4+HhERERofR03b96ETCZDYmIiBg4ciLCwsCrrf/ToUWzcuBH//Oc/IZfLMXDgQAAPOwzi4+MxcOBABAUFYf78+Vo7FoCHf49fffVVBAQEICAgAGPGjMG9e/cAAIWFhXj//ffRt29f+Pn54ZVXXsGDBw/E5549exZDhw6Fn58fXn/9dY2/4cePH0d4eDj8/f0xatQonD17VtwXERGBlStXYuLEifD19UVERATy8/OxfPly9O/fHyEhITh16pR4fFFRkViP4OBgLF68GCUlJVpfT21ZLEQ5OTlhzpw5aNOmDSQSCfz9/dG9e3etIerw4cNo27YtRo4cCXt7e0yZMgVqtVp841X3gXhSYmIiwsPD0bVrV7i4uCAmJgaHDx9GYWGheMyvv/6KgwcPYvr06cZ/8URE9ZggCHhQUm7yL0MnBCckJGDfvn3YunUrTpw4geeeew4xMTHi/q5duyIxMRFnzpzBiy++iDlz5qC4uFjcf/ToUfTu3RunT5/G5MmTAQD79+/HlClTcPbsWfTo0QMff/yxzvMfPXoU/fr1w+nTpzFhwgS8/fbb4r558+ahU6dOOHnyJN5//30kJiZW+3qOHz+O5ORk8Vhd9R8wYABmzJiBwYMH4/z58zhy5AgAID4+Hj///DN2796NY8eOwc7ODosXL9Z6rr///e8QBAH//e9/cfLkScTFxaFRo0YAgNjYWOTn5yMpKQmnT5/G/PnzNRay/O6777Bz507885//xIULF5CcnAwAuHz5Ml5//XW8/fbbOH36NGbPno3XXntNDGcAsG/fPixatAjff/89VCoVxo4dC09PT/z73//G+PHj8f7774vHvvXWWygtLcXBgwdx6NAhZGVl4W9/+1u17WiIOjMnSqlU4qeffsKkSZMq7cvIyECXLl3ExxKJBDKZDBkZGejfv7/GB6Jly5ZYt24dYmJisHPnTq3nyszMRN++fcXH7du3h52dHa5duwYfHx8AwMKFC/Hmm2/W+rJdlUpl1BV8/1CUIm7T98jNV8Dm29vgBTGmIwhAm2a26NaNXeSmxFtkmI8p2lqlUomXiVd8xX72P1y+ft9o59ClS/unsfy14BpdGVgRuARBwM6dOxEbGwsPDw8AEHuQcnJy0KpVK7zwwgvi8yZPnozPPvsMV69eRbdu3SAIArp27Yrhw4cDABo1agRBEPCXv/wFfn5+AICwsDDs3r1b45wV/wqCAF9fX4SEhAAAXnzxRXz44Ye4d+8eiouLceHCBWzevBn29vbo3LkzQkND8dNPP2kNjBXbZs2aBWdnZ3FbdfV/sk5ff/01vvnmGzz99NMAgNmzZ2Pw4MH46KOPYGNjo3FOW1tb3L9/H1lZWZDJZOjatSsAIC8vD//+97+RmpqKJk2aAAC6d++uca7p06fjqaeeAgD069cPP//8M1566SV8/fXXGD16tNh+/fv3R+fOnXHs2DGMHDkSgiBg5MiR6NixIwAgJCQEu3btQnh4OIqLixEaGooVK1agqKgIDx48wJEjR3Dy5EmxTaKiorBgwQLMnTu3UvsJglDp86DP56NOhCi1Wo0FCxbA29sbvXv3rrRfqVSicePGGttcXV2hUCgAQPxAtG7dGgAQHR0NX19f3Lp1C61atdJanpubm87ykpKS4OLigv79+2t0ERoiIyOjVs9/0r2icmTfLoRKDQBqo5ZNlaXfKMOZH36Eoz0vZDW1tLQ0S1ehwTB2W9va2qK4uBhSqfThHya1eX43qdUqKJXKGoeoBw8eQKlUIicnBzExMRrPk0qlyMrKwlNPPYUdO3YgKSkJd+/eBQAoFArk5uaiY8eOKCsrQ4sWLaBUKsXnqlQqNG3aVNwmkUhQXFws9l49fu6ysjI0adJEPLYiYOTn5+Pu3btwcXGBVCoV9zdt2hRqtVrjfBUqhsqeeuopjf3V1b+8vFw8viK8vfzyyxplSyQS3LhxAy1atNDY/sorr6CoqAizZs1CcXExhg8fjtdeew2//vorXFxc4ODgoLWuAODi4iLus7W1RX5+PpRKJbKzs3Hu3Dl8/fXX4rHl5eUICAiAUqmEWq1G48aNxefa2Njg6aef1ugdrGjD3NxcqFQq9O/fX2OfSqWqVC+1Wo2ysrJafR4sHqIEQUBcXBzy8vKwdetWrR8GJycnjaE24OGYZ0XKrPhAPN5tKJVKkZubi+TkZGzcuBEA4Ofnhy1btlRZXkFBAdasWYOEhASjvD4vLy84OTkZpawK3Z8vxpnzP8HLy8soN1CkytSCgDnxD+cwdOnSBU+5Olq4RvWXSqVCWloavL29K/2vl4zLFG2tUqlw9epVODo6imV+HN0XJaWm71lsZF/zlaolEgkcHBzg5OQEd3d3LFy4EEFBQZWOO3v2LLZt24YdO3bA09MTUqkUgYGBaNSoEZycnGBnZwc7OzuN3+s2NjYa2ypGMCpuR/L4ue3s7GBrayseW9FmDg4OaNu2LYqKiqBWq8XV3/Pz8yGVSrX+Hak4j7OzszikVl397e3tNc7v4OAABwcHJCUliR0RVXFycsLbb7+Nt99+G9nZ2Zg2bRq8vLzQr18/FBUVoaSkROyJepKjo6N4Xjs7O9jY2MDJyQmtW7eGr68voqOjtT5PKpXC3t5efK69vT2kUikcHR1RXFys0d4dOnSAra0tUlNTYW9vX+VrUalUsLOzQ5cuXTQ+D0qlssYdIBYNUYIgYNGiRUhPT8f27dvFUPQkLy8v/OMf/9B43pUrVzB+/HgAgLu7OxYtWqT1A9G9e3dERUVpbPP09ER6ero4CS8rKwulpaXo2LEjLl26hLy8PIwZMwYAUFZWhsLCQgQHB2P79u3w9PTU6zXa2NgY/Q/DU26OaN7YDu3cG/OPjomo1I+6zk3xM6TK2M7mY+y2rggKFYFGIpHA0aFu/Qfv8bqNHz8eq1atwscff4y2bduioKAAJ06cwPDhw6FUKmFra4smTZpApVJh06ZNKCoqEp/7eDnayn7y3yefU9WxHh4e8PX1xerVq/Hmm2/i2rVr2L9/Pzp06KA1LGort7r6N2vWDMePH9e4ZcrLL7+M5cuXIy4uDi1atEB+fj7Onz8vDjk+7ujRo2jfvj3atWsHV1dXMQy1aNECAwYMwMKFC7Fw4UI0btwYFy9eRLdu3TTCzJPtJpFI8PLLL2PGjBno1asXunfvjtLSUly4cAHt27fHM888o7PNtbVh8+bN0a9fPyxbtgzz5s2Dm5sbcnNzK03jebyMJz8P+nw2LPouX7x4MS5evIitW7dWec+lQYMGISsrC3v37kVpaSk+//xzAECvXr0AAOPHj8fKlSuRnZ0NACgoKMDBgwd1lhceHo7ExERcunQJCoUCq1atwqBBg+Dq6gq5XI6jR48iKSkJSUlJWLJkCZ566ikkJSWhQ4cORnz1VJc9/uuqFovZElEdFBERgREjRmDGjBno3r07XnzxRfzvf/8DAPTu3Rv9+vXDsGHDMHDgQNja2sLd3d1sdfvkk09w5coVBAUFYeHChXjhhReq7VF5XHX1Hzp0KGxtbREUFCSGpNdffx2dO3fGhAkTIJfLMW7cOJ1DXFlZWYiMjET37t0RFhaG4OBgvPjiiwCAjz76CC4uLggLC0NQUBDi4+OhrsHQbteuXfHRRx9hxYoVCAoKwoABA7Bt27YaPVebjz76CHZ2dhg5ciT8/Pzwf//3f7h+/bpBZVVHItRmvfNayMnJwcCBA8WuxQozZsxAVFQU5HI5Nm/eDH9/fwDAqVOn8MEHHyA7Oxuenp5YsmSJONlcrVbjyy+/xFdffYXbt2/Dzc0NvXr1wrJly3SePyEhARs2bIBCoUBwcDCWLl1aad5VxXnnzZuHEydO6PX6lEol0tPT0aVLF6MP56lUKly4cAG+vr78n7uJqNUCXnzj4ZUjO+IGo4kbh/NMhe9n8zFFW6tUKmRkZMDLy4s/vz8JggClUgknJ6da3w5nyZIlKC4uxtKlS41Uu/qjtu2s672rz99viw3neXh4aKyj8aQnlzoICgrC/v37tR4rlUoRERGhcy0NbSZOnIiJEydWe1xQUJDeAYqsH696JCJL+Omnn+Di4oJ27drh3LlzSEpKwqeffmrpapEOFp9YTlQXPf6/Ggt11hJRA5Sfn4/o6Gjcu3cPzZo1w2uvvYZ+/fpZulqkA0MUUTUYoYjIXPr164ejR49auhpUQ3Xr8gkiIiIiK8EQRaSDOKLHrigiItKCIYqoGgJTFJFOFfMHOXeQrE3Fe7Y2V1ByThSRDhKwE4qoOlKpFA4ODsjJyUHLli1hZ2dn6SpZnCAIUKvVUKlUtV7igHSrTTsLgoD8/HzY2dnV6s4fDFFE1eB/sImq1q5dO+Tl5eH69evskcLDP9BlZWWws7NjiDKh2raznZ0d2rZtW6s6MEQR6SKRMEER1YBUKsUzzzyDli1bPrwBcQP/3FTco/DJe7KRcdWmnSUSiVHuPcsQRaSD+P+ahv33gKjGHr+fGfF+kOZiyXbmxHKianBiORERacMQRaQD/0NNRERVYYgi0qni0m0LV4OIiOokhiiiajBDERGRNgxRRDpwOI+IiKrCEEWkA6/OIyKiqjBEEVWDV+cREZE2DFFEunA4j4iIqsAQRaSDhFfnERFRFRiiiIiIiAzAEEWkA6/OIyKiqjBEEVWjod9MlYiItGOIIqoGIxQREWnDEEWkA+9GT0REVWGIIqoOu6KIiEgLhigiHdgRRUREVWGIIqoGJ5YTEZE2DFFE1WCEIiIibRiiiHTgxHIiIqoKQxSRDmKEYlcUERFpwRBFVA1mKCIi0oYhikgHjuYREVFVGKKIqsGr84iISBuGKCIiIiIDMEQR6cCr84iIqCoMUUQ6VEQojuYREZE2FgtRCQkJCA8PR7du3RATE6PzuOTkZMjlcvHL19cXMpkM//znP2t17j59+kAulyM6OhoFBQWVjiktLcXQoUMRHBxs8HmofhB4fR4REWlhsRDVokULzJw5E2PHjq3yuLCwMJw/f178Wr16NVxcXNCnTx+DznvixAmsXbsWGzZswPHjxyGVShEXF1fpuE2bNqFp06YGnYPqCY7mERFRFSwWogYPHoyQkBA0adJEr+ft2bMHw4cPh6OjI4CHV05t27YNQ4YMQWBgIKZNm4bc3Fydz09MTER4eDi6du0KFxcXxMTE4PDhwygsLBSP+fXXX3Hw4EFMnz7dsBdH9YLkzxTF4TwiItLG1tIV0Mf9+/dx5MgRfPHFF+K2hIQE7Nu3D1u3bkXLli2xbt06xMTEYOfOnVrLyMzMRN++fcXH7du3h52dHa5duwYfHx8AwMKFC/Hmm2/CwcGh1nVWqVRQqVS1LufJMh//l0zlYXpSq9VsaxPi+9l82NbmwXY2D1O1sz7lWVWI2rdvH9q2bQu5XC5u27lzJ2JjY9G6dWsAQHR0NHx9fXHr1i20atWqUhlKpRJubm4a21xdXaFQKAAASUlJcHFxQf/+/XHq1Kla1zkjI6PWZeiSlpZmsrIJKC8vB/DwZ/jHHXsL16b+4/vZfNjW5sF2Ng9LtrNVhaiKobjH5eTkICYmBlLpo5FJqVSK3NxcJCcnY+PGjQAAPz8/bNmyBU5OThpDdwBQVFQEZ2dnFBQUYM2aNUhISDBanb28vODk5GS08oCHKTktLQ3e3t6wsbExatn0iO2+O8CDEnh6euLZ1voNO1PN8f1sPmxr82A7m4ep2lmpVNa4A8RqQtSlS5eQmZmJF198UWO7u7s7Fi1ahKCgoErP6d69O6KiojS2eXp6Ij09HWFhYQCArKwslJaWomPHjrh06RLy8vIwZswYAEBZWRkKCwsRHByM7du3w9PTU+9629jYmOxDZMqy6dG8cqmU7WwOfD+bD9vaPNjO5mHsdtanLItNLC8vL0dJSQnKy8uhVqtRUlKCsrIynccnJiaiT58+aN68ucb28ePHY+XKlcjOzgYAFBQU4ODBgzrLCQ8PR2JiIi5dugSFQoFVq1Zh0KBBcHV1hVwux9GjR5GUlISkpCQsWbIETz31FJKSktChQwfjvHCyGhVrbXKJAyIi0sZiPVHr16/HunXrxMcpKSkYNWoUli9fDrlcjs2bN8Pf3x/AwzWb9u3bh6VLl1YqJyIiAlKpFDNmzMDt27fh5uaGXr16Yfjw4VrPGxwcjOjoaEyfPh0KhQLBwcFiufb29hohrXHjxpBKpZWCGzUwzFBERKSFxUJUdHQ0oqOjte47f/68xmN7e3udk7ylUikiIiIQERFR43NPnDgREydOrPa4oKAgnDhxosblUv3C274QEVFVeNsXompwnSgiItKGIYqoGpwTRURE2jBEEenA0TwiIqoKQxSRDhW3fWFHFBERacMQRVQNZigiItKGIYpIFw7nERFRFRiiiHSoyFACL88jIiItGKKIiIiIDMAQRaQDF9skIqKqMEQRVYOjeUREpA1DFBEREZEBGKKIdJBwmSgiIqoCQxRRdTieR0REWjBEEenAaeVERFQVhigiHSquzmM/FBERacMQRVQNjuYREZE2DFFEREREBmCIItLh0dV57IoiIqLKGKKIqsMMRUREWjBEEenA274QEVFVGKKIqsGJ5UREpA1DFFE1OCeKiIi0YYgi0oGjeUREVBWGKCIdJODN84iISDeGKCIiIiIDMEQR6cKOKCIiqgJDFFE1eHUeERFpwxBFpAPnlRMRUVUYooh0eHR1HruiiIioMoYoompwOI+IiLRhiCLSiQN6RESkG0MUkQ4SXp1HRERVYIgiqg7H84iISAuGKCIdOJhHRERVYYgi0uXP8Tz2QxERkTYWC1EJCQkIDw9Ht27dEBMTU+WxMpkMvr6+kMvlkMvliIyMrNW5U1JSEBISAh8fH0yePBk5OTlaj4uIiIBMJkNJSUmtzkfWjaN5RESkja2lTtyiRQvMnDkTqampuH//frXH79mzB88++2ytz/vLL7/grbfewtq1a+Hv74/4+HjMnTsXu3fv1jju22+/hVqtrvX5yHpxOI+IiKpisZ6owYMHIyQkBE2aNKl1WXv37kVoaCj8/f3xyiuvIDMzU+exycnJ6NOnD3r37g0HBwfMnj0bly9f1njO/fv3sX79erz55pu1rhtZL/HqPHZFERGRFhbridLX5MmToVar0a1bN7zxxhvw9PQEABw5cgSrV6/G+vXr0alTJ+zevRtRUVE4dOgQ7O3tK5WTkZEBb29v8bGLiwvatm2LzMxMscyPP/4YkydPRtOmTWtdb5VKBZVKVetynizz8X/JNCqyk1qtZlubEN/P5sO2Ng+2s3mYqp31Kc8qQtQXX3wBX19flJaWYvPmzZg6dSoOHToEFxcX7Ny5E5GRkZDJZACAcePGYcuWLbh48SICAgIqlaVUKuHm5qaxzdXVFQqFAgBw5swZZGRkYOnSpbh161at656RkVHrMnRJS0szWdkEFBcrAQDXr1+HfdltC9em/uP72XzY1ubBdjYPS7azVYSowMBAAIC9vT1iYmKQnJyMH374AX379kVOTg5WrFiB+Ph48fiysjLcvn0bycnJiIuLAwC0atUKBw4cgJOTEwoLCzXKLyoqgrOzM8rKyrBo0SIsW7YMUqlxRjq9vLzg5ORklLIqqFQqpKWlwdvbGzY2NkYtmx5x+u9x4F4B2rVrD99u7pauTr3F97P5sK3Ng+1sHqZqZ6VSWeMOEKsIUU+SSCTiPBV3d3dERkYiPDxc67FhYWEaj728vJCeni4+VigUyM7OhqenJ27fvo1r167h1VdfBfCoS2/gwIH48MMP0bdvX73ramNjY7IPkSnLpofvMwCQSqVsZzPg+9l82NbmwXY2D2O3sz5lWSxElZeXQ6VSoby8HGq1GiUlJZBKpbCzs9M4LjMzE6WlpZDJZCgrK8OWLVtQUlICuVwOABg/fjw++eQTPPfcc5DJZFAqlTh16hQCAwPh4uJS6bxhYWEYPXo0UlNT4efnh7Vr10Imk8HT0xMqlQrHjh0Tj/3tt98wZswY7Nq1C82bNzdtg1Cdw9u+EBFRVSwWotavX49169aJj1NSUjBq1CgsX74ccrkcmzdvhr+/P/Lz87Fw4ULk5uaiUaNG6NatG7Zu3SrOawoJCcGDBw8QGxuLmzdvwtHREX5+fuIQ4JOeffZZLFu2DO+99x7u3r0LHx8frFq1CsDD9Pl4WKpYH6pZs2ZaJ6lTA8Gr84iISAuLhajo6GhER0dr3Xf+/Hnx+x49eiAlJaXKskJDQxEaGlrjcw8bNgzDhg2r9rjWrVvjypUrNS6X6heuE0VERFXhbV+IdOFtX4iIqAoMUUTV4GgeERFpwxBFpAOH84iIqCoMUUQ6SMQUxa4oIiKqjCGKqBocziMiIm0Yooh04oAeERHpxhBFpAMX2yQioqowRBFVh+N5RESkBUMUkQ4czCMioqowRBHpwuE8IiKqAkMUERERkQEYooh0kPzZFcUpUUREpA1DFFF1GKKIiEgLhigiHSScWU5ERFVgiCLSRZxYzq4oIiKqjCGKqBqcE0VERNowRBHpIOFKUUREVAWGKCIdeNsXIiKqCkMUUXU4nkdERFowRBEREREZgCGKSAfJn+N57IciIiJtGKKIqsHRPCIi0oYhikgHXptHRERVYYgi0oErlhMRUVUYooiqIXA8j4iItGCIIiIiIjIAQxSRDrw6j4iIqsIQRURERGQAg0PU7du3ceHCBSNWhahuEeeVsyuKiIi00DtE3bt3D1OnTkW/fv0wZcoUAMDBgwfxwQcfGLtuRHWCwBRFRERa6B2ili5diubNm+PYsWOws7MDAAQFBeF///uf0StHZFFc4oCIiKpgq+8TTp48iX/9619wdHQUJ942bdoU+fn5Rq8ckSVJ/kxRXOGAiIi00bsnysbGBlKp5tOKiorg6upqtEoR1SkMUUREpIXeISogIABr1qzR2LZ161YEBQUZrVJEdQFXLCcioqroPZz35ptvYsqUKdi/fz8UCgUGDx6M8vJyfP3116aoH5Hl/BmiOLGciIi00TtEtWzZEnv37sWxY8dw/fp1NG/eHIMGDYKzs7Ne5SQkJCAxMREZGRkYNGgQVq5cqfW4GzduYN68ecjKyoJarUanTp3w+uuvw9/fX9+qa5x748aNKCoqQu/evbFkyRI0btxY45jS0lKEhYWhsLAQJ06cMPhcZP04J4qIiLTRezhv//79sLe3x6BBgzBt2jSMHDkSzs7OOHDggF7ltGjRAjNnzsTYsWOrPK5Jkyb45JNPcPLkSZw5cwZTp07Fq6++itLSUn2rDgA4ceIE1q5diw0bNuD48eOQSqWIi4urdNymTZvQtGlTg85B9QNH84iIqCp6h6j3339f6/ZFixbpVc7gwYMREhKCJk2aVHmci4sL2rVrB6lUCkEQIJVK8ccff+D+/fsAHt4cdtu2bRgyZAgCAwMxbdo05Obm6iwvMTER4eHh6Nq1K1xcXBATE4PDhw+jsLBQPObXX3/FwYMHMX36dL1eE9UvEk6KIiKiKug9nKftjva///67yf/gDBgwAHl5eSgvL0d4eDhatmwJ4OHQ3L59+7B161a0bNkS69atQ0xMDHbu3Km1nMzMTPTt21d83L59e9jZ2eHatWvw8fEBACxcuBBvvvkmHBwcal1vlUoFlUpV63KeLPPxf8k0Kt7rKrWabW1CfD+bD9vaPNjO5mGqdtanvBqHqH79+kEikaCkpAT9+/fX2Hf//n385S9/qfFJDXH06FGUlJTgwIEDGoFt586diI2NRevWrQEA0dHR8PX1xa1bt9CqVatK5SiVSri5uWlsc3V1hUKhAAAkJSXBxcUF/fv3x6lTp2pd74yMjFqXoUtaWprJyibgjz/+AADk5OTgwoUCC9em/uP72XzY1ubBdjYPS7ZzjUPU3LlzIQgCFi5ciDlz5ojbJRIJmjdvjh49epikgo9r1KgRwsPDMXjwYHTp0gWdO3dGTk4OYmJiNNaukkqlyM3NRXJyMjZu3AgA8PPzw5YtW+Dk5KQxdAc8XOfK2dkZBQUFWLNmDRISEoxWZy8vLzg5ORmtPOBhSk5LS4O3tzdsbGyMWjY9kvLjGeBGMVq1agVf346Wrk69xfez+bCtzYPtbB6mamelUlnjDpAah6hRo0YBANq2bVurK+OMoaysDDdu3EDnzp3h7u6ORYsWaV2nqnv37oiKitLY5unpifT0dISFhQEAsrKyUFpaio4dO+LSpUvIy8vDmDFjxPMUFhYiODgY27dvh6enp951tbGxMdmHyJRl06M5URKJlO1sBnw/mw/b2jzYzuZh7HbWpyy9J5ZXBCilUokbN25ofOmjvLwcJSUlKC8vh1qtRklJCcrKyiod9/333+PHH39EeXk5iouLsW7dOvz+++94/vnnAQDjx4/HypUrkZ2dDQAoKCjAwYMHdZ43PDwciYmJuHTpEhQKBVatWoVBgwbB1dUVcrkcR48eRVJSEpKSkrBkyRI89dRTSEpKQocOHfR6fWT9JLw+j4iIqqD3xPKbN2/i9ddfx8WLFyvtS09Pr3E569evx7p168THKSkpGDVqFJYvXw65XI7NmzfD398fCoUCS5Yswa1bt2Bvbw+ZTIbNmzeLE8sjIiIglUoxY8YM3L59G25ubujVqxeGDx+u9bzBwcGIjo7G9OnToVAoEBwcjKVLlwIA7O3t0bx5c/HYxo0bQyqVamwjIiIiAgwIUUuXLkWTJk2wZ88eREREICEhAatWrcKwYcP0Kic6OhrR0dFa950/f178PiQkBCEhITrLkUqliIiIQERERI3PPXHiREycOLHa44KCgrjQZkPGjigiIqqC3sN5Fy5cwIcffojnnnsOEokEXbp0weLFi7F9+3YTVI/IcioylLZlPYiIiPQOUSqVCk899RQAwMHBAcXFxWjZsqU4J4movmGEIiIibfQezmvdujWuXLkCmUyGTp064euvv4arq6sYrIjqC65YTkREVdE7RE2fPh137tyBTCbDzJkzERUVhdLSUixZssQU9SOyGDFCsSuKiIi00CtECYKAgIAA8X53gYGBOHXqFMrKyoy+oCRRXSEwRRERkRZ6zYkSBAEDBgzQuK+MnZ0dAxTVTxzNIyKiKugVoqRSKdzd3aFUKk1VH6I649HVeRatBhER1VF6X503Z84cvPvuu8jKyhJXG6/4IqqXGKKIiEgLvSeWz5s3DwDwr3/9q9I+fVYsJ6rreHUeERFVRe8QtWPHDlPUg6ju+TNDsSOKiIi00TtEBQYGmqIeRHUWVywnIiJt9J4TRdRQcDCPiIiqwhBFpAPnRBERUVUYooiIiIgMwBBFVA1OiSIiIm0Yooiqwdu+EBGRNnpfnde5c2etc0Xs7e3RqlUrhIWFITIyEnZ2dkapIJGlcEoUERFVRe8QtWDBAuzcuROTJk2Ch4cHcnJy8MUXX2D06NGwtbXFtm3b8ODBA8TExJiivkRmI+FCUUREVAW9Q9T+/fuxYcMGdOjQQdzWq1cvvPHGG/jmm2/g5+eHuXPnMkRRvcEMRURE2ug9J+rXX39FmzZtNLa1bt0a165dAwB4e3vj3r17xqkdkSVxOI+IiKqgd4jq0KEDNm/erLHt73//u9gzlZubCxcXF+PUjsiCKjIUr84jIiJt9B7Oe//99zFt2jR8+eWXcHd3x2+//YaysjIxWP3666+IiooyekWJLIVX5xERkTZ6h6jnn38e//rXv3DkyBHk5eWhZcuWGDBgAFxdXQEAPXv2RM+ePY1eUSJz49V5RERUFb1DFAC4urrixRdfNHZdiOoYXp1HRES66R2i1Go19u7dix9//BEKhUJj38cff2y0ihHVFcxQRESkjd4hauHChfjuu+/Qo0cPODk5maJORHUCh/OIiKgqeoeo7777Dv/4xz/Qvn17E1SHqO54dHUe+6KIiKgyvZc4sLOzQ+vWrU1RF6K6iRmKiIi00DtEjRs3DgkJCaaoC1Gdou0ekURERBX0Hs5LTU3Fjz/+iC+//BItWrTQ2Pfll18arWJEdQU7ooiISBu9Q1SvXr3Qq1cvU9SFqG5hRxQREVVB7xA1a9YsU9SDqM7hxHIiIqpKjUKUIAji/BC1Wq3zOKlU7ylWRERERFapRiHKz88PP/zwAwDgueee0znhNj093Xg1I7IwzisnIqKq1ChEbdq0Sfx+x44dRjlxQkICEhMTkZGRgUGDBmHlypU6jz19+jQWL16MGzduoFOnTli6dCk6d+5cq3Nv3LgRRUVF6N27N5YsWYLGjRtrHFNaWoqwsDAUFhbixIkTBp+LrNnDFMXRPCIi0qZG42/+/v7i94GBgTq/9NGiRQvMnDkTY8eOrfK4+/fvY+bMmYiMjMSZM2cQGhqKV199FaWlpXqdr8KJEyewdu1abNiwAcePH4dUKkVcXFyl4zZt2oSmTZsadA6qX5ihiIhIG4MmMd24cQOHDh3CN998o/Glj8GDByMkJARNmjSp8rjDhw+jbdu2GDlyJOzt7TFlyhSo1WqkpqYCeDhfa9u2bRgyZAgCAwMxbdo05Obm6iwvMTER4eHh6Nq1K1xcXBATE4PDhw+jsLBQPObXX3/FwYMHMX36dL1eE9UvHM4jIqKq6H113s6dO/HBBx+gcePGcHR0FLdLJBKMHj3aqJUDgIyMDHTp0kXjPDKZDBkZGejfvz8SEhKwb98+bN26FS1btsS6desQExODnTt3ai0vMzMTffv2FR+3b98ednZ2uHbtGnx8fAA8vD/gm2++CQcHh1rXX6VSQaVS1bqcJ8t8/F8yjYqr8o79cBMZ2fctXJt6TBAAVTE6eZXAxamRpWtTr/F3h3mwnc3DVO2sT3l6h6hNmzZh1apVGDx4sL5PNYhSqaw0X8nV1RUKhQLAw1AXGxsr3oomOjoavr6+uHXrFlq1aqW1PDc3N53lJSUlwcXFBf3798epU6dqXf+MjIxal6FLWlqaycomoETxBwAg734x8u4XW7g29V/yv3/Ac20cqz+Qao2/O8yD7WwelmxnvUNUYWGh2QIUADg5OWkMtQFAUVERnJ2dAQA5OTmIiYnRWF5BKpUiNzcXycnJ2LhxI4CHVxhu2bKlyvIKCgqwZs0ao97WxsvLC05OTkYrD3iYktPS0uDt7Q0bGxujlk2PyDqXopnbObR09+DyHSb0zZFM3MxTwMOjNXx921i6OvUaf3eYB9vZPEzVzkqlssYdIHqHqH79+uH06dN6TyQ3lJeXF/7xj3+IjwVBwJUrVzB+/HgAgLu7OxYtWoSgoKBKz+3evTuioqI0tnl6eiI9PR1hYWEAgKysLJSWlqJjx464dOkS8vLyMGbMGABAWVkZCgsLERwcjO3bt8PT01Pv+tvY2JjsQ2TKsglwdLBHlzaO8PVty3Y2oSNnb+JmngKQSNnOZsLfHebBdjYPY7ezPmXpHaKefvppvPbaaxg8eHCle+fNmTOnxuWUl5dDpVKhvLwcarUaJSUlkEqlsLOz0zhu0KBB+Pjjj7F3714MGzYMX331FQCIt54ZP348Vq5ciY8//hht27ZFQUEBTpw4geHDh2s9b3h4OObNm4cXXngB7dq1w6pVqzBo0CC4urpCLpfj6NGj4rHnz59HXFwckpKSqp0AT0SGkTxaGt6i9SAi0pfeIery5cvo3LkzsrOzkZ2dLW7X947369evx7p168THKSkpGDVqFJYvXw65XI7NmzfD398fTZo0wWeffYYPPvgA7733Hjw9PbF+/XrY29sDACIiIiCVSjFjxgzcvn0bbm5u6NWrl84QFRwcjOjoaEyfPh0KhQLBwcFYunQpAMDe3h7NmzcXj23cuDGkUqnGNiIyDUYoIrI2eoUolUqFN954A507dxZDjKGio6MRHR2tdd/58+c1HgcFBWH//v1aj5VKpYiIiEBERESNzz1x4kRMnDix2uOCgoK40CaRiVX8B4wdUURkbfSaLWtjY4NJkyZVGnIjIjKU9M9ObN7omYisjd6XHLVr1w55eXmmqAsRNWCMUERkbfSeExUREYGYmBjMmjULHh6al363acPLk4lIP+J8SqYoIrIyeoeod999FwAwderUx+YyCJBIJEhPTzdu7Yio3qvIUGoO5xGRldE7RP373/82RT2IqIGSgD1RRGSd9A5RHh4epqgHETVQj0bzmKKIyLroHaIA4N69e/jxxx+Rn5+vcUWNKW5ATET1nHh1nmWrQUSkL71D1MmTJzFr1ixIJBIoFAo4OztDqVTimWeeYYgiIr1JuU4UEVkpvZc4iI+Px5QpU3DmzBk4OzvjzJkz+Otf/4qpU6eaon5E1EBwOI+IrI3eIerXX3/FjBkzADxaHG/mzJnYunWrcWtGRA2ChMN5RGSl9A5Rtra2YnhydXXFvXv3YGdnh/v37xu9ckRU/z2+VAoRkTXRe06UTCbDuXPn0LNnT8jlcnzwwQdwcnJChw4dTFE/IqrnKm5dzghFRNZG756od955B82aNQMAvPHGG/jjjz9w9epVLFy40Nh1I6IGgCuWE5G10rsnytPTU/ze3d2dc6GIqFYqeqK4YjkRWRuD1om6ceMGDhw4gNu3byMuLg5ZWVkoLy/Hs88+a+z6EVE9J+F4HhFZKb2H877//nuEhYXh9OnTSEpKAgDcuXMHH330kbHrRkQNgDix3ML1ICLSl94h6pNPPsGKFSvw97//Hba2DzuyunXrhkuXLhm9ckTUAIhLHDBGEZF10TtEZWVlISQkBMCj/0E6ODigpKTEuDUjogaBK5YTkbXSO0S1aNECWVlZGtt++eUXPPPMM0arFBE1PFyxnIisjd4havTo0Zg7dy5OnDgBtVqNs2fP4p133sHYsWNNUT8iquc4sZyIrJXeV+dNmTIFCoUCc+bMQVFRESIjIzFu3DhMnDjRFPUjonquYlqAmiGKiKyM3iFKKpUiOjoa0dHRyM/Ph6urK+zs7HDy5En07NnTFHUkonrsUUcUUxQRWRe9h/Me17RpU9jb26OsrAxTp041Vp2IqAHhcB4RWatahajH8fJkIjIM14kiIutktBAl3v+KiEgP0op1ojgpioisjNFCFBGRIbhiORFZqxpPLF+9erXOfWq12iiVIaIGiCuWE5GVqnGIOnv2bJX7/f39a10ZImp4xOE8ZigisjI1DlFffPGFKetBRA0Wh/OIyDpxThQRWdSjJQ4Yo4jIujBEEZFFcZkoIrJWDFFEZFHi1XnsiSIiK8MQRUQWJeHEciKyUgxRRGRhnFhORNaJIYqILIorlhORtarxEgfGJpfLNR6XlJSgb9++2LBhg9bjZTIZHB0dxfkTfn5+2LJli8HnT0lJwSeffII7d+7A19cXy5Ytg4eHBwAgMTER77zzDhwcHMTjFy1ahLCwMIPPR0Q6VIQoy9aCiEhvFgtR58+fF79XqVTo378/hg0bVuVz9uzZg2effbbW5/7ll1/w1ltvYe3atfD390d8fDzmzp2L3bt3i8d4e3tj165dtT4XEVXt0cRyC1eEiEhPdWI47/jx41AqlRgyZIjBZezduxehoaHw9/fHK6+8gszMTJ3HJicno0+fPujduzccHBwwe/ZsXL58ucrnEJFpPLp1OVMUEVkXi/VEPS4xMREjRozQGD7TZvLkyVCr1ejWrRveeOMNeHp6AgCOHDmC1atXY/369ejUqRN2796NqKgoHDp0CPb29pXKycjIgLe3t/jYxcUFbdu2RWZmpljmlStX0KNHD7i6umLw4MGIjo6utn7aqFQqqFQqvZ9XXZmP/0umwXY2l4fhSaVSs61NjO9p82A7m4ep2lmf8iweou7du4cjR47gyy+/rPK4L774Ar6+vigtLcXmzZsxdepUHDp0CC4uLti5cyciIyMhk8kAAOPGjcOWLVtw8eJFBAQEVCpLqVTCzc1NY5urqysUCgUAICAgAPv374eHhweuX7+O2NhYrFixAu+9957ery8jI0Pv59RUWlqaycqmR9jOpnXnTgEA4O7dfFy4cMGylWkg+J42D7azeViynS0eovbt24d27drBx8enyuMCAwMBAPb29oiJiUFycjJ++OEH9O3bFzk5OVixYgXi4+PF48vKynD79m0kJycjLi4OANCqVSscOHAATk5OKCws1Ci/qKgIzs7OAIA2bdqI2zt27Ij58+dj/vz5BoUoLy8vODk56f28qqhUKqSlpcHb2xs2NjZGLZseYTubR9pv6cDPhWjatCl8fb2rfwIZjO9p82A7m4ep2lmpVNa4A8TiISoxMRHh4eF6P08ikYgrHLu7uyMyMlJnOU9eVefl5YX09HTxsUKhQHZ2tjiU9ySpVGrwaso2NjYm+xCZsmx6hO1sWjbSP6dmSsB2NhO+p82D7Wwexm5nfcqy6MTyn3/+GVevXsWLL75Y5XGZmZn4+eefUV5ejuLiYqxduxYlJSXiMgnjx4/Hpk2bcPnyZQiCAIVCgSNHjqCoqEhreWFhYTh+/DhSU1NRUlKCtWvXQiaTiSHq2LFjyMvLAwDcuHEDn376KUJCQoz4yomoAlcsJyJrZdGeqMTERPTr1w/NmjWrtE8ul2Pz5s3w9/dHfn4+Fi5ciNzcXDRq1AjdunXD1q1bxXlNISEhePDgAWJjY3Hz5k04OjrCz89PHAJ80rPPPotly5bhvffew927d+Hj44NVq1aJ+0+ePIm3334bCoUCTZo0wZAhQzB79myTtAERPcQMRUTWxqIhqqo5Ro+vI9WjRw+kpKRUWVZoaChCQ0NrfO5hw4bpXJcqNjYWsbGxNS6LiAwnkXC1TSKyTnVinSgiargqMpSa43lEZGUYoojIorhiORFZK4YoIrIorlhORNaKIYqILKqiJ0rNDEVEVoYhiogsqmJOFDuiiMjaMEQRkUU9ylBMUURkXRiiiMiyuNgmEVkphigisiipeHUeUxQRWReGKCKqExihiMjaMEQRkUVxxXIislYMUURkUVyxnIisFUMUEVkUlzggImvFEEVEFiX58/I8ZigisjYMUURkWeISB4xRRGRdGKKIyKKkvAExEVkphigiqhO4YjkRWRuGKCKyKAlXLCciK8UQRUQWxRXLichaMUQRUZ3ACEVE1oYhiogsiutEEZG1YogiIosS14liiCIiK8MQRUQWJfnztxDnRBGRtWGIIiKL4orlRGStGKKIyLK4YjkRWSmGKCKyKK5YTkTWiiGKiOoEZigisjYMUURkURIO5xGRlWKIIiKLEpeJYoYiIivDEEVEFiWpmBPFAT0isjIMUURkUVyxnIisFUMUEVkUVywnImvFEEVEFsUVy4nIWjFEEZFFcTSPiKwVQxQRWRYX2yQiK8UQRUQW9WiJA6YoIrIuFgtRCxYsQLdu3SCXy8WvW7du6Tw+IyMDY8eOhY+PD4YPH47vv/++VudPSUlBSEgIfHx8MHnyZOTk5Ij7EhMT0aVLF426JScn1+p8RKTdoyUOiIisi0V7oqZMmYLz58+LX61atdJ6XFlZGaKiojBw4ECcOXMGs2bNwqxZs5Cfn2/QeX/55Re89dZbWLhwIU6dOgWZTIa5c+dqHOPt7a1Rt7CwMIPORURVk3C1TSKyUraWrkBNnD59Gg8ePMD06dMhlUoxfPhw7NixAykpKZgwYQIAYO/evdi8eTNyc3Ph5eWFRYsWwdPTU2t5ycnJ6NOnD3r37g0AmD17Nnr27InMzEydzyEi06jIUKXlaty+p7RoXeo7GymDKpExWTRE7dq1C7t27cIzzzyDSZMmYfTo0VqPy8zMhJeXF6TSRx1nXbp0QUZGBgDgyJEjWL16NdavX49OnTph9+7diIqKwqFDh2Bvb1+pvIyMDHh7e4uPXVxc0LZtW40QdeXKFfTo0QOurq4YPHgwoqOj4eDgoPdrVKlUUKlUej+vujIf/5dMg+1sHhVzoX699Qcilx62cG3qv+H+T8Hbm+9pU+LvDvMwVTvrU57FQlRERATefPNNuLm54ezZs5gzZw5cXV0xZMiQSscqFAq4ublpbHNzcxPnMe3cuRORkZGQyWQAgHHjxmHLli24ePEiAgICKpWnVCorlefq6gqFQgEACAgIwP79++Hh4YHr168jNjYWK1aswHvvvaf366wIeqaQlpZmsrLpEbazaZU/UKGpmy3+UPAPjimp1ALUAnDrXinf02bCdjYPS7azxUJU165dxe979OiBCRMmICUlRWuIcnZ2RmFhoca2wsJCODs7AwBycnKwYsUKxMfHi/vLyspw+/ZtJCcnIy4uDgDQqlUrHDhwAE5OTpXKKyoqEstr06aNuL1jx46YP38+5s+fb1CI8vLygpOTk97Pq4pKpUJaWhq8vb1hY2Nj1LLpEbazeahUKjg7sJ1N7dv//ILPD6ZDEMC2NjH+7jAPU7WzUqmscQdInZkTJZVKdV7i7Onpic2bN0OtVotDeunp6QgNDQUAuLu7IzIyEuHh4Vqf/+SkcC8vL6Snp4uPFQoFsrOzdc6Hqqpu1bGxsTHZh8iUZdMjbGfzYDublo3Nw9+dgsC2Nhe2s3kYu531KctiV+cdPHgQRUVFUKvVOHv2LBISEjBo0CCtxwYGBqJRo0bYsmULSktLcejQIWRkZGDo0KEAgPHjx2PTpk24fPkyBEGAQqHAkSNHUFRUpLW8sLAwHD9+HKmpqSgpKcHatWshk8nEEHXs2DHk5eUBAG7cuIFPP/0UISEhJmgFIiLzkEofTuFX8ypIIqOxWE/Ul19+iffffx8qlQqtWrXC3LlzMWLECHH/iBEjMGPGDISFhcHOzg7r16/Hu+++i3Xr1sHDwwPr1q1D06ZNAQAhISF48OABYmNjcfPmTTg6OsLPzw+BgYFaz/3ss89i2bJleO+993D37l34+Phg1apV4v6TJ0/i7bffhkKhQJMmTTBkyBDMnj3bpO1BRGRKFUtJMEMRGY9FQ1RVDhw4oPFYJpNh9+7dOo8PDQ0Vh/dqYtiwYRg2bJjWfbGxsYiNja1xWUREdZ0Nb69DZHS87QsRUQPA4Twi42OIIiJqAHh7HSLjY4giImoAKnqiBLWFK0JUjzBEERE1ANKKieWWrQZRvcIQRUTUAHBOFJHxMUQRETUAEl6dR2R0DFFERA2AlCGKyOgYooiIGgAO5xEZH0MUEVEDwJ4oIuNjiCIiagD+vHc7QxSRETFEERE1AJxYTmR8DFFERA0A50QRGR9DFBFRAyDlbV+IjI4hioioAeDEciLjY4giImoAOLGcyPgYooiIGoCKieWcE0VkPAxRREQNQMXEcmYoIuNhiCIiagA4J4rI+BiiiIgaACmH84iMjiGKiKgB4MRyIuNjiCIiagC4YjmR8TFEERE1AOLEcgvXg6g+YYgiImoAOCeKyPgYooiIGgAucUBkfAxRREQNwJ8dUQxRREbEEEVE1ABwOI/I+BiiiIgaABsO5xEZHUMUEVEDwCUOiIyPIYqIqAHgxHIi42OIIiJqAComlnNOFJHxMEQRETUANlxsk8joGKKIiBoAKedEERkdQxQRUQPw+MRygUmKyCgYooiIGoCKieUAe6OIjIUhioioAXgsQ3FyOZGRWCRElZaW4p133sHAgQMhl8sxYsQI7Nu3T+fxMpkMvr6+kMvlkMvliIyMrNX5U1JSEBISAh8fH0yePBk5OTnivsTERHTp0kU8l1wuR3Jycq3OR0RkaZo9UQxRRMZga4mTlpeXo0WLFvj888/RunVrnDt3DjNmzEDr1q0hl8u1PmfPnj149tlna33uX375BW+99RbWrl0Lf39/xMfHY+7cudi9e7d4jLe3N3bt2lXrcxER1RUVc6IAQK22YEWI6hGLhCgnJyfMmTNHfOzv74/u3bvj/PnzOkNUVfbu3YvNmzcjNzcXXl5eWLRoETw9PbUem5ycjD59+qB3794AgNmzZ6Nnz57IzMzU+RwiImv3eE/U9z/9BodGdhasTf0mqNVQPVBZuhpkBhYJUU9SKpX46aefMGnSJJ3HTJ48GWq1Gt26dcMbb7whBp4jR45g9erVWL9+PTp16oTdu3cjKioKhw4dgr29faVyMjIy4O3tLT52cXFB27ZtNULUlStX0KNHD7i6umLw4MGIjo6Gg4ODQa9NpVJBpTLuh6miPGOXS5rYzubBdjYTQQ2J5OGk8lVfX7B0beo9j6b26BnA97Qpmep3hz7lWTxEqdVqLFiwAN7e3mLv0JO++OIL+Pr6orS0FJs3b8bUqVNx6NAhuLi4YOfOnYiMjIRMJgMAjBs3Dlu2bMHFixcREBBQqSylUgk3NzeNba6urlAoFACAgIAA7N+/Hx4eHrh+/TpiY2OxYsUKvPfeewa9voyMDIOeVxNpaWkmK5seYTubB9vZ9AY+74bMWw8sXY16rbRcQO79MhQoy/meNhNLtrNFQ5QgCIiLi0NeXh62bt2qMWb/uMDAQACAvb09YmJikJycjB9++AF9+/ZFTk4OVqxYgfj4ePH4srIy3L59G8nJyYiLiwMAtGrVCgcOHICTkxMKCws1yi8qKoKzszMAoE2bNuL2jh07Yv78+Zg/f77BIcrLywtOTk4GPVcXlUqFtLQ0eHt7w8bGxqhl0yNsZ/NgO5uPtzfb2tSycwsxO/4Y1GqwnU3MVL87lEpljTtALBaiBEHAokWLkJ6eju3bt4shpiYkEol4dYm7uzsiIyMRHh6u9diwsDCNx15eXkhPTxcfKxQKZGdn65wPJZVKa3Uli42Njck+RKYsmx5hO5sH29l82NamY2//8M+qSi2wnc3E2O2sT1kWWydq8eLFuHjxIrZu3QoXFxedx2VmZuLnn39GeXk5iouLsXbtWpSUlIgT0MePH49Nmzbh8uXLEAQBCoUCR44cQVFRkdbywsLCcPz4caSmpqKkpARr166FTCYTQ9SxY8eQl5cHALhx4wY+/fRThISEGPnVExFRfVRxj0IVr4BsECzSE5WTk4OvvvoK9vb26N+/v7h9xowZiIqKglwux+bNm+Hv74/8/HwsXLgQubm5aNSoEbp164atW7eK85pCQkLw4MEDxMbG4ubNm3B0dISfn584BPikZ599FsuWLcN7772Hu3fvwsfHB6tWrRL3nzx5Em+//TYUCgWaNGmCIUOGYPbs2aZsDiIiqifsbB/2TajVXIurIbBIiPLw8MCVK1d07j9//rz4fY8ePZCSklJleaGhoQgNDa3x+YcNG4Zhw4Zp3RcbG4vY2Ngal0VERFTBRvpniOI9ChsE3vaFiIjISGxtHl0gpWJvVL3HEEVERGQkNjaP/qyqVAxR9R1DFBERkZE83hNVztnl9R5DFBERkZFUzIkCOJzXEDBEERERGYlUKhHvU1hezp6o+o4hioiIyIhsK0KUmiGqvmOIIiIiMqKKyeWcWF7/MUQREREZUcXkck4sr/8YooiIiIyoYnI5J5bXfwxRRERERmRry56ohoIhioiIyIjEnijOiar3GKKIiIiMiHOiGg6GKCIiIiOquDqvnD1R9R5DFBERkRFVrBOl4jpR9R5DFBERkRHZ2rInqqGwtXQFiIiI6pOKieXxX/0AO9sLlq1MPWYjlWKAtxN8fS1XB4YoIiIiI+ro4Yb06/fwoFSFB6UqS1enXrv7h71Fz88QRUREZESRYV3RsUkxvGSdYWNjY+nq1FsSiYDc7AyL1oEhioiIyIgkEgmautmhTUtXhigTUqlUuH1DYtE6cGI5ERERkQEYooiIiIgMwBBFREREZACGKCIiIiIDMEQRERERGYAhioiIiMgADFFEREREBmCIIiIiIjIAQxQRERGRARiiiIiIiAzAEEVERERkAIYoIiIiIgMwRBEREREZwNbSFaiv1Go1AKC4uNjoZatUKgCAUqnkHcJNiO1sHmxn82Fbmwfb2TxM1c4Vf7cr/o5XRSIIgmC0M5MoPz8f169ft3Q1iIiIyADt27dH06ZNqzyGIcpEysvLUVBQgEaNGkEq5agpERGRNVCr1SgpKUHjxo1ha1v1gB1DFBEREZEB2EVCREREZACGKCIiIiIDMEQRERERGYAhioiIiMgADFFEREREBmCIIiIiIjIAQxQRERGRARiiiIiIiAzAEEVERERkAIaoOu6PP/7AnDlzIJfL0bt3b2zfvl3cJ5PJ8Msvv4iPk5KSEBgYiDNnzligpnVXaWkp3nnnHQwcOBByuRwjRozAvn37xP0ZGRkYO3YsfHx8MHz4cHz//fcaz09JSUFISAh8fHwwefJk5OTkiPvWrl2LmJgY8XFBQQHGjBmD2bNno6yszPQvro66d+8egoKCMHbsWHEb29n4vvvuO4SGhsLX1xcDBgzAP//5TwBsa2O6efMmpk+fjsDAQPTs2RNvvvkmioqKAAC//fYbpk6dCl9fXwwcOBAHDhzQeO7p06cRGhoKHx8fvPTSS7h8+bK4LzExUePzUVJSgqioKEyYMEEsvz5LSEhAeHg4unXrpvF+A2r3/gWAVatWoUePHvDz88M777yD0tJScV9ERAR27twpPk5PT0evXr2wbds2w16IQHXa/PnzhaioKKGwsFC4fPmy0KNHD+E///mPIAiC4OXlJVy9elUQBEFISEgQAgMDhYsXL1qyunWSQqEQVq1aJWRnZwtqtVo4c+aM0L17d+GHH34QSktLhQEDBgjr168XSkpKhAMHDgjdu3cX7t69KwiCIFy9elXw9fUVjh8/LhQXFwtLly4VRo8eLZa9Zs0aYe7cuYIgCMKdO3eE0NBQITY2VigvL7fIa60rFixYILzyyivCmDFjBEEQ2M4mkJqaKvTt21c4e/asoFKphLt37wrZ2dlsayP761//Krz++utCcXGx8PvvvwsRERHCkiVLBEEQhHHjxglxcXFCcXGxcPLkScHX11e4cuWKIAiCcO/ePcHPz0/49ttvhZKSEuHvf/+70L9/f6GkpEQQBEHYs2eP+PkoKioSJk2aJEydOlVQKpWWeaFm9t133wmHDx8WFi1aJL7fBKH2vyt27dolDBw4UMjOzhbu3bsnjBs3Tvj444/F/RMnThS++uorQRAE4dy5c0JgYKDwj3/8w+DXwZ6oOkypVCIlJQUxMTFwcXGBTCbD2LFjsWfPHo3jNm7ciL/97W/YsWMHnn/+eQvVtu5ycnLCnDlz0KZNG0gkEvj7+6N79+44f/48Tp8+jQcPHmD69Omwt7fH8OHD4enpiZSUFABAcnIy+vTpg969e8PBwQGzZ8/G5cuXkZmZqXGOW7duYcKECfD398eHH34IGxsbS7zUOuH06dO4fv06wsPDNbaxnY1rzZo1eO211+Dn5wepVIqmTZuiTZs2bGsju3nzJkJDQ+Hg4IDGjRtjyJAhyMjIwPXr1/Hjjz8iJiYGDg4OCAoKwsCBA/Htt98CAA4fPoy2bdti5MiRsLe3x5QpU6BWq5GamqpRfkFBAaZOnQoXFxesX78ejo6OlniZZjd48GCEhISgSZMmGttr+/7ds2cP/vrXv6JNmzZo0qQJZs2ahcTExErnT01NxfTp0/HOO+9o9AjqiyGqDrt+/ToEQYCXl5e4rXPnzhq/7NasWYOdO3ciISEBMpnMEtW0OkqlEj/99BM8PT2RmZkJLy8vSKWPPgpdunRBRkYGgIfdyp07dxb3ubi4oG3btho/g5ycHEyYMAGDBg1CXFwcJBKJ+V5MHVNaWooPPvigUjuwnY1LpVIhLS0Nv//+O4YMGYLevXvjrbfeQmFhIdvayCZPnox9+/ZBoVDg3r17SElJQd++fZGZmYlWrVqhcePG4rFdunQR2zEjIwNdunQR90kkEshkMvHnADwMUBEREWjTpg1Wr14Ne3t7872wOqq279/MzEyN/V26dMG9e/dw9+5dcdt///tfREdHY/ny5QgLC6tVfRmi6jClUgkXFxeNbW5ublAoFOLj48ePo0ePHujQoYO5q2eV1Go1FixYAG9vb/Tu3RsKhQJubm4axzzexkqlstJ+V1dXjZ/B1atXcf/+/Vp/GOuDTZs2oWfPnhq/xACwnY3s7t27KCsrw8GDB/H555/j4MGDuHv3LpYtW8a2NrLAwEBcu3YN/v7+6NmzJ+zt7REREQGFQgFXV1eNY/Vt57y8PGRmZuKll16Cra2t6V+MFajt+/fJ/RU/o8fb/dSpU2jVqhV69OhR6/oyRNVhTk5OGj94ACgsLISzs7P4OD4+Ht9//z0++OADc1fP6giCgLi4OOTl5WHlypWQSCRwdnZGYWGhxnGPt7GTk1Ol/UVFRRo/g379+mHSpEmYMmUKrl69avoXUkdlZWXh22+/xezZsyvtYzsbV8WQz4QJE/DMM8/Azc0NUVFROHr0KNvaiFQqFSIjI9G/f39cuHAB586dQ4sWLfDGG2/A2dm50gRwfdvZ09MTcXFxmDlzJk6fPm36F2QFavv+fXJ/xfePt/vs2bPRtGlTREZG1noSP0NUHda+fXsA0OhmT09Ph6enp/i4TZs22LFjBw4fPowlS5aYu4pWQxAELFq0COnp6diyZYv4gfL09ERGRgbUarV4bHp6ujiE6uXlhfT0dHGfQqFAdna2xs8AAObNm4fw8HBMnjxZ44rJhuTcuXO4e/cuhgwZguDgYCxduhSXLl1CcHAwWrduzXY2Ijc3N7i7u2sdZuN72ngKCgqQm5uLiRMnolGjRnBxccH48ePx3//+F56enrh16xb++OMP8fjHfz8/2c6CIODKlSsa0zMAYNy4cXjjjTcwY8YMnD171jwvrA6r7fvX09NT4yrIy5cv4+mnn0azZs3EbY0aNcKGDRtgb2+PadOmVeqs0AdDVB3m5OSEIUOGYOXKlSgqKkJGRga++eYbvPTSSxrHtWvXDjt27MB3332HZcuWWai2ddvixYtx8eJFbN26VWOINDAwEI0aNcKWLVtQWlqKQ4cOISMjA0OHDgUAhIWF4fjx40hNTUVJSQnWrl0LmUxW6Q8OALz++ut48cUXMXnyZFy7ds1sr62uGD58OP71r38hKSkJSUlJmD17Nry8vJCUlIR+/fqxnY1s9OjR+PLLL3Hnzh0UFRVh8+bNGDhwIN/TRvT000+jTZs2+Oqrr1BaWgqlUoldu3ZBJpOhffv26NatG1atWoUHDx7gzJkzOHLkCEaNGgUAGDRoELKysrB3716Ulpbi888/BwD06tWr0nleeeUVvP7665g+fTrOnTtn1tdoKeXl5SgpKUF5eTnUajVKSkpQVlZW6/dveHg4tm/fjhs3buD333/HZ599pnGRSwUHBwds3LgRtra2mDZtGpRKpWEvxODr+sgsCgoKhOjoaMHX11cIDg4Wtm3bJu57fIkDQRCEa9euCb179xaWL19ugZrWXTdv3hS8vLyEbt26Cb6+vuLX+vXrBUEQhMuXLwujR48WvL29haFDhwqpqakazz948KAwcOBA4fnnnxciIiKEmzdvivsevxy8wvLly4Xg4GDh2rVrpn9xddjjl3ALAtvZ2MrKyoQPPvhACAgIEHr06CEsWLBAKCwsFASBbW1M6enpwqRJk4SAgAAhMDBQmDZtmpCVlSUIgiDcunVLmDJlivD8888LAwYMEPbt26fx3JMnTwojRowQvL29hfDwcOHSpUvivic/H4IgCF988YXQvXt34dy5c6Z/YRa2Zs0awcvLS+MrNjZWEITavX/VarUQHx8vBAYGCt27dxfeeustcVkJQdBc4kAQHi6BM3HiRGHChAmCQqHQ+3VIBEEQDI6SRERERA0Uh/OIiIiIDMAQRURERGQAhigiIiIiAzBEERERERmAIYqIiIjIAAxRRERERAZgiCIiIiIyAEMUERERkQEYooiITEQul+PUqVOWrgYRmQhDFBHVGxEREVi5ciUAYODAgdi9e7dZzpuYmIi+fftW2n7+/HkEBQWZpQ5EZH4MUUREOqhUKo27yRMRPY4hiojqncjISNy6dQuLFy+GXC7HiBEjxH1JSUkICwuDn58fRowYgQMHDoj7Tp06BZlMhgMHDmDIkCHw8fFBfn4+Dh06hPDwcAQEBCAoKAhRUVG4ceMGAODs2bOIi4tDXl4e5HI55HI5kpOTAQAymQypqali+f/5z38QHh4OPz8/DBkyBFu3btUIaTKZDF988QXGjRsHuVyOF154AWfPnjV1cxGRofS+ZTERUR01ceJEIT4+XhAEQRgwYICwa9cujf179uwR+vXrJ/z444+CSqUSzpw5I8jlcuHMmTOCIAjCyZMnBS8vL2HmzJnCvXv3hJKSEqG8vFw4duyYkJ6eLpSXlwv5+fnCjBkzhLFjx2qU26dPn0r18fLyEk6cOCEIgiBcvHhR6Nq1q3DgwAGhrKxMSEtLE4KDg4Vt27ZpHP/CCy8I169fF8rKyoQlS5YI/fv3N3YzEZGRsCeKiBqMbdu2ISoqCt7e3pBKpfD398fw4cPx7bffahw3f/58NGnSBPb29rCxsUHfvn3RuXNn2NjY4Omnn8bs2bNx4cIFFBUV1fjc33zzDfr164fhw4fD1tYW3bp1Q2RkJL7++muN46ZOnYp27drB1tYWY8eOxa1bt3D37l2jvH4iMi5bS1eAiMhcsrKy8NFHH+GTTz4Rt6lUKvj7+2sc17p1a43Hp0+fxmeffYZffvkFSqVS3H7v3j24uLjU6Ny//fYbOnXqpLGtbdu2+O233zS2tWjRQvze0dERAKBQKNCsWbManYeIzIchiojqJYlEUmlbs2bNMHv2bIwcObLK50qljzrpS0tLMWPGDLz22mv47LPP4OLigkuXLmHUqFEQBKHS8bq4u7sjOztbY1t2djbc3d1r8GqIqC7icB4R1UvNmzfHtWvXNLZNnjwZf/vb3/Djjz9CrVajtLQUP/74I3766Sed5ZSVlaGkpASNGzeGi4sLbt++jVWrVmkc06xZM9y/fx/379/XWc5LL72EY8eO4bvvvoNKpcKlS5ewdetWvPzyy7V6nURkOQxRRFQvzZw5E0eOHIG/vz9eeOEFAA9D1KxZs7Bw4UIEBgaiT58+WLFiBYqLi3WW4+zsjCVLlmD9+vWQy+WYNm0ahg4dqnFMjx498Je//AVDhw6Fv78/9u3bV6kcHx8frF69Ghs2bEBAQADmzJmDiIgITJo0ybgvnIjMRiJU9EcTERERUY2xJ4qIiIjIAAxRRERERAZgiCIiIiIyAEMUERERkQEYooiIiIgMwBBFREREZACGKCIiIiIDMEQRERERGYAhioiIiMgADFFEREREBmCIIiIiIjIAQxQRERGRAf4fTyQ5lBrv3n4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# lr_scheduler.py\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def MultiStepLR(initial_learning_rate, lr_steps, lr_rate, name='MultiStepLR'):\n",
        "    \"\"\"Multi-steps learning rate scheduler.\"\"\"\n",
        "    lr_steps_value = [initial_learning_rate]\n",
        "    for _ in range(len(lr_steps)):\n",
        "        lr_steps_value.append(lr_steps_value[-1] * lr_rate)\n",
        "    return tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "        boundaries=lr_steps, values=lr_steps_value)\n",
        "\n",
        "\n",
        "def CosineAnnealingLR_Restart(initial_learning_rate, t_period, lr_min):\n",
        "    \"\"\"Cosine annealing learning rate scheduler with restart.\"\"\"\n",
        "    return tf.keras.experimental.CosineDecayRestarts(\n",
        "        initial_learning_rate=initial_learning_rate,\n",
        "        first_decay_steps=t_period, t_mul=1.0, m_mul=1.0,\n",
        "        alpha=lr_min / initial_learning_rate)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # pretrain PSNR lr scheduler\n",
        "    lr_scheduler = MultiStepLR(2e-4, [200000, 400000, 600000, 800000], 0.5)\n",
        "\n",
        "    # ESRGAN lr scheduler\n",
        "    # lr_scheduler = MultiStepLR(1e-4, [50000, 100000, 200000, 300000], 0.5)\n",
        "\n",
        "    # Cosine Annealing lr scheduler\n",
        "    # lr_scheduler = CosineAnnealingLR_Restart(2e-4, 250000, 1e-7)\n",
        "\n",
        "    ##############################\n",
        "    # Draw figure\n",
        "    ##############################\n",
        "    N_iter = 1000000\n",
        "    step_list = list(range(0, N_iter, 1000))\n",
        "    lr_list = []\n",
        "    for i in step_list:\n",
        "        current_lr = lr_scheduler(i).numpy()\n",
        "        lr_list.append(current_lr)\n",
        "\n",
        "    import matplotlib as mpl\n",
        "    from matplotlib import pyplot as plt\n",
        "    import matplotlib.ticker as mtick\n",
        "    mpl.style.use('default')\n",
        "    import seaborn\n",
        "    seaborn.set(style='whitegrid')\n",
        "    seaborn.set_context('paper')\n",
        "\n",
        "    plt.figure(1)\n",
        "    plt.subplot(111)\n",
        "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0, 0))\n",
        "    plt.title('Title', fontsize=16, color='k')\n",
        "    plt.plot(step_list, lr_list, linewidth=1.5, label='learning rate scheme')\n",
        "    legend = plt.legend(loc='upper right', shadow=False)\n",
        "    ax = plt.gca()\n",
        "    labels = ax.get_xticks().tolist()\n",
        "    for k, v in enumerate(labels):\n",
        "        labels[k] = str(int(v / 1000)) + 'K'\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.1e'))\n",
        "\n",
        "    ax.set_ylabel('Learning rate')\n",
        "    ax.set_xlabel('Iteration')\n",
        "    fig = plt.gcf()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkuI8-mnHqVP"
      },
      "outputs": [],
      "source": [
        "# losses.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input, VGG19\n",
        "\n",
        "def get_pixel_loss(criterion='l1'):\n",
        "    \"\"\"pixel loss\"\"\"\n",
        "    if criterion == 'l1':\n",
        "        return tf.keras.losses.MeanAbsoluteError()\n",
        "    elif criterion == 'l2':\n",
        "        return tf.keras.losses.MeanSquaredError()\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Loss type {} is not recognized.'.format(criterion))\n",
        "\n",
        "def get_content_loss(criterion='l1', output_layer=54, before_act=True):\n",
        "    \"\"\"content loss\"\"\"\n",
        "    if criterion == 'l1':\n",
        "        loss_func = tf.keras.losses.MeanAbsoluteError()\n",
        "    elif criterion == 'l2':\n",
        "        loss_func = tf.keras.losses.MeanSquaredError()\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Loss type {} is not recognized.'.format(criterion))\n",
        "    vgg = VGG19(input_shape=(None, None, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "    if output_layer == 22:  # Low level feature\n",
        "        pick_layer = 5\n",
        "    elif output_layer == 54:  # Hight level feature\n",
        "        pick_layer = 20\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'VGG output layer {} is not recognized.'.format(criterion))\n",
        "\n",
        "    if before_act:\n",
        "        vgg.layers[pick_layer].activation = None\n",
        "\n",
        "    fea_extrator = tf.keras.Model(vgg.input, vgg.layers[pick_layer].output)\n",
        "    fea_extrator.trainable = False\n",
        "\n",
        "    @tf.function\n",
        "    def content_loss(real_hr, fake_hr):\n",
        "        # the input scale range is [0, 1] (vgg is [0, 255]).\n",
        "        # 12.75 is rescale factor for vgg featuremaps.\n",
        "        preprocess_fake_hr = preprocess_input(fake_hr * 255.) / 12.75\n",
        "        preprocess_real_hr = preprocess_input(real_hr * 255.) / 12.75\n",
        "        fake_hr_features = fea_extrator(preprocess_fake_hr)\n",
        "        real_hr_features = fea_extrator(preprocess_real_hr)\n",
        "\n",
        "        return loss_func(real_hr_features, fake_hr_features)\n",
        "\n",
        "    return content_loss\n",
        "\n",
        "def get_discriminator_loss(gan_type='ragan'):\n",
        "    \"\"\"discriminator loss\"\"\"\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    sigma = tf.sigmoid\n",
        "\n",
        "    def discriminator_loss_ragan(real_discriminator_logits, fake_discriminator_logits):\n",
        "        real_logits = sigma(real_discriminator_logits - tf.reduce_mean(fake_discriminator_logits))\n",
        "        fake_logits = sigma(fake_discriminator_logits - tf.reduce_mean(real_discriminator_logits))\n",
        "        return 0.5 * (\n",
        "            cross_entropy(tf.ones_like(real_logits), real_logits) +\n",
        "            cross_entropy(tf.zeros_like(fake_logits), fake_logits))\n",
        "\n",
        "    def discriminator_loss(real_discriminator_logits, fake_discriminator_logits):\n",
        "        real_loss = cross_entropy(tf.ones_like(real_discriminator_logits), sigma(real_discriminator_logits))\n",
        "        fake_loss = cross_entropy(tf.zeros_like(fake_discriminator_logits), sigma(fake_discriminator_logits))\n",
        "        return real_loss + fake_loss\n",
        "\n",
        "    if gan_type == 'ragan':\n",
        "        return discriminator_loss_ragan\n",
        "    elif gan_type == 'gan':\n",
        "        return discriminator_loss\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Discriminator loss type {} is not recognized.'.format(gan_type))\n",
        "\n",
        "def get_generator_loss(gan_type='ragan'):\n",
        "    \"\"\"generator loss\"\"\"\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    sigma = tf.sigmoid\n",
        "\n",
        "    def generator_loss_ragan(real_discriminator_logits, fake_discriminator_logits):\n",
        "        real_logits = sigma(real_discriminator_logits - tf.reduce_mean(fake_discriminator_logits))\n",
        "        fake_logits = sigma(fake_discriminator_logits - tf.reduce_mean(real_discriminator_logits))\n",
        "        return 0.5 * (\n",
        "            cross_entropy(tf.ones_like(fake_logits), fake_logits) +\n",
        "            cross_entropy(tf.zeros_like(real_logits), real_logits))\n",
        "\n",
        "    def generator_loss(real_discriminator_logits, fake_discriminator_logits):\n",
        "        return cross_entropy(tf.ones_like(fake_discriminator_logits), sigma(fake_discriminator_logits))\n",
        "\n",
        "    if gan_type == 'ragan':\n",
        "        return generator_loss_ragan\n",
        "    elif gan_type == 'gan':\n",
        "        return generator_loss\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Generator loss type {} is not recognized.'.format(gan_type))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzYZSzR6HeQz"
      },
      "outputs": [],
      "source": [
        "# dataset.py\n",
        "\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "DATA_PATH = \"/content/hr\"\n",
        "\n",
        "def scale_input_image(img):\n",
        "    #img/ 255.\n",
        "    return tf.image.convert_image_dtype(img, dtype=tf.float32)\n",
        "\n",
        "def unscale_output_image(img):\n",
        "    #img * 255\n",
        "    return tf.image.convert_image_dtype(img, dtype=tf.uint8, saturate=True)\n",
        "\n",
        "def random_crop_and_flip(img, random_crop_size):\n",
        "    assert img.shape[2] == 3\n",
        "    height, width = img.shape[0], img.shape[1]\n",
        "    dy, dx = random_crop_size\n",
        "    x = np.random.randint(0, width - dx + 1)\n",
        "    y = np.random.randint(0, height - dy + 1)\n",
        "    image = img[y:(y+dy), x:(x+dx), :]\n",
        "    flip_case = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
        "    if(tf.equal(flip_case, 0)):\n",
        "        image = tf.image.flip_left_right(image)\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_image(image_path, hr_height, hr_width, crop_per_image, ext):\n",
        "    assert ext in ['.png', '.jpg', '.jpeg', '.JPEG']\n",
        "    image = tf.io.read_file(image_path)\n",
        "    if ext == '.png':\n",
        "        image = tf.image.decode_png(image, channels=3)\n",
        "    else:\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "    image = scale_input_image(image)\n",
        "    cropped_images = [ random_crop_and_flip(image, (hr_height, hr_width)) for _ in range(crop_per_image)]\n",
        "\n",
        "    return cropped_images\n",
        "\n",
        "\n",
        "\n",
        "def load_dataset(hr_height, hr_width, scale, crop_per_image=20, ext='.png'):\n",
        "    image_paths = []\n",
        "    for root, _, files in os.walk(DATA_PATH):\n",
        "        for file in files:\n",
        "            if f'{ext}' in file:\n",
        "                image_paths.append(os.path.join(root, file))\n",
        "\n",
        "    random.shuffle(image_paths)\n",
        "    images = []\n",
        "    for img_path in image_paths:\n",
        "        images += load_and_preprocess_image(img_path, hr_height, hr_width, crop_per_image, ext)\n",
        "\n",
        "    random.shuffle(images)\n",
        "    hr_images = []\n",
        "    lr_images = []\n",
        "    for img in images:\n",
        "        hr_image = img\n",
        "        lr_shape = [int(hr_image.shape[0]/scale), int(hr_image.shape[1]/scale)]\n",
        "        lr_image = tf.image.resize(hr_image, lr_shape, method=tf.image.ResizeMethod.BICUBIC)\n",
        "        #lr_image = lr_image / 255\n",
        "        lr_image = tf.clip_by_value(\n",
        "        lr_image, 0, 1, name=None\n",
        "        )\n",
        "        hr_images.append(hr_image)\n",
        "        lr_images.append(lr_image)\n",
        "\n",
        "    lr_dataset = tf.data.Dataset.from_tensor_slices(lr_images)\n",
        "    hr_dataset = tf.data.Dataset.from_tensor_slices(hr_images)\n",
        "\n",
        "    dataset = tf.data.Dataset.zip((lr_dataset, hr_dataset))\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuxTzvTsHPrO"
      },
      "outputs": [],
      "source": [
        "# esrgan.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, PReLU, Dropout, Dense\n",
        "from tensorflow.keras.layers import BatchNormalization, Concatenate, Lambda, Add\n",
        "\n",
        "\n",
        "def residual_dense_block(input, filters):\n",
        "    x1 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(input)\n",
        "    x1 = LeakyReLU(0.2)(x1)\n",
        "    x1 = Concatenate()([input, x1])\n",
        "\n",
        "    x2 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(x1)\n",
        "    x2 = LeakyReLU(0.2)(x2)\n",
        "    x2 = Concatenate()([input, x1, x2])\n",
        "\n",
        "    x3 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(x2)\n",
        "    x3 = LeakyReLU(0.2)(x3)\n",
        "    x3 = Concatenate()([input, x1, x2, x3])\n",
        "\n",
        "    x4 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(x3)\n",
        "    x4 = LeakyReLU(0.2)(x4)\n",
        "    x4 = Concatenate()([input, x1, x2, x3, x4])\n",
        "\n",
        "    x5 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(x4)\n",
        "    x5 = Lambda(lambda x: x * 0.2)(x5)\n",
        "    x = Add()([x5, input])\n",
        "\n",
        "    return x\n",
        "\n",
        "def rrdb(input, filters):\n",
        "    x = residual_dense_block(input, filters)\n",
        "    x = residual_dense_block(x, filters)\n",
        "    x = residual_dense_block(x, filters)\n",
        "    x = Lambda(lambda x: x * 0.2)(x)\n",
        "    out = Add()([x, input])\n",
        "    return out\n",
        "\n",
        "def sub_pixel_conv2d(scale_factor=2, **kwargs):\n",
        "    return Lambda(lambda  x: tf.nn.depth_to_space(x, scale_factor), **kwargs)\n",
        "\n",
        "def upsample(input_tensor, filters, scale_factor=2):\n",
        "    x = Conv2D(filters=filters*4, kernel_size=3, strides=1, padding='same')(input_tensor)\n",
        "    x = sub_pixel_conv2d(scale_factor=scale_factor)(x)\n",
        "    x = PReLU(shared_axes=[1,2])(x)\n",
        "    return x\n",
        "\n",
        "def rrdb_net(input_shape=(None, None, 3), filters=64, scale_factor=4, name='RRDB_model'):\n",
        "    lr_image = Input(shape=input_shape, name='input')\n",
        "\n",
        "    #Pre-residual\n",
        "    x_start = Conv2D(filters, kernel_size=3, strides=1, padding='same')(lr_image)\n",
        "    x_start = LeakyReLU(0.2)(x_start)\n",
        "\n",
        "    #Residual block\n",
        "    x = rrdb(x_start, filters)\n",
        "\n",
        "    #Post Residual block\n",
        "    x = Conv2D(filters,  kernel_size=3, strides=1, padding='same')(x)\n",
        "    x = Lambda(lambda x: x * 0.2)(x)\n",
        "    x = Add()([x, x_start])\n",
        "\n",
        "    #Upsampling\n",
        "    x = upsample(x, filters, scale_factor)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size=3, strides=1, padding='same')(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    out = Conv2D(filters=3, kernel_size=3, strides=1, padding='same')(x)\n",
        "\n",
        "    return Model(inputs=lr_image, outputs=out, name=name)\n",
        "\n",
        "def conv2d_block(input, filters, strides=1, bn=True):\n",
        "    x = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(input)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    if bn:\n",
        "        x = BatchNormalization(momentum=0.8)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def discriminator_net(input_shape=(None, None, 3), filters=64, name='Discriminator'):\n",
        "    img = Input(shape=input_shape)\n",
        "\n",
        "    x = conv2d_block(img, filters, bn=False)\n",
        "    x = conv2d_block(x, filters, strides=2)\n",
        "    x = conv2d_block(x, filters*2)\n",
        "    x = conv2d_block(x, filters*2, strides=2)\n",
        "    x = conv2d_block(x, filters*4)\n",
        "    x = conv2d_block(x, filters*4, strides=2)\n",
        "    x = conv2d_block(x, filters*8)\n",
        "    x = conv2d_block(x, filters*8, strides=2)\n",
        "    x = Dense(filters*16)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(1)(x)\n",
        "\n",
        "    return Model(inputs=img, outputs=x, name=name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ujiPn8qYD3m",
        "outputId": "fd70b805-479b-48f5-eb17-216f88736c08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.45.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "PXO_hLvkJw3E",
        "outputId": "1a24b79a-2616-4364-b871-ecb3c6df1a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*] training from scratch.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240422_034157-psnr-training</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/personal-nag/uncategorized/runs/psnr-training' target=\"_blank\">psnr-training</a></strong> to <a href='https://wandb.ai/personal-nag/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/personal-nag/uncategorized' target=\"_blank\">https://wandb.ai/personal-nag/uncategorized</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/personal-nag/uncategorized/runs/psnr-training' target=\"_blank\">https://wandb.ai/personal-nag/uncategorized/runs/psnr-training</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loss=0.0088, lr=2.0e-04:   0%| | 1988/1000000 [6:1"
          ]
        }
      ],
      "source": [
        "#train_psnr.py\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "# from modules.esrgan import rrdb_net\n",
        "# from modules.lr_scheduler import MultiStepLR\n",
        "# from modules.data import load_dataset\n",
        "# from modules.losses import get_pixel_loss\n",
        "\n",
        "HAS_WANDB_ACCOUNT = False\n",
        "PROJECT = 'esrgan-tf2'\n",
        "import wandb\n",
        "if not HAS_WANDB_ACCOUNT:\n",
        "    wandb.login(anonymous='allow')\n",
        "else:\n",
        "    wandb.login()\n",
        "\n",
        "INITIAL_LR = 2e-4\n",
        "LR_RATE = 0.5\n",
        "LR_STEPS = [200000, 400000, 600000, 800000]\n",
        "ADAM_BETA1_G = 0.9\n",
        "ADAM_BETA2_G = 0.99\n",
        "W_PIXEL = 1.0\n",
        "PIXEL_CRITERION = 'l1'\n",
        "\n",
        "HR_HEIGHT = 128\n",
        "HR_WIDTH = 128\n",
        "SCALE = 4\n",
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 10240\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "\n",
        "NUM_ITER = 1000000\n",
        "SAVE_STEPS = 5000\n",
        "\n",
        "\n",
        "CHECK_POINT_PATH =  \"./saved/checkpoints/psnr\"\n",
        "Path(CHECK_POINT_PATH).mkdir(parents=True, exist_ok=True)\n",
        "SAVE_MODEL_PATH = \"./saved/models/psnr.h5\"\n",
        "Path(SAVE_MODEL_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    current_epoch = 0\n",
        "    epochs = NUM_ITER // len(dataset)\n",
        "\n",
        "\n",
        "    dataset = load_dataset(HR_HEIGHT, HR_WIDTH, SCALE)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    model = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "    learning_rate = MultiStepLR(INITIAL_LR, LR_STEPS, LR_RATE)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate,\n",
        "                                        beta_1= ADAM_BETA1_G,\n",
        "                                        beta_2= ADAM_BETA2_G\n",
        "                                        )\n",
        "    pixel_loss = get_pixel_loss(PIXEL_CRITERION)\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(step=tf.Variable(0, name='step'),\n",
        "                                     optimizer=optimizer,\n",
        "                                     model=model)\n",
        "    manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
        "                                         directory=CHECK_POINT_PATH,\n",
        "                                         max_to_keep=3)\n",
        "    if manager.latest_checkpoint:\n",
        "        checkpoint.restore(manager.latest_checkpoint)\n",
        "        print('[*] load ckpt from {} at step {}.'.format(\n",
        "            manager.latest_checkpoint, checkpoint.step.numpy()))\n",
        "    else:\n",
        "        print(\"[*] training from scratch.\")\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(lr, hr):\n",
        "        with tf.GradientTape() as tape:\n",
        "            generated_hr = model(lr, training=True)\n",
        "            loss = W_PIXEL * pixel_loss(hr, generated_hr)\n",
        "\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    wandb_run_id = \"psnr-training\" #@param {type:\"string\"}\n",
        "    if HAS_WANDB_ACCOUNT:\n",
        "        wandb.init(entity='ilab', project=PROJECT, id=wandb_run_id)\n",
        "    else:\n",
        "        wandb.init(id=wandb_run_id)\n",
        "\n",
        "    remain_steps = max(NUM_ITER - checkpoint.step.numpy(), 0)\n",
        "    pbar = tqdm(total=remain_steps, ncols=50)\n",
        "\n",
        "    for lr, hr in dataset.take(remain_steps):\n",
        "        checkpoint.step.assign_add(1)\n",
        "        steps = checkpoint.step.numpy()\n",
        "        loss = train_step(lr, hr)\n",
        "        learning_rate = optimizer.lr.numpy()  # Get the learning rate value\n",
        "        wandb.log({\"steps\": steps, \"loss\": loss, \"learning_rate\": learning_rate})\n",
        "        pbar.set_description(\"loss={:.4f}, lr={:.1e}\".format(loss, learning_rate))\n",
        "        pbar.update(1)\n",
        "        if steps % SAVE_STEPS == 0:\n",
        "            manager.save()\n",
        "            print(\"\\n[*] save ckpt file at {}\".format(manager.latest_checkpoint))\n",
        "\n",
        "    model.save(SAVE_MODEL_PATH)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGW4Vmv_Jz69"
      },
      "outputs": [],
      "source": [
        "# train_esrgan.py\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "# from modules.esrgan import rrdb_net, discriminator_net\n",
        "# from modules.lr_scheduler import MultiStepLR\n",
        "# from modules.data import load_dataset\n",
        "# from modules.losses import get_pixel_loss, get_content_loss\n",
        "# from modules.losses import get_discriminator_loss, get_generator_loss\n",
        "\n",
        "HAS_WANDB_ACCOUNT = False\n",
        "PROJECT = 'esrgan-tf2'\n",
        "import wandb\n",
        "if not HAS_WANDB_ACCOUNT:\n",
        "    wandb.login(anonymous='allow')\n",
        "else:\n",
        "    wandb.login()\n",
        "\n",
        "INITIAL_LR_G = 1e-4\n",
        "INITIAL_LR_D = 1e-4\n",
        "LR_RATE = 0.5\n",
        "LR_STEPS = [50000, 100000, 200000, 300000]\n",
        "ADAM_BETA1_G = 0.9\n",
        "ADAM_BETA2_G = 0.99\n",
        "ADAM_BETA1_D = 0.9\n",
        "ADAM_BETA2_D = 0.99\n",
        "\n",
        "PIXEL_CRITERION = 'l1'\n",
        "FEATURE_CRITERION = 'l2'\n",
        "GAN_TYPE = 'ragan'\n",
        "WEIGHT_PIXEL = 1e-2\n",
        "WEIGHT_FEATURE = 1.0\n",
        "WEIGHT_GAN = 5e-3\n",
        "\n",
        "HR_HEIGHT = 128\n",
        "HR_WIDTH = 128\n",
        "SCALE = 4\n",
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 10240\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "\n",
        "NUM_ITER = 400000\n",
        "SAVE_STEPS =  5000\n",
        "\n",
        "PRETRAIN_PATH =  \"./saved/checkpoints/psnr\"\n",
        "CHECK_POINT_PATH =  \"./saved/checkpoints/esrgan\"\n",
        "Path(CHECK_POINT_PATH).mkdir(parents=True, exist_ok=True)\n",
        "SAVE_GAN_PATH = \"./saved/models/esrgan.h5\"\n",
        "Path(SAVE_GAN_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "SAVE_DISC_PATH = \"./saved/models/disc_gan.h5\"\n",
        "Path(SAVE_DISC_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    dataset = load_dataset(HR_HEIGHT, HR_WIDTH, SCALE)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    generator = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "    discriminator = discriminator_net(input_shape=INPUT_SHAPE)\n",
        "\n",
        "    learning_rate_G = MultiStepLR(INITIAL_LR_G, LR_STEPS, LR_RATE)\n",
        "    learning_rate_D = MultiStepLR(INITIAL_LR_D, LR_STEPS, LR_RATE)\n",
        "    optimizer_G = tf.keras.optimizers.Adam(learning_rate= learning_rate_G,\n",
        "                                        beta_1= ADAM_BETA1_G,\n",
        "                                        beta_2= ADAM_BETA2_G\n",
        "                                        )\n",
        "    optimizer_D = tf.keras.optimizers.Adam(learning_rate= learning_rate_D,\n",
        "                                        beta_1= ADAM_BETA1_D,\n",
        "                                        beta_2= ADAM_BETA2_D\n",
        "                                        )\n",
        "\n",
        "    pixel_loss = get_pixel_loss(PIXEL_CRITERION)\n",
        "    feature_loss = get_content_loss(FEATURE_CRITERION)\n",
        "    generator_loss = get_generator_loss(GAN_TYPE)\n",
        "    discriminator_loss = get_discriminator_loss(GAN_TYPE)\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(step=tf.Variable(0, name='step'),\n",
        "                                     optimizer_G=optimizer_G,\n",
        "                                     optimizer_D=optimizer_D,\n",
        "                                     model=generator,\n",
        "                                     discriminator=discriminator)\n",
        "    manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
        "                                         directory=CHECK_POINT_PATH,\n",
        "                                         max_to_keep=3)\n",
        "    if manager.latest_checkpoint:\n",
        "        checkpoint.restore(manager.latest_checkpoint)\n",
        "        print('[*] load ckpt from {} at step {}.'.format(\n",
        "            manager.latest_checkpoint, checkpoint.step.numpy()))\n",
        "    else:\n",
        "        if tf.train.latest_checkpoint(PRETRAIN_PATH):\n",
        "            checkpoint.restore(tf.train.latest_checkpoint(PRETRAIN_PATH))\n",
        "            checkpoint.step.assign(0)\n",
        "            print(\"[*] training from pretrain model {}.\".format(\n",
        "                    PRETRAIN_PATH ))\n",
        "        else:\n",
        "            print(\"[*] cannot find pretrain model {}.\".format(\n",
        "                PRETRAIN_PATH))\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(lr, hr):\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            generated_hr = generator(lr, training=True)\n",
        "            real_logits = discriminator(hr, training=True)\n",
        "            fake_logits = discriminator(generated_hr, training=True)\n",
        "            losses_G = {}\n",
        "            losses_D = {}\n",
        "            losses_G['pixel'] = WEIGHT_PIXEL * pixel_loss(hr, generated_hr)\n",
        "            losses_G['feature'] = WEIGHT_FEATURE * feature_loss(hr, generated_hr)\n",
        "            losses_G['gan'] = WEIGHT_GAN * generator_loss(real_logits, fake_logits)\n",
        "            losses_D['disc'] = discriminator_loss(real_logits, fake_logits)\n",
        "            total_loss_G = tf.add_n([l for l in losses_G.values()])\n",
        "            total_loss_D = tf.add_n([l for l in losses_D.values()])\n",
        "\n",
        "\n",
        "        grads_G = tape.gradient(\n",
        "            total_loss_G, generator.trainable_variables)\n",
        "        grads_D = tape.gradient(\n",
        "            total_loss_D, discriminator.trainable_variables)\n",
        "        optimizer_G.apply_gradients(\n",
        "            zip(grads_G, generator.trainable_variables))\n",
        "        optimizer_D.apply_gradients(\n",
        "            zip(grads_D, discriminator.trainable_variables))\n",
        "\n",
        "        return total_loss_G, total_loss_D, losses_G, losses_D\n",
        "\n",
        "\n",
        "    wandb_run_id = \"esrgan-training\" #@param {type:\"string\"}\n",
        "    if HAS_WANDB_ACCOUNT:\n",
        "        wandb.init(entity='ilab', project=PROJECT, id=wandb_run_id)\n",
        "    else:\n",
        "        wandb.init(id=wandb_run_id)\n",
        "    remain_steps = max(NUM_ITER - checkpoint.step.numpy(), 0)\n",
        "    pbar = tqdm(total=remain_steps, ncols=50)\n",
        "    for lr, hr in dataset.take(remain_steps):\n",
        "        checkpoint.step.assign_add(1)\n",
        "        steps = checkpoint.step.numpy()\n",
        "        total_loss_G, total_loss_D, losses_G, losses_D = train_step(lr, hr)\n",
        "        learning_rate_G = optimizer_G.lr.numpy()\n",
        "        learning_rate_D = optimizer_D.lr.numpy()\n",
        "        wandb.log({**{\"steps\": steps},**losses_G, **losses_D,\n",
        "                    **{\"total_loss_G\": total_loss_G.numpy()},\n",
        "                    **{\"learning_rate_G\": learning_rate_G,\n",
        "                    \"learning_rate_D\": learning_rate_D}})\n",
        "\n",
        "        pbar.set_description(\"loss_G={:.4f}, loss_D={:.4f}, lr_G={:.1e}, lr_D={:.1e}\".format(\n",
        "            total_loss_G.numpy(), total_loss_D.numpy(),\n",
        "            learning_rate_G, learning_rate_D))\n",
        "        pbar.update(1)\n",
        "        if steps % SAVE_STEPS == 0:\n",
        "            manager.save()\n",
        "            print(\"\\n[*] save ckpt file at {}\".format(manager.latest_checkpoint))\n",
        "\n",
        "\n",
        "    generator.save(SAVE_GAN_PATH)\n",
        "    discriminator.save(SAVE_DISC_PATH)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP9SuiyEzmle"
      },
      "outputs": [],
      "source": [
        "# net_interp.py\n",
        "\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "# from modules.esrgan import rrdb_net\n",
        "\n",
        "\n",
        "SCALE = 4\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "ALPHA = 0.8\n",
        "\n",
        "CHECKPOINT_PATH_PSNR = \"./saved/checkpoints/psnr\"\n",
        "CHECKPOINT_PATH_ESRGAN = \"./saved/checkpoints/esrgan\"\n",
        "SAVE_MODEL_PATH = \"./saved/models/interp_esr.h5\"\n",
        "Path(SAVE_MODEL_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def main():\n",
        "\n",
        "    # define network\n",
        "    model = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "\n",
        "    # load checkpoint\n",
        "    checkpoint_psnr = tf.train.Checkpoint(model=model)\n",
        "    if tf.train.latest_checkpoint(CHECKPOINT_PATH_PSNR):\n",
        "        status = checkpoint_psnr.restore(tf.train.latest_checkpoint(CHECKPOINT_PATH_PSNR))\n",
        "        status.expect_partial()\n",
        "        print(\"[*] load ckpt psnr from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH_PSNR)))\n",
        "    else:\n",
        "        print(\"[*] Cannot find ckpt psnr from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH_PSNR)))\n",
        "        exit()\n",
        "    vars_psnr = [v.numpy() for v in checkpoint_psnr.model.trainable_variables]\n",
        "\n",
        "    checkpoint_esrgan = tf.train.Checkpoint(model=model)\n",
        "    if tf.train.latest_checkpoint(CHECKPOINT_PATH_ESRGAN):\n",
        "        status = checkpoint_esrgan.restore(tf.train.latest_checkpoint(CHECKPOINT_PATH_ESRGAN))\n",
        "        status.expect_partial()\n",
        "        print(\"[*] load ckpt edsr from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH_ESRGAN)))\n",
        "    else:\n",
        "        print(\"[*] Cannot find ckpt edsr from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH_ESRGAN)))\n",
        "        exit()\n",
        "    vars_edsr = [v.numpy() for v in checkpoint_esrgan.model.trainable_variables]\n",
        "\n",
        "    # network interpolation\n",
        "    for i, var in enumerate(model.trainable_variables):\n",
        "        var.assign((1 - ALPHA) * vars_psnr[i] + ALPHA * vars_edsr[i])\n",
        "\n",
        "    model.save(SAVE_MODEL_PATH)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbbvgasNgDT-"
      },
      "outputs": [],
      "source": [
        "#demo.py (esrgan evaluate)\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "# from modules.esrgan import rrdb_net\n",
        "# from modules.utils import read_image, scale_image_0_1_range, tensor2img\n",
        "# from modules.utils import save_image_grid\n",
        "\n",
        "\n",
        "\n",
        "SCALE = 4\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "\n",
        "FROM_CHECKPOINT = True\n",
        "#MODEL_PATH = \"./saved/models/psnr.h5\"\n",
        "MODEL_PATH = \"./saved/models/esrgan.h5\"\n",
        "#CHECKPOINT_PATH = \"./saved/checkpoints/psnr\"\n",
        "CHECKPOINT_PATH = \"./saved/checkpoints/esrgan\"\n",
        "\n",
        "IMG_DIR = \"./images/input\"  # Path to the directory containing LR images\n",
        "GT_DIR = \"./images/ground_truth\"  # Path to the directory containing ground truth HR images (optional)\n",
        "SAVE_DIR = \"./images/results\"  # Directory to save the upscaled images\n",
        "\n",
        "Path(SAVE_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def main():\n",
        "\n",
        "    model = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(model=model)\n",
        "\n",
        "    if tf.train.latest_checkpoint(CHECKPOINT_PATH) and FROM_CHECKPOINT:\n",
        "            status = checkpoint.restore(tf.train.latest_checkpoint(CHECKPOINT_PATH))\n",
        "            status.expect_partial()  # Add this line to suppress warnings\n",
        "            print(\"[*] load ckpt from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH)))\n",
        "    else:\n",
        "        if os.path.isfile(MODEL_PATH):\n",
        "            h5_model = load_model(MODEL_PATH, custom_objects={'tf': tf})\n",
        "            weights = h5_model.get_weights()\n",
        "            model.set_weights(weights)\n",
        "            print(\"[*] load model weights from {}.\".format(\n",
        "            MODEL_PATH))\n",
        "        else:\n",
        "            print(\"[*] Cannot find ckpt or h5 model file.\")\n",
        "            exit()\n",
        "\n",
        "    if os.path.isdir(IMG_DIR):  # Check if it's a directory\n",
        "        for img_path in glob.glob(os.path.join(IMG_DIR, \"*.png\")):  # Assuming PNG images\n",
        "            # Extract filename without extension\n",
        "            filename = os.path.splitext(os.path.basename(img_path))[0]\n",
        "\n",
        "             # Load LR image\n",
        "            lr_image = read_image(img_path)\n",
        "            lr_image = scale_image_0_1_range(lr_image)\n",
        "            lr_image = tf.expand_dims(lr_image, axis=0)\n",
        "\n",
        "            base_filename = filename[2:]\n",
        "\n",
        "            # Load ground truth HR image (if available)\n",
        "            hr_filename = f\"hr{base_filename}.png\"  # Add \"hr\" prefix and extension\n",
        "            hr_img_path = os.path.join(GT_DIR, hr_filename)\n",
        "            if os.path.exists(hr_img_path):\n",
        "                hr_image = read_image(hr_img_path)\n",
        "            else:\n",
        "                hr_image = None\n",
        "\n",
        "            # Generate HR image\n",
        "            generated_hr = model(lr_image)\n",
        "            generated_hr_image = tensor2img(generated_hr)\n",
        "            unscale_lr_image = tensor2img(lr_image)\n",
        "\n",
        "            # Calculate metrics (if ground truth is available)\n",
        "            if hr_image is not None:\n",
        "                psnr = calculate_psnr(hr_image, generated_hr_image)\n",
        "                ssim = calculate_ssim(hr_image, generated_hr_image)\n",
        "                print(f\"[***] Image: {filename}, PSNR: {psnr}, SSIM: {ssim}\")\n",
        "\n",
        "            # Save image grid with LR, generated HR, and optionally ground truth\n",
        "            save_path = os.path.join(SAVE_DIR, f\"{filename}_upscaled.png\")\n",
        "            save_image_grid(unscale_lr_image, generated_hr_image, hr_image, save_path=save_path)\n",
        "\n",
        "    else:\n",
        "        print(f\"[!] Invalid image directory: {IMG_DIR}\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IWMT3VRzwNn"
      },
      "outputs": [],
      "source": [
        "#test.py (interp_esr)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "# from modules.esrgan import rrdb_net\n",
        "# from modules.utils import create_lr_hr_pair, scale_image_0_1_range, tensor2img\n",
        "# from modules.utils import save_image_grid\n",
        "# from modules.metrics import calculate_psnr, calculate_ssim\n",
        "\n",
        "\n",
        "SCALE = 4\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "\n",
        "FROM_CHECKPOINT = False\n",
        "#MODEL_PATH = \"./saved/models/psnr.h5\"\n",
        "# MODEL_PATH = \"./saved/models/esrgan.h5\"\n",
        "MODEL_PATH = \"./saved/models/interp_esr.h5\"\n",
        "#CHECKPOINT_PATH = \"./saved/checkpoints/psnr\"\n",
        "CHECKPOINT_PATH = \"./saved/checkpoints/esrgan\"\n",
        "\n",
        "IMG_DIR = \"./images/input\"  # Path to the directory containing LR images\n",
        "GT_DIR = \"./images/ground_truth\"  # Path to the directory containing ground truth HR images\n",
        "SAVE_DIR = \"./images/results\"  # Directory to save the upscaled images\n",
        "\n",
        "Path(SAVE_IMG_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def main():\n",
        "\n",
        "    model = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(model=model)\n",
        "    if tf.train.latest_checkpoint(CHECKPOINT_PATH) and FROM_CHECKPOINT:\n",
        "        checkpoint.restore(tf.train.latest_checkpoint(CHECKPOINT_PATH))\n",
        "        print(\"[*] load ckpt from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH)))\n",
        "    else:\n",
        "        if os.path.isfile(MODEL_PATH):\n",
        "            h5_model = load_model(MODEL_PATH, custom_objects={'tf': tf})\n",
        "            weights = h5_model.get_weights()\n",
        "            model.set_weights(weights)\n",
        "            print(\"[*] load model weights from {}.\".format(\n",
        "            MODEL_PATH))\n",
        "        else:\n",
        "            print(\"[*] Cannot find ckpt or h5 model file.\")\n",
        "            exit()\n",
        "\n",
        "    if os.path.isdir(IMG_DIR):  # Check if it's a directory\n",
        "        for img_path in glob.glob(os.path.join(IMG_DIR, \"*.png\")):  # Assuming PNG images\n",
        "            # Extract filename without extension\n",
        "            filename = os.path.splitext(os.path.basename(img_path))[0]\n",
        "\n",
        "            # Load LR image\n",
        "            lr_image = read_image(img_path)\n",
        "            lr_image = scale_image_0_1_range(lr_image)\n",
        "            lr_image = tf.expand_dims(lr_image, axis=0)\n",
        "\n",
        "            base_filename = filename[2:]\n",
        "\n",
        "            # Load ground truth HR image\n",
        "            hr_filename = f\"hr{base_filename}.png\"  # Add \"hr\" prefix and extension\n",
        "            hr_img_path = os.path.join(GT_DIR, hr_filename)\n",
        "            hr_image = read_image(hr_img_path)\n",
        "\n",
        "\n",
        "            # Generate HR image\n",
        "            generated_hr = model(lr_image)\n",
        "            generated_hr_image = tensor2img(generated_hr)\n",
        "            unscale_lr_image = tensor2img(lr_image)\n",
        "\n",
        "            # Calculate metrics\n",
        "            psnr = calculate_psnr(hr_image, generated_hr_image)\n",
        "            ssim = calculate_ssim(hr_image, generated_hr_image)\n",
        "            print(f\"[***] Image: {filename}, PSNR: {psnr}, SSIM: {ssim}\")\n",
        "\n",
        "            # Save image grid\n",
        "            save_path = os.path.join(SAVE_DIR, f\"{filename}_upscaled.png\")\n",
        "            save_image_grid(unscale_lr_image, generated_hr_image,  hr_image)\n",
        "\n",
        "    else:\n",
        "        print(f\"[!] Invalid image directories: {IMG_DIR}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxe8GnZAXOix"
      },
      "outputs": [],
      "source": [
        "!pip install zipfile\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "def zip_folder(folder_path, output_path):\n",
        "    \"\"\"Zip the contents of an entire folder (with that folder included\n",
        "    in the archive). Empty subfolders will be included in the archive\n",
        "    as well.\n",
        "    \"\"\"\n",
        "    parent_folder = os.path.dirname(folder_path)\n",
        "    # Retrieve the paths of the folder contents.\n",
        "    contents = os.walk(folder_path)\n",
        "    try:\n",
        "        zip_file = zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED)\n",
        "        for root, folders, files in contents:\n",
        "            # Include all subfolders, including empty ones.\n",
        "            for folder_name in folders:\n",
        "                absolute_path = os.path.join(root, folder_name)\n",
        "                relative_path = absolute_path.replace(parent_folder + '/', '')\n",
        "                print(\"Adding {} to archive.\".format(absolute_path))\n",
        "                zip_file.write(absolute_path, relative_path)\n",
        "            for file_name in files:\n",
        "                absolute_path = os.path.join(root, file_name)\n",
        "                relative_path = absolute_path.replace(parent_folder + '/', '')\n",
        "                print(\"Adding {} to archive.\".format(absolute_path))\n",
        "                zip_file.write(absolute_path, relative_path)\n",
        "        print(\"'{0}' created successfully.\".format(output_path))\n",
        "    except IOError as message:\n",
        "        print(message)\n",
        "        sys.exit(1)\n",
        "    except OSError as message:\n",
        "        print(message)\n",
        "        sys.exit(1)\n",
        "    finally:\n",
        "        zip_file.close()\n",
        "\n",
        "zip_folder(\"saved\", \"saved.zip\")\n",
        "\n",
        "files.download(\"saved.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIwmGBMy8dIt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2_jGTegXYy7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}