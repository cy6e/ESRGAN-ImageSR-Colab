{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagaditya39/ESRGAN-ImageSR-Colab/blob/main/gan2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ujiPn8qYD3m",
        "outputId": "74f672cf-ba98-440e-f7e5-fe1caf62af27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Collecting appdirs>=1.4.3 (from wandb)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: appdirs, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-2.0.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HflivmcCJQhl"
      },
      "outputs": [],
      "source": [
        "#utils.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "def read_image(img_path):\n",
        "    base=os.path.basename(img_path)\n",
        "    ext = os.path.splitext(base)[1]\n",
        "    assert ext in ['.png', '.jpg', '.jpeg', '.JPEG']\n",
        "    image = tf.io.read_file(img_path)\n",
        "    if ext == '.png':\n",
        "        image = tf.image.decode_png(image, channels=3)\n",
        "    else:\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "    return image\n",
        "\n",
        "# def create_lr_hr_pair(img_path, scale):\n",
        "#     image = read_image(img_path)\n",
        "#     lr_height, lr_width = image.shape[0] // scale, image.shape[1] // scale\n",
        "#     hr_height, hr_width = lr_height * scale, lr_width * scale\n",
        "#     hr_image = image[:hr_height, :hr_width, :]\n",
        "#     lr_shape = [lr_height, lr_width]\n",
        "#     lr_image = tf.image.resize(hr_image, lr_shape, method=tf.image.ResizeMethod.BICUBIC)\n",
        "\n",
        "#     return lr_image, hr_image\n",
        "\n",
        "def scale_image_0_1_range(image):\n",
        "    image = image / 255\n",
        "    red_max = tf.reduce_max(image, axis=None)\n",
        "    red_min = tf.reduce_min(image, axis=None)\n",
        "    if red_max > 1 or red_min < 0:\n",
        "        image = tf.clip_by_value(\n",
        "            image, 0, 1, name=None\n",
        "        )\n",
        "    return image\n",
        "\n",
        "\n",
        "# def unscale_image_0_255_range(image):\n",
        "#     image = image * 255\n",
        "#     red_max = tf.reduce_max(image, axis=None)\n",
        "#     red_min = tf.reduce_min(image, axis=None)\n",
        "#     if red_max > 255 or red_min < 0:\n",
        "#         image = tf.clip_by_value(\n",
        "#             image, 0, 255, name=None\n",
        "#         )\n",
        "#     return image\n",
        "\n",
        "def tensor2img(tensor):\n",
        "    return (np.squeeze(tensor.numpy()).clip(0, 1) * 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "def save_image_grid(lr, hr, ref=None, save_path=None):\n",
        "    lr_title = \"lr: {}\".format(lr.shape)\n",
        "    hr_title = \"hr: {}\".format(hr.shape)\n",
        "    images = [lr, hr]\n",
        "    titles = [lr_title, hr_title]\n",
        "    if ref is not None:\n",
        "        ref_title = \"ref: {}\".format(ref.shape)\n",
        "        images += [ref]\n",
        "        titles += [ref_title]\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
        "    else:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "\n",
        "    for i, (img, title) in enumerate(zip(images, titles)):\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(title, fontsize = 20)\n",
        "        axes[i].axis('off')\n",
        "    # fig.savefig(save_path, bbox_inches = 'tight', pad_inches = 0.25)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "#didnt work\n",
        "\n",
        "def load_models_for_epoch(base_path, epoch_num, is_gan=False):\n",
        "    # \"\"\"Loads model(s) for a specific epoch.\"\"\"\n",
        "    model_path = f\"{base_path}_epoch_{epoch_num}.h5\"\n",
        "    if not Path(model_path).exists():\n",
        "        raise ValueError(f\"Model for epoch {epoch_num} not found at {model_path}\")\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    if is_gan:  # Load discriminator as well for GAN training\n",
        "        disc_path = f\"{base_path.replace('esrgan', 'disc_gan')}_epoch_{epoch_num}.h5\"\n",
        "        discriminator = tf.keras.models.load_model(disc_path)\n",
        "        return model, discriminator\n",
        "    return model\n",
        "\n",
        "def get_available_epochs(base_path):\n",
        "    # \"\"\"Returns a list of available epoch numbers from saved model filenames.\"\"\"\n",
        "    model_dir = Path(base_path).parent\n",
        "    pattern = re.compile(r\"_epoch_(\\d+)\\.h5\")\n",
        "    epochs = []\n",
        "    for filename in model_dir.glob(\"*.h5\"):\n",
        "        match = pattern.search(filename.name)\n",
        "        if match:\n",
        "            epochs.append(int(match.group(1)))\n",
        "    return sorted(epochs)\n",
        "\n",
        "\n",
        "def download_saved_folder(saved_folder_path, download_location=\"local\", drive_folder_id=None):\n",
        "    # \"\"\"Downloads the saved folder to the specified location.\"\"\"\n",
        "\n",
        "    if download_location == \"local\":\n",
        "        # Download to local machine (assuming you are using Colab)\n",
        "        shutil.make_archive(saved_folder_path, 'zip', saved_folder_path)\n",
        "        zipped_filename = saved_folder_path + \".zip\"\n",
        "        files.download(zipped_filename)\n",
        "\n",
        "    elif download_location == \"drive\" and drive_folder_id:\n",
        "        # Download to Google Drive (Colab only)\n",
        "        drive.mount('/content/gdrive')  # Mount Google Drive\n",
        "        destination_path = \"/content/gdrive/My Drive/\" + drive_folder_id\n",
        "        shutil.make_archive(saved_folder_path, 'zip', saved_folder_path)\n",
        "        zipped_filename = saved_folder_path + \".zip\"\n",
        "        shutil.move(zipped_filename, destination_path)\n",
        "        print(f\"Saved folder uploaded to Google Drive folder ID: {drive_folder_id}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"[!] Invalid download location or missing Drive folder ID.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "quRvGoGgJJQI"
      },
      "outputs": [],
      "source": [
        "#metrics.py\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def calculate_psnr(img1, img2):\n",
        "    #img1 and img2 have range [0, 255]\n",
        "    #psnr = 20 * np.log10(255.0 / np.sqrt(np.mean((img1 - img2)**2)))\n",
        "    return tf.image.psnr(img1, img2, max_val=255)\n",
        "\n",
        "def calculate_ssim(hr, generated_hr):\n",
        "    #hr and generated_hr have range [0, 255]\n",
        "    return tf.image.ssim(hr, generated_hr, max_val=255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "WsyXyCB6I-v_",
        "outputId": "a31c4ae3-e77a-4eae-aa72-2ec713a97581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-6c03de2b82ca>:60: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels(labels)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# lr_scheduler.py\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def MultiStepLR(initial_learning_rate, lr_steps, lr_rate, name='MultiStepLR'):\n",
        "    # \"\"\"Multi-steps learning rate scheduler.\"\"\"\n",
        "    lr_steps_value = [initial_learning_rate]\n",
        "    for _ in range(len(lr_steps)):\n",
        "        lr_steps_value.append(lr_steps_value[-1] * lr_rate)\n",
        "    return tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "        boundaries=lr_steps, values=lr_steps_value)\n",
        "\n",
        "\n",
        "# def CosineAnnealingLR_Restart(initial_learning_rate, t_period, lr_min):\n",
        "#     # \"\"\"Cosine annealing learning rate scheduler with restart.\"\"\"\n",
        "#     return tf.keras.experimental.CosineDecayRestarts(\n",
        "#         initial_learning_rate=initial_learning_rate,\n",
        "#         first_decay_steps=t_period, t_mul=1.0, m_mul=1.0,\n",
        "#         alpha=lr_min / initial_learning_rate)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # pretrain PSNR lr scheduler\n",
        "    lr_scheduler = MultiStepLR(2e-4, [1000, 3000, 5000, 7000], 0.5)\n",
        "\n",
        "    # ESRGAN lr scheduler\n",
        "    # lr_scheduler = MultiStepLR(1e-4, [50000, 100000, 200000, 300000], 0.5)\n",
        "\n",
        "    # Cosine Annealing lr scheduler\n",
        "    # lr_scheduler = CosineAnnealingLR_Restart(2e-4, 250000, 1e-7)\n",
        "\n",
        "\n",
        "    # Draw figure\n",
        "\n",
        "    N_iter = 8000\n",
        "    step_list = list(range(0, N_iter, 100))\n",
        "    lr_list = []\n",
        "    for i in step_list:\n",
        "        current_lr = lr_scheduler(i).numpy()\n",
        "        lr_list.append(current_lr)\n",
        "\n",
        "    import matplotlib as mpl\n",
        "    from matplotlib import pyplot as plt\n",
        "    import matplotlib.ticker as mtick\n",
        "    mpl.style.use('default')\n",
        "    import seaborn\n",
        "    seaborn.set(style='whitegrid')\n",
        "    seaborn.set_context('paper')\n",
        "\n",
        "    plt.figure(1)\n",
        "    plt.subplot(111)\n",
        "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0, 0))\n",
        "    plt.title('Title', fontsize=16, color='k')\n",
        "    plt.plot(step_list, lr_list, linewidth=1.5, label='learning rate scheme')\n",
        "    legend = plt.legend(loc='upper right', shadow=False)\n",
        "    ax = plt.gca()\n",
        "    labels = ax.get_xticks().tolist()\n",
        "    for k, v in enumerate(labels):\n",
        "        labels[k] = str(int(v / 1000)) + 'K'\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.1e'))\n",
        "\n",
        "    ax.set_ylabel('Learning rate')\n",
        "    ax.set_xlabel('Iteration')\n",
        "    fig = plt.gcf()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yuxTzvTsHPrO"
      },
      "outputs": [],
      "source": [
        "# esrgan.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, PReLU, Dropout, Dense\n",
        "from tensorflow.keras.layers import BatchNormalization, Concatenate, Lambda, Add\n",
        "\n",
        "\n",
        "def residual_dense_block(input, filters):\n",
        "    x1 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(input)\n",
        "    x1 = LeakyReLU(0.2)(x1)\n",
        "    x1 = Concatenate()([input, x1])\n",
        "\n",
        "    x2 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(x1)\n",
        "    x2 = LeakyReLU(0.2)(x2)\n",
        "    x2 = Concatenate()([input, x1, x2])\n",
        "\n",
        "    x3 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(x2)\n",
        "    x3 = LeakyReLU(0.2)(x3)\n",
        "    x3 = Concatenate()([input, x1, x2, x3])\n",
        "\n",
        "    x4 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(x3)\n",
        "    x4 = LeakyReLU(0.2)(x4)\n",
        "    x4 = Concatenate()([input, x1, x2, x3, x4])\n",
        "\n",
        "    x5 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(x4)\n",
        "    x5 = Lambda(lambda x: x * 0.2)(x5)\n",
        "    x = Add()([x5, input])\n",
        "\n",
        "    return x\n",
        "\n",
        "def rrdb(input, filters):\n",
        "    x = residual_dense_block(input, filters)\n",
        "    x = residual_dense_block(x, filters)\n",
        "    x = residual_dense_block(x, filters)\n",
        "    x = Lambda(lambda x: x * 0.2)(x)\n",
        "    out = Add()([x, input])\n",
        "    return out\n",
        "\n",
        "def sub_pixel_conv2d(scale_factor=2, **kwargs):\n",
        "    return Lambda(lambda  x: tf.nn.depth_to_space(x, scale_factor), **kwargs)\n",
        "\n",
        "def upsample(input_tensor, filters, scale_factor=2):\n",
        "    x = Conv2D(filters=filters*4, kernel_size=3, strides=1, padding='same')(input_tensor)\n",
        "    x = sub_pixel_conv2d(scale_factor=scale_factor)(x)\n",
        "    x = PReLU(shared_axes=[1,2])(x)\n",
        "    return x\n",
        "\n",
        "def rrdb_net(input_shape=(None, None, 3), filters=64, scale_factor=4, name='RRDB_model'):\n",
        "    lr_image = Input(shape=input_shape, name='input')\n",
        "\n",
        "    #Pre-residual\n",
        "    x_start = Conv2D(filters, kernel_size=3, strides=1, padding='same')(lr_image)\n",
        "    x_start = LeakyReLU(0.2)(x_start)\n",
        "\n",
        "    #Residual block\n",
        "    x = rrdb(x_start, filters)\n",
        "\n",
        "    #Post Residual block\n",
        "    x = Conv2D(filters,  kernel_size=3, strides=1, padding='same')(x)\n",
        "    x = Lambda(lambda x: x * 0.2)(x)\n",
        "    x = Add()([x, x_start])\n",
        "\n",
        "    #Upsampling\n",
        "    x = upsample(x, filters, scale_factor)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size=3, strides=1, padding='same')(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    out = Conv2D(filters=3, kernel_size=3, strides=1, padding='same')(x)\n",
        "\n",
        "    return Model(inputs=lr_image, outputs=out, name=name)\n",
        "\n",
        "def conv2d_block(input, filters, strides=1, bn=True):\n",
        "    x = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(input)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    if bn:\n",
        "        x = BatchNormalization(momentum=0.8)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def discriminator_net(input_shape=(None, None, 3), filters=64, name='Discriminator'):\n",
        "    img = Input(shape=input_shape)\n",
        "\n",
        "    x = conv2d_block(img, filters, bn=False)\n",
        "    x = conv2d_block(x, filters, strides=2)\n",
        "    x = conv2d_block(x, filters*2)\n",
        "    x = conv2d_block(x, filters*2, strides=2)\n",
        "    x = conv2d_block(x, filters*4)\n",
        "    x = conv2d_block(x, filters*4, strides=2)\n",
        "    x = conv2d_block(x, filters*8)\n",
        "    x = conv2d_block(x, filters*8, strides=2)\n",
        "    x = Dense(filters*16)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(1)(x)\n",
        "\n",
        "    return Model(inputs=img, outputs=x, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PkuI8-mnHqVP"
      },
      "outputs": [],
      "source": [
        "# losses.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input, VGG19\n",
        "\n",
        "def get_pixel_loss(criterion='l1'):\n",
        "    \"\"\"pixel loss\"\"\"\n",
        "    if criterion == 'l1':\n",
        "        return tf.keras.losses.MeanAbsoluteError()\n",
        "    elif criterion == 'l2':\n",
        "        return tf.keras.losses.MeanSquaredError()\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Loss type {} is not recognized.'.format(criterion))\n",
        "\n",
        "def get_content_loss(criterion='l1', output_layer=54, before_act=True):\n",
        "    \"\"\"content loss\"\"\"\n",
        "    if criterion == 'l1':\n",
        "        loss_func = tf.keras.losses.MeanAbsoluteError()\n",
        "    elif criterion == 'l2':\n",
        "        loss_func = tf.keras.losses.MeanSquaredError()\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Loss type {} is not recognized.'.format(criterion))\n",
        "    vgg = VGG19(input_shape=(None, None, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "    if output_layer == 22:  # Low level feature\n",
        "        pick_layer = 5\n",
        "    elif output_layer == 54:  # Hight level feature\n",
        "        pick_layer = 20\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'VGG output layer {} is not recognized.'.format(criterion))\n",
        "\n",
        "    if before_act:\n",
        "        vgg.layers[pick_layer].activation = None\n",
        "\n",
        "    fea_extrator = tf.keras.Model(vgg.input, vgg.layers[pick_layer].output)\n",
        "    fea_extrator.trainable = False\n",
        "\n",
        "    @tf.function\n",
        "    def content_loss(real_hr, fake_hr):\n",
        "        # the input scale range is [0, 1] (vgg is [0, 255]).\n",
        "        # 12.75 is rescale factor for vgg featuremaps.\n",
        "        preprocess_fake_hr = preprocess_input(fake_hr * 255.) / 12.75\n",
        "        preprocess_real_hr = preprocess_input(real_hr * 255.) / 12.75\n",
        "        fake_hr_features = fea_extrator(preprocess_fake_hr)\n",
        "        real_hr_features = fea_extrator(preprocess_real_hr)\n",
        "\n",
        "        return loss_func(real_hr_features, fake_hr_features)\n",
        "\n",
        "    return content_loss\n",
        "\n",
        "def get_discriminator_loss(gan_type='ragan'):\n",
        "    \"\"\"discriminator loss\"\"\"\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    sigma = tf.sigmoid\n",
        "\n",
        "    def discriminator_loss_ragan(real_discriminator_logits, fake_discriminator_logits):\n",
        "        real_logits = sigma(real_discriminator_logits - tf.reduce_mean(fake_discriminator_logits))\n",
        "        fake_logits = sigma(fake_discriminator_logits - tf.reduce_mean(real_discriminator_logits))\n",
        "        return 0.5 * (\n",
        "            cross_entropy(tf.ones_like(real_logits), real_logits) +\n",
        "            cross_entropy(tf.zeros_like(fake_logits), fake_logits))\n",
        "\n",
        "    def discriminator_loss(real_discriminator_logits, fake_discriminator_logits):\n",
        "        real_loss = cross_entropy(tf.ones_like(real_discriminator_logits), sigma(real_discriminator_logits))\n",
        "        fake_loss = cross_entropy(tf.zeros_like(fake_discriminator_logits), sigma(fake_discriminator_logits))\n",
        "        return real_loss + fake_loss\n",
        "\n",
        "    if gan_type == 'ragan':\n",
        "        return discriminator_loss_ragan\n",
        "    elif gan_type == 'gan':\n",
        "        return discriminator_loss\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Discriminator loss type {} is not recognized.'.format(gan_type))\n",
        "\n",
        "def get_generator_loss(gan_type='ragan'):\n",
        "    \"\"\"generator loss\"\"\"\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    sigma = tf.sigmoid\n",
        "\n",
        "    def generator_loss_ragan(real_discriminator_logits, fake_discriminator_logits):\n",
        "        real_logits = sigma(real_discriminator_logits - tf.reduce_mean(fake_discriminator_logits))\n",
        "        fake_logits = sigma(fake_discriminator_logits - tf.reduce_mean(real_discriminator_logits))\n",
        "        return 0.5 * (\n",
        "            cross_entropy(tf.ones_like(fake_logits), fake_logits) +\n",
        "            cross_entropy(tf.zeros_like(real_logits), real_logits))\n",
        "\n",
        "    def generator_loss(real_discriminator_logits, fake_discriminator_logits):\n",
        "        return cross_entropy(tf.ones_like(fake_discriminator_logits), sigma(fake_discriminator_logits))\n",
        "\n",
        "    if gan_type == 'ragan':\n",
        "        return generator_loss_ragan\n",
        "    elif gan_type == 'gan':\n",
        "        return generator_loss\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Generator loss type {} is not recognized.'.format(gan_type))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UzYZSzR6HeQz"
      },
      "outputs": [],
      "source": [
        "# dataset.py\n",
        "\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "DATA_PATH = \"/content/HR\"\n",
        "\n",
        "def scale_input_image(img):\n",
        "    #img/ 255.\n",
        "    return tf.image.convert_image_dtype(img, dtype=tf.float32)\n",
        "\n",
        "# def unscale_output_image(img):\n",
        "#     #img * 255\n",
        "#     return tf.image.convert_image_dtype(img, dtype=tf.uint8, saturate=True)\n",
        "\n",
        "def random_crop_and_flip(img, random_crop_size):\n",
        "    assert img.shape[2] == 3\n",
        "    height, width = img.shape[0], img.shape[1]\n",
        "    dy, dx = random_crop_size\n",
        "    x = np.random.randint(0, width - dx + 1)\n",
        "    y = np.random.randint(0, height - dy + 1)\n",
        "    image = img[y:(y+dy), x:(x+dx), :]\n",
        "    flip_case = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
        "    if(tf.equal(flip_case, 0)):\n",
        "        image = tf.image.flip_left_right(image)\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_image(image_path, hr_height, hr_width, crop_per_image, ext):\n",
        "    assert ext in ['.png', '.jpg', '.jpeg', '.JPEG']\n",
        "    image = tf.io.read_file(image_path)\n",
        "    if ext == '.png':\n",
        "        image = tf.image.decode_png(image, channels=3)\n",
        "    else:\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "    image = scale_input_image(image)\n",
        "    cropped_images = [ random_crop_and_flip(image, (hr_height, hr_width)) for _ in range(crop_per_image)]\n",
        "\n",
        "    return cropped_images\n",
        "\n",
        "\n",
        "\n",
        "def load_dataset(hr_height, hr_width, scale, crop_per_image=20, ext='.png'):\n",
        "    image_paths = []\n",
        "    for root, _, files in os.walk(DATA_PATH):\n",
        "        for file in files:\n",
        "            if f'{ext}' in file:\n",
        "                image_paths.append(os.path.join(root, file))\n",
        "\n",
        "    random.shuffle(image_paths)\n",
        "    images = []\n",
        "    for img_path in image_paths:\n",
        "        images += load_and_preprocess_image(img_path, hr_height, hr_width, crop_per_image, ext)\n",
        "\n",
        "    random.shuffle(images)\n",
        "    hr_images = []\n",
        "    lr_images = []\n",
        "    for img in images:\n",
        "        hr_image = img\n",
        "        lr_shape = [int(hr_image.shape[0]/scale), int(hr_image.shape[1]/scale)]\n",
        "        lr_image = tf.image.resize(hr_image, lr_shape, method=tf.image.ResizeMethod.BICUBIC)\n",
        "        #lr_image = lr_image / 255\n",
        "        lr_image = tf.clip_by_value(\n",
        "        lr_image, 0, 1, name=None\n",
        "        )\n",
        "        hr_images.append(hr_image)\n",
        "        lr_images.append(lr_image)\n",
        "\n",
        "    lr_dataset = tf.data.Dataset.from_tensor_slices(lr_images)\n",
        "    hr_dataset = tf.data.Dataset.from_tensor_slices(hr_images)\n",
        "\n",
        "    dataset = tf.data.Dataset.zip((lr_dataset, hr_dataset))\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "PXO_hLvkJw3E",
        "outputId": "6fd50b8f-ec25-4db0-ad9c-1db9a7912428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madityanag1305\u001b[0m (\u001b[33mpersonal-nag\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] load ckpt from ./saved/checkpoints/psnr/ckpt-4000 at step 4000.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240430_140354-psnr-training</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/personal-nag/check/runs/psnr-training' target=\"_blank\">psnr-training</a></strong> to <a href='https://wandb.ai/personal-nag/check' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/personal-nag/check' target=\"_blank\">https://wandb.ai/personal-nag/check</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/personal-nag/check/runs/psnr-training' target=\"_blank\">https://wandb.ai/personal-nag/check/runs/psnr-training</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.0089, lr=5.0e-05:  25%|▎| 1000/4000 [23:14</usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[*] save ckpt file at ./saved/checkpoints/psnr/ckpt-5000\n",
            "\n",
            "[*] save model at ./saved/models/psnr/model-5000.h5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_64a0b48f-e500-42c8-b145-40d0f187e7a5\", \"saved.zip\", 130594180)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.0084, lr=2.5e-05:  50%|▌| 2000/4000 [46:12<WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[*] save ckpt file at ./saved/checkpoints/psnr/ckpt-6000\n",
            "\n",
            "[*] save model at ./saved/models/psnr/model-6000.h5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bb3c8dea-59e6-4883-a7d4-0d40362e419f\", \"saved.zip\", 143934349)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.0076, lr=2.5e-05:  75%|▊| 3000/4000 [1:09:1WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[*] save ckpt file at ./saved/checkpoints/psnr/ckpt-7000\n",
            "\n",
            "[*] save model at ./saved/models/psnr/model-7000.h5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5415f317-7870-444c-a7ab-6a59b26bc4a6\", \"saved.zip\", 157324608)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.0083, lr=1.2e-05: 100%|█| 4000/4000 [1:31:5WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[*] save ckpt file at ./saved/checkpoints/psnr/ckpt-8000\n",
            "\n",
            "[*] save model at ./saved/models/psnr/model-8000.h5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a3ed5b35-7179-4e4a-a5ba-bef1dba073ca\", \"saved.zip\", 170696455)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "loss=0.0083, lr=1.2e-05: 100%|█| 4000/4000 [1:32:0\n"
          ]
        }
      ],
      "source": [
        "#train_psnr.py\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "# from modules.esrgan import rrdb_net\n",
        "# from modules.lr_scheduler import MultiStepLR\n",
        "# from modules.data import load_dataset\n",
        "# from modules.losses import get_pixel_loss\n",
        "\n",
        "HAS_WANDB_ACCOUNT = True\n",
        "PROJECT = 'check'\n",
        "import wandb\n",
        "if not HAS_WANDB_ACCOUNT:\n",
        "    wandb.login(anonymous='allow')\n",
        "else:\n",
        "    wandb.login(key='api_key')\n",
        "\n",
        "INITIAL_LR = 2e-4\n",
        "LR_RATE = 0.5\n",
        "# LR_STEPS = [2000, 4000, 6000, 8000]\n",
        "LR_STEPS = [1000, 3000, 5000, 7000]\n",
        "ADAM_BETA1_G = 0.9\n",
        "ADAM_BETA2_G = 0.99\n",
        "W_PIXEL = 1.0\n",
        "PIXEL_CRITERION = 'l1'\n",
        "\n",
        "HR_HEIGHT = 128\n",
        "HR_WIDTH = 128\n",
        "SCALE = 4\n",
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 10240\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "\n",
        "NUM_ITER = 8000\n",
        "SAVE_STEPS = 1000\n",
        "\n",
        "\n",
        "CHECK_POINT_PATH =  \"./saved/checkpoints/psnr\"\n",
        "Path(CHECK_POINT_PATH).mkdir(parents=True, exist_ok=True)\n",
        "SAVE_MODEL_PATH = \"./saved/models/psnr\"\n",
        "Path(SAVE_MODEL_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def main():\n",
        "\n",
        "    # num_epochs = 0\n",
        "\n",
        "\n",
        "    dataset = load_dataset(HR_HEIGHT, HR_WIDTH, SCALE)\n",
        "    # leng= len(dataset)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    model = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "    learning_rate = MultiStepLR(INITIAL_LR, LR_STEPS, LR_RATE)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate,\n",
        "                                        beta_1= ADAM_BETA1_G,\n",
        "                                        beta_2= ADAM_BETA2_G\n",
        "                                        )\n",
        "    pixel_loss = get_pixel_loss(PIXEL_CRITERION)\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(step=tf.Variable(0, name='step'),\n",
        "                                     optimizer=optimizer,\n",
        "                                     model=model)\n",
        "    manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
        "                                         directory=CHECK_POINT_PATH,\n",
        "                                         max_to_keep=3)\n",
        "    if manager.latest_checkpoint:\n",
        "        checkpoint.restore(manager.latest_checkpoint)\n",
        "        print('[*] load ckpt from {} at step {}.'.format(\n",
        "            manager.latest_checkpoint, checkpoint.step.numpy()))\n",
        "        # try:\n",
        "        #       model.load_weights(f\"{SAVE_MODEL_PATH}/model-{checkpoint.step.numpy()}.h5\")\n",
        "        #       print(f\"[*] Loaded model weights from step {checkpoint.step.numpy()}\")\n",
        "        # except (ValueError, tf.errors.NotFoundError):\n",
        "        #       print(\"[*] Saved model is not compatible with the current configuration. Training from scratch.\")\n",
        "        #       checkpoint.step.assign(0)\n",
        "    else:\n",
        "        print(\"[*] training from scratch.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(lr, hr):\n",
        "        with tf.GradientTape() as tape:\n",
        "            generated_hr = model(lr, training=True)\n",
        "            loss = W_PIXEL * pixel_loss(hr, generated_hr)\n",
        "\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    wandb_run_id = \"psnr-training\" #@param {type:\"string\"}\n",
        "    if HAS_WANDB_ACCOUNT:\n",
        "        wandb.init(entity='personal-nag', project=PROJECT, id=wandb_run_id)\n",
        "    else:\n",
        "        wandb.init(id=wandb_run_id)\n",
        "\n",
        "    remain_steps = max(NUM_ITER - checkpoint.step.numpy(), 0)\n",
        "    pbar = tqdm(total=remain_steps, ncols=50)\n",
        "\n",
        "\n",
        "    for lr, hr in dataset.take(remain_steps):\n",
        "        checkpoint.step.assign_add(1)\n",
        "        steps = checkpoint.step.numpy()\n",
        "        loss = train_step(lr, hr)\n",
        "        learning_rate = optimizer.lr.numpy()  # Get the learning rate value\n",
        "        wandb.log({\"steps\": steps, \"loss\": loss, \"learning_rate\": learning_rate})\n",
        "        pbar.set_description(\"loss={:.4f}, lr={:.1e}\".format(loss, learning_rate))\n",
        "        pbar.update()\n",
        "        # sys.stdout.flush()\n",
        "        if steps % SAVE_STEPS == 0:\n",
        "           manager.save(checkpoint_number=steps)\n",
        "           print(f\"\\n[*] save ckpt file at {manager.latest_checkpoint}\")\n",
        "           model.save(f\"{SAVE_MODEL_PATH}/model-{steps}.h5\")\n",
        "           print(f\"\\n[*] save model at {SAVE_MODEL_PATH}/model-{steps}.h5\")\n",
        "\n",
        "\n",
        "\n",
        "           download_saved_folder(saved_folder_path=\"saved\", download_location=\"local\")\n",
        "           # files.download(\"saved.zip\")\n",
        "\n",
        "    model.save(SAVE_MODEL_PATH)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGW4Vmv_Jz69"
      },
      "outputs": [],
      "source": [
        "# train_esrgan.py\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "# from modules.esrgan import rrdb_net, discriminator_net\n",
        "# from modules.lr_scheduler import MultiStepLR\n",
        "# from modules.data import load_dataset\n",
        "# from modules.losses import get_pixel_loss, get_content_loss\n",
        "# from modules.losses import get_discriminator_loss, get_generator_loss\n",
        "\n",
        "HAS_WANDB_ACCOUNT = True\n",
        "PROJECT = 'check'\n",
        "import wandb\n",
        "if not HAS_WANDB_ACCOUNT:\n",
        "    wandb.login(anonymous='allow')\n",
        "else:\n",
        "    wandb.login(key='api_key')\n",
        "\n",
        "INITIAL_LR_G = 1e-4\n",
        "INITIAL_LR_D = 1e-4\n",
        "LR_RATE = 0.5\n",
        "LR_STEPS = [500, 1000, 2000, 3000]\n",
        "ADAM_BETA1_G = 0.9\n",
        "ADAM_BETA2_G = 0.99\n",
        "ADAM_BETA1_D = 0.9\n",
        "ADAM_BETA2_D = 0.99\n",
        "\n",
        "PIXEL_CRITERION = 'l1'\n",
        "FEATURE_CRITERION = 'l2'\n",
        "GAN_TYPE = 'ragan'\n",
        "WEIGHT_PIXEL = 1e-2\n",
        "WEIGHT_FEATURE = 1.0\n",
        "WEIGHT_GAN = 5e-3\n",
        "\n",
        "HR_HEIGHT = 128\n",
        "HR_WIDTH = 128\n",
        "SCALE = 4\n",
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 10240\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "\n",
        "NUM_ITER = 4000\n",
        "SAVE_STEPS =  500\n",
        "\n",
        "PRETRAIN_PATH =  \"./saved/checkpoints/psnr\"\n",
        "CHECK_POINT_PATH =  \"./saved/checkpoints/esrgan\"\n",
        "Path(CHECK_POINT_PATH).mkdir(parents=True, exist_ok=True)\n",
        "SAVE_GAN_PATH = \"./saved/models/esrgan\"\n",
        "Path(SAVE_GAN_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "SAVE_DISC_PATH = \"./saved/models/disc_gan\"\n",
        "Path(SAVE_DISC_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    # num_epochs = 0\n",
        "\n",
        "    dataset = load_dataset(HR_HEIGHT, HR_WIDTH, SCALE)\n",
        "    # leng = len(dataset)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    generator = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "    discriminator = discriminator_net(input_shape=INPUT_SHAPE)\n",
        "\n",
        "    learning_rate_G = MultiStepLR(INITIAL_LR_G, LR_STEPS, LR_RATE)\n",
        "    learning_rate_D = MultiStepLR(INITIAL_LR_D, LR_STEPS, LR_RATE)\n",
        "    optimizer_G = tf.keras.optimizers.Adam(learning_rate= learning_rate_G,\n",
        "                                        beta_1= ADAM_BETA1_G,\n",
        "                                        beta_2= ADAM_BETA2_G\n",
        "                                        )\n",
        "    optimizer_D = tf.keras.optimizers.Adam(learning_rate= learning_rate_D,\n",
        "                                        beta_1= ADAM_BETA1_D,\n",
        "                                        beta_2= ADAM_BETA2_D\n",
        "                                        )\n",
        "\n",
        "    pixel_loss = get_pixel_loss(PIXEL_CRITERION)\n",
        "    feature_loss = get_content_loss(FEATURE_CRITERION)\n",
        "    generator_loss = get_generator_loss(GAN_TYPE)\n",
        "    discriminator_loss = get_discriminator_loss(GAN_TYPE)\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(step=tf.Variable(0, name='step'),\n",
        "                                     optimizer_G=optimizer_G,\n",
        "                                     optimizer_D=optimizer_D,\n",
        "                                     model=generator,\n",
        "                                     discriminator=discriminator)\n",
        "    manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
        "                                         directory=CHECK_POINT_PATH,\n",
        "                                         max_to_keep=3)\n",
        "    if manager.latest_checkpoint:\n",
        "        checkpoint.restore(manager.latest_checkpoint)\n",
        "        print('[*] load ckpt from {} at step {}.'.format(\n",
        "            manager.latest_checkpoint, checkpoint.step.numpy()))\n",
        "    # else:\n",
        "    #     if tf.train.latest_checkpoint(PRETRAIN_PATH):\n",
        "    #         checkpoint.restore(tf.train.latest_checkpoint(PRETRAIN_PATH))\n",
        "    #         checkpoint.step.assign(0)\n",
        "    #         print(\"[*] training from pretrain model {}.\".format(\n",
        "    #                 PRETRAIN_PATH ))\n",
        "    else:\n",
        "        print(\"[*] cannot find pretrain model {}.\".format(PRETRAIN_PATH))\n",
        "\n",
        "    # saved_checkpoints = [int(ckpt.split('-')[-1]) for ckpt in os.listdir(CHECK_POINT_PATH)]\n",
        "    # if saved_checkpoints:\n",
        "    #     latest_epoch = max(saved_checkpoints)\n",
        "    #     print(f\"Found saved checkpoints. Latest epoch: {latest_epoch}\")\n",
        "    #     print(\"Available checkpoints:\")\n",
        "    #     for epoch in sorted(saved_checkpoints):\n",
        "    #         print(f\"Epoch {epoch}\")\n",
        "    #     resume_epoch = int(input(\"Enter the epoch number to resume training from: \"))\n",
        "    #     checkpoint.restore(f\"{CHECK_POINT_PATH}/ckpt-{resume_epoch}\")\n",
        "    #     print(f\"Restored checkpoint from epoch {resume_epoch}\")\n",
        "    # else:\n",
        "    #     if tf.train.latest_checkpoint(PRETRAIN_PATH):\n",
        "    #         checkpoint.restore(tf.train.latest_checkpoint(PRETRAIN_PATH))\n",
        "    #         checkpoint.step.assign(0)\n",
        "    #         print(\"[*] training from pretrain model {}.\".format(\n",
        "    #                 PRETRAIN_PATH ))\n",
        "    #     else:\n",
        "    #         print(\"[*] cannot find pretrain model {}.\".format(\n",
        "    #             PRETRAIN_PATH))\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(lr, hr):\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            generated_hr = generator(lr, training=True)\n",
        "            real_logits = discriminator(hr, training=True)\n",
        "            fake_logits = discriminator(generated_hr, training=True)\n",
        "            losses_G = {}\n",
        "            losses_D = {}\n",
        "            losses_G['pixel'] = WEIGHT_PIXEL * pixel_loss(hr, generated_hr)\n",
        "            losses_G['feature'] = WEIGHT_FEATURE * feature_loss(hr, generated_hr)\n",
        "            losses_G['gan'] = WEIGHT_GAN * generator_loss(real_logits, fake_logits)\n",
        "            losses_D['disc'] = discriminator_loss(real_logits, fake_logits)\n",
        "            total_loss_G = tf.add_n([l for l in losses_G.values()])\n",
        "            total_loss_D = tf.add_n([l for l in losses_D.values()])\n",
        "\n",
        "\n",
        "        grads_G = tape.gradient(\n",
        "            total_loss_G, generator.trainable_variables)\n",
        "        grads_D = tape.gradient(\n",
        "            total_loss_D, discriminator.trainable_variables)\n",
        "        optimizer_G.apply_gradients(\n",
        "            zip(grads_G, generator.trainable_variables))\n",
        "        optimizer_D.apply_gradients(\n",
        "            zip(grads_D, discriminator.trainable_variables))\n",
        "\n",
        "        return total_loss_G, total_loss_D, losses_G, losses_D\n",
        "\n",
        "\n",
        "    wandb_run_id = \"esrgan-training\" #@param {type:\"string\"}\n",
        "    if HAS_WANDB_ACCOUNT:\n",
        "        wandb.init(entity='personal-nag', project=PROJECT, id=wandb_run_id)\n",
        "    else:\n",
        "        wandb.init(id=wandb_run_id)\n",
        "    remain_steps = max(NUM_ITER - checkpoint.step.numpy(), 0)\n",
        "    pbar = tqdm(total=remain_steps, ncols=50)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for lr, hr in dataset.take(remain_steps):\n",
        "        checkpoint.step.assign_add(1)\n",
        "        steps = checkpoint.step.numpy()\n",
        "        total_loss_G, total_loss_D, losses_G, losses_D = train_step(lr, hr)\n",
        "        learning_rate_G = optimizer_G.lr.numpy()\n",
        "        learning_rate_D = optimizer_D.lr.numpy()\n",
        "        wandb.log({**{\"steps\": steps},**losses_G, **losses_D,\n",
        "                    **{\"total_loss_G\": total_loss_G.numpy()},\n",
        "                    **{\"learning_rate_G\": learning_rate_G,\n",
        "                    \"learning_rate_D\": learning_rate_D}})\n",
        "\n",
        "        pbar.set_description(\"loss_G={:.4f}, loss_D={:.4f}, lr_G={:.1e}, lr_D={:.1e}\".format(\n",
        "            total_loss_G.numpy(), total_loss_D.numpy(),\n",
        "            learning_rate_G, learning_rate_D))\n",
        "        pbar.update()\n",
        "        if steps % SAVE_STEPS == 0:\n",
        "            manager.save(checkpoint_number=steps)\n",
        "            print(f\"\\n[*] save ckpt file at {manager.latest_checkpoint}\")\n",
        "            generator.save(f\"{SAVE_GAN_PATH}/generator-{steps}.h5\")\n",
        "            discriminator.save(f\"{SAVE_DISC_PATH}/discriminator-{steps}.h5\")\n",
        "            print(f\"[*] save generator at {SAVE_GAN_PATH}/generator-{steps}.h5\")\n",
        "            print(f\"[*] save discriminator at {SAVE_DISC_PATH}/discriminator-{steps}.h5\")\n",
        "\n",
        "            download_saved_folder(saved_folder_path=\"saved\", download_location=\"local\")\n",
        "\n",
        "    generator.save(SAVE_GAN_PATH)\n",
        "    discriminator.save(SAVE_DISC_PATH)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP9SuiyEzmle"
      },
      "outputs": [],
      "source": [
        "# net_interp.py\n",
        "\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "# from modules.esrgan import rrdb_net\n",
        "\n",
        "\n",
        "SCALE = 4\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "ALPHA = 0.8\n",
        "\n",
        "CHECKPOINT_PATH_PSNR = \"./saved/checkpoints/psnr\"\n",
        "CHECKPOINT_PATH_ESRGAN = \"./saved/checkpoints/esrgan\"\n",
        "SAVE_MODEL_PATH = \"./saved/models/interp_esr\"\n",
        "Path(SAVE_MODEL_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def main():\n",
        "\n",
        "    # define network\n",
        "    model = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "\n",
        "    # load checkpoint\n",
        "    checkpoint_psnr = tf.train.Checkpoint(model=model)\n",
        "    if tf.train.latest_checkpoint(CHECKPOINT_PATH_PSNR):\n",
        "        status = checkpoint_psnr.restore(tf.train.latest_checkpoint(CHECKPOINT_PATH_PSNR))\n",
        "        status.expect_partial()\n",
        "        print(\"[*] load ckpt psnr from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH_PSNR)))\n",
        "    else:\n",
        "        print(\"[*] Cannot find ckpt psnr from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH_PSNR)))\n",
        "        exit()\n",
        "    vars_psnr = [v.numpy() for v in checkpoint_psnr.model.trainable_variables]\n",
        "\n",
        "    checkpoint_esrgan = tf.train.Checkpoint(model=model)\n",
        "    if tf.train.latest_checkpoint(CHECKPOINT_PATH_ESRGAN):\n",
        "        status = checkpoint_esrgan.restore(tf.train.latest_checkpoint(CHECKPOINT_PATH_ESRGAN))\n",
        "        status.expect_partial()\n",
        "        print(\"[*] load ckpt edsr from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH_ESRGAN)))\n",
        "    else:\n",
        "        print(\"[*] Cannot find ckpt edsr from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH_ESRGAN)))\n",
        "        exit()\n",
        "    vars_edsr = [v.numpy() for v in checkpoint_esrgan.model.trainable_variables]\n",
        "\n",
        "    # network interpolation\n",
        "    for i, var in enumerate(model.trainable_variables):\n",
        "        var.assign((1 - ALPHA) * vars_psnr[i] + ALPHA * vars_edsr[i])\n",
        "\n",
        "    model.save(SAVE_MODEL_PATH)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbbvgasNgDT-"
      },
      "outputs": [],
      "source": [
        "#demo.py (esrgan evaluate)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "# from modules.esrgan import rrdb_net\n",
        "# from modules.utils import read_image, scale_image_0_1_range, tensor2img\n",
        "# from modules.utils import save_image_grid\n",
        "\n",
        "\n",
        "\n",
        "SCALE = 4\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "\n",
        "FROM_CHECKPOINT = True\n",
        "#MODEL_PATH = \"./saved/models/psnr\"\n",
        "MODEL_PATH = \"./saved/models/esrgan\"\n",
        "#CHECKPOINT_PATH = \"./saved/checkpoints/psnr\"\n",
        "CHECKPOINT_PATH = \"./saved/checkpoints/esrgan\"\n",
        "\n",
        "IMG_DIR = \"./images/input\"  # Path to the directory containing LR images\n",
        "GT_DIR = \"./images/ground_truth\"  # Path to the directory containing ground truth HR images (optional)\n",
        "SAVE_DIR = \"./images/results\"  # Directory to save the upscaled images\n",
        "\n",
        "Path(SAVE_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def main():\n",
        "\n",
        "    model = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(model=model)\n",
        "\n",
        "    if tf.train.latest_checkpoint(CHECKPOINT_PATH) and FROM_CHECKPOINT:\n",
        "            status = checkpoint.restore(tf.train.latest_checkpoint(CHECKPOINT_PATH))\n",
        "            status.expect_partial()  # suppress warnings or else it spam\n",
        "            print(\"[*] load ckpt from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH)))\n",
        "    else:\n",
        "        if os.path.isfile(MODEL_PATH):\n",
        "            h5_model = load_model(MODEL_PATH, custom_objects={'tf': tf})\n",
        "            weights = h5_model.get_weights()\n",
        "            model.set_weights(weights)\n",
        "            print(\"[*] load model weights from {}.\".format(\n",
        "            MODEL_PATH))\n",
        "        else:\n",
        "            print(\"[*] Cannot find ckpt or h5 model file.\")\n",
        "            exit()\n",
        "\n",
        "    if os.path.isdir(IMG_DIR):  # Check if it's a directory\n",
        "        for img_path in glob.glob(os.path.join(IMG_DIR, \"*.png\")):  # Assuming PNG images\n",
        "            # Extract filename without extension\n",
        "            filename = os.path.splitext(os.path.basename(img_path))[0]\n",
        "\n",
        "             # Load LR image\n",
        "            lr_image = read_image(img_path)\n",
        "            lr_image = scale_image_0_1_range(lr_image)\n",
        "            lr_image = tf.expand_dims(lr_image, axis=0)\n",
        "\n",
        "            base_filename = filename[2:]\n",
        "\n",
        "            # Load ground truth HR image (if available)\n",
        "            hr_filename = f\"hr{base_filename}.png\"  # Add \"hr\" prefix and extension\n",
        "            hr_img_path = os.path.join(GT_DIR, hr_filename)\n",
        "            if os.path.exists(hr_img_path):\n",
        "                hr_image = read_image(hr_img_path)\n",
        "            else:\n",
        "                hr_image = None\n",
        "\n",
        "            # Generate HR image\n",
        "            generated_hr = model(lr_image)\n",
        "            generated_hr_image = tensor2img(generated_hr)\n",
        "            unscale_lr_image = tensor2img(lr_image)\n",
        "\n",
        "            # Calculate metrics (if ground truth is available)\n",
        "            if hr_image is not None:\n",
        "                psnr = calculate_psnr(hr_image, generated_hr_image)\n",
        "                ssim = calculate_ssim(hr_image, generated_hr_image)\n",
        "                print(f\"[***] Image: {filename}, PSNR: {psnr}, SSIM: {ssim}\")\n",
        "\n",
        "            # Save image grid with LR, generated HR, and optionally ground truth\n",
        "            save_path = os.path.join(SAVE_DIR, f\"{filename}_upscaled.png\")\n",
        "            save_image_grid(unscale_lr_image, generated_hr_image, hr_image, save_path=save_path)\n",
        "\n",
        "    else:\n",
        "        print(f\"[!] Invalid image directory: {IMG_DIR}\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IWMT3VRzwNn"
      },
      "outputs": [],
      "source": [
        "#test.py (interp_esr)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "# from modules.esrgan import rrdb_net\n",
        "# from modules.utils import create_lr_hr_pair, scale_image_0_1_range, tensor2img\n",
        "# from modules.utils import save_image_grid\n",
        "# from modules.metrics import calculate_psnr, calculate_ssim\n",
        "\n",
        "\n",
        "SCALE = 4\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "\n",
        "FROM_CHECKPOINT = False\n",
        "#MODEL_PATH = \"./saved/models/psnr\"\n",
        "# MODEL_PATH = \"./saved/models/esrgan\"\n",
        "MODEL_PATH = \"./saved/models/interp_esr\"\n",
        "#CHECKPOINT_PATH = \"./saved/checkpoints/psnr\"\n",
        "CHECKPOINT_PATH = \"./saved/checkpoints/esrgan\"\n",
        "\n",
        "IMG_DIR = \"./images/input\"  # Path to the directory containing LR images\n",
        "GT_DIR = \"./images/ground_truth\"  # Path to the directory containing ground truth HR images\n",
        "SAVE_DIR = \"./images/results\"  # Directory to save the upscaled images\n",
        "\n",
        "Path(SAVE_DIR).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def main():\n",
        "\n",
        "    model = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(model=model)\n",
        "    if tf.train.latest_checkpoint(CHECKPOINT_PATH) and FROM_CHECKPOINT:\n",
        "        checkpoint.restore(tf.train.latest_checkpoint(CHECKPOINT_PATH))\n",
        "        print(\"[*] load ckpt from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH)))\n",
        "    else:\n",
        "        if os.path.isfile(MODEL_PATH):\n",
        "            h5_model = load_model(MODEL_PATH, custom_objects={'tf': tf})\n",
        "            weights = h5_model.get_weights()\n",
        "            model.set_weights(weights)\n",
        "            print(\"[*] load model weights from {}.\".format(\n",
        "            MODEL_PATH))\n",
        "        else:\n",
        "            print(\"[*] Cannot find ckpt or h5 model file.\")\n",
        "            exit()\n",
        "\n",
        "    if os.path.isdir(IMG_DIR):  # Check if it's a directory\n",
        "        for img_path in glob.glob(os.path.join(IMG_DIR, \"*.png\")):  # Assuming PNG images\n",
        "            # Extract filename without extension\n",
        "            filename = os.path.splitext(os.path.basename(img_path))[0]\n",
        "\n",
        "            # Load LR image\n",
        "            lr_image = read_image(img_path)\n",
        "            lr_image = scale_image_0_1_range(lr_image)\n",
        "            lr_image = tf.expand_dims(lr_image, axis=0)\n",
        "\n",
        "            base_filename = filename[2:]\n",
        "\n",
        "            # Load ground truth HR image\n",
        "            hr_filename = f\"hr{base_filename}.png\"  # Add \"hr\" prefix and extension\n",
        "            hr_img_path = os.path.join(GT_DIR, hr_filename)\n",
        "            hr_image = read_image(hr_img_path)\n",
        "\n",
        "\n",
        "            # Generate HR image\n",
        "            generated_hr = model(lr_image)\n",
        "            generated_hr_image = tensor2img(generated_hr)\n",
        "            unscale_lr_image = tensor2img(lr_image)\n",
        "\n",
        "            # Calculate metrics\n",
        "            psnr = calculate_psnr(hr_image, generated_hr_image)\n",
        "            ssim = calculate_ssim(hr_image, generated_hr_image)\n",
        "            print(f\"[***] Image: {filename}, PSNR: {psnr}, SSIM: {ssim}\")\n",
        "\n",
        "            # Save image grid\n",
        "            save_path = os.path.join(SAVE_DIR, f\"{filename}_upscaled.png\")\n",
        "            save_image_grid(unscale_lr_image, generated_hr_image,  hr_image)\n",
        "\n",
        "    else:\n",
        "        print(f\"[!] Invalid image directories: {IMG_DIR}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxe8GnZAXOix"
      },
      "outputs": [],
      "source": [
        "# !pip install zipfile\n",
        "# import os\n",
        "# import zipfile\n",
        "# from google.colab import files\n",
        "\n",
        "# def zip_folder(folder_path, output_path):\n",
        "#     \"\"\"Zip the contents of an entire folder (with that folder included\n",
        "#     in the archive). Empty subfolders will be included in the archive\n",
        "#     as well.\n",
        "#     \"\"\"\n",
        "#     parent_folder = os.path.dirname(folder_path)\n",
        "#     # Retrieve the paths of the folder contents.\n",
        "#     contents = os.walk(folder_path)\n",
        "#     try:\n",
        "#         zip_file = zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED)\n",
        "#         for root, folders, files in contents:\n",
        "#             # Include all subfolders, including empty ones.\n",
        "#             for folder_name in folders:\n",
        "#                 absolute_path = os.path.join(root, folder_name)\n",
        "#                 relative_path = absolute_path.replace(parent_folder + '/', '')\n",
        "#                 print(\"Adding {} to archive.\".format(absolute_path))\n",
        "#                 zip_file.write(absolute_path, relative_path)\n",
        "#             for file_name in files:\n",
        "#                 absolute_path = os.path.join(root, file_name)\n",
        "#                 relative_path = absolute_path.replace(parent_folder + '/', '')\n",
        "#                 print(\"Adding {} to archive.\".format(absolute_path))\n",
        "#                 zip_file.write(absolute_path, relative_path)\n",
        "#         print(\"'{0}' created successfully.\".format(output_path))\n",
        "#     except IOError as message:\n",
        "#         print(message)\n",
        "#         sys.exit(1)\n",
        "#     except OSError as message:\n",
        "#         print(message)\n",
        "#         sys.exit(1)\n",
        "#     finally:\n",
        "#         zip_file.close()\n",
        "\n",
        "# zip_folder(\"saved\", \"saved.zip\")\n",
        "\n",
        "# files.download(\"saved.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIwmGBMy8dIt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2_jGTegXYy7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
