{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagaditya39/ESRGAN-ImageSR-Colab/blob/main/gan2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ujiPn8qYD3m",
        "outputId": "488180e4-c747-4dd3-ee4d-40baf7dba2ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.45.0-py2.py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Collecting appdirs>=1.4.3 (from wandb)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: appdirs, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.45.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HflivmcCJQhl"
      },
      "outputs": [],
      "source": [
        "#utils.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "def read_image(img_path):\n",
        "    base=os.path.basename(img_path)\n",
        "    ext = os.path.splitext(base)[1]\n",
        "    assert ext in ['.png', '.jpg', '.jpeg', '.JPEG']\n",
        "    image = tf.io.read_file(img_path)\n",
        "    if ext == '.png':\n",
        "        image = tf.image.decode_png(image, channels=3)\n",
        "    else:\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "    return image\n",
        "\n",
        "# def create_lr_hr_pair(img_path, scale):\n",
        "#     image = read_image(img_path)\n",
        "#     lr_height, lr_width = image.shape[0] // scale, image.shape[1] // scale\n",
        "#     hr_height, hr_width = lr_height * scale, lr_width * scale\n",
        "#     hr_image = image[:hr_height, :hr_width, :]\n",
        "#     lr_shape = [lr_height, lr_width]\n",
        "#     lr_image = tf.image.resize(hr_image, lr_shape, method=tf.image.ResizeMethod.BICUBIC)\n",
        "\n",
        "#     return lr_image, hr_image\n",
        "\n",
        "def scale_image_0_1_range(image):\n",
        "    image = image / 255\n",
        "    red_max = tf.reduce_max(image, axis=None)\n",
        "    red_min = tf.reduce_min(image, axis=None)\n",
        "    if red_max > 1 or red_min < 0:\n",
        "        image = tf.clip_by_value(\n",
        "            image, 0, 1, name=None\n",
        "        )\n",
        "    return image\n",
        "\n",
        "\n",
        "# def unscale_image_0_255_range(image):\n",
        "#     image = image * 255\n",
        "#     red_max = tf.reduce_max(image, axis=None)\n",
        "#     red_min = tf.reduce_min(image, axis=None)\n",
        "#     if red_max > 255 or red_min < 0:\n",
        "#         image = tf.clip_by_value(\n",
        "#             image, 0, 255, name=None\n",
        "#         )\n",
        "#     return image\n",
        "\n",
        "def tensor2img(tensor):\n",
        "    return (np.squeeze(tensor.numpy()).clip(0, 1) * 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "def save_image_grid(lr, hr, ref=None, save_path=None):\n",
        "    lr_title = \"lr: {}\".format(lr.shape)\n",
        "    hr_title = \"hr: {}\".format(hr.shape)\n",
        "    images = [lr, hr]\n",
        "    titles = [lr_title, hr_title]\n",
        "    if ref is not None:\n",
        "        ref_title = \"ref: {}\".format(ref.shape)\n",
        "        images += [ref]\n",
        "        titles += [ref_title]\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
        "    else:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "\n",
        "    for i, (img, title) in enumerate(zip(images, titles)):\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(title, fontsize = 20)\n",
        "        axes[i].axis('off')\n",
        "    # fig.savefig(save_path, bbox_inches = 'tight', pad_inches = 0.25)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def load_models_for_epoch(base_path, epoch_num, is_gan=False):\n",
        "    # \"\"\"Loads model(s) for a specific epoch.\"\"\"\n",
        "    model_path = f\"{base_path}_epoch_{epoch_num}.h5\"\n",
        "    if not Path(model_path).exists():\n",
        "        raise ValueError(f\"Model for epoch {epoch_num} not found at {model_path}\")\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    if is_gan:  # Load discriminator as well for GAN training\n",
        "        disc_path = f\"{base_path.replace('esrgan', 'disc_gan')}_epoch_{epoch_num}.h5\"\n",
        "        discriminator = tf.keras.models.load_model(disc_path)\n",
        "        return model, discriminator\n",
        "    return model\n",
        "\n",
        "def get_available_epochs(base_path):\n",
        "    # \"\"\"Returns a list of available epoch numbers from saved model filenames.\"\"\"\n",
        "    model_dir = Path(base_path).parent\n",
        "    pattern = re.compile(r\"_epoch_(\\d+)\\.h5\")\n",
        "    epochs = []\n",
        "    for filename in model_dir.glob(\"*.h5\"):\n",
        "        match = pattern.search(filename.name)\n",
        "        if match:\n",
        "            epochs.append(int(match.group(1)))\n",
        "    return sorted(epochs)\n",
        "\n",
        "\n",
        "def download_saved_folder(saved_folder_path, download_location=\"local\", drive_folder_id=None):\n",
        "    # \"\"\"Downloads the saved folder to the specified location.\"\"\"\n",
        "\n",
        "    if download_location == \"local\":\n",
        "        # Download to local machine (assuming you are using Colab)\n",
        "        shutil.make_archive(saved_folder_path, 'zip', saved_folder_path)\n",
        "        zipped_filename = saved_folder_path + \".zip\"\n",
        "        files.download(zipped_filename)\n",
        "\n",
        "    elif download_location == \"drive\" and drive_folder_id:\n",
        "        # Download to Google Drive (Colab only)\n",
        "        drive.mount('/content/gdrive')  # Mount Google Drive\n",
        "        destination_path = \"/content/gdrive/My Drive/\" + drive_folder_id\n",
        "        shutil.make_archive(saved_folder_path, 'zip', saved_folder_path)\n",
        "        zipped_filename = saved_folder_path + \".zip\"\n",
        "        shutil.move(zipped_filename, destination_path)\n",
        "        print(f\"Saved folder uploaded to Google Drive folder ID: {drive_folder_id}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"[!] Invalid download location or missing Drive folder ID.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "quRvGoGgJJQI"
      },
      "outputs": [],
      "source": [
        "#metrics.py\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def calculate_psnr(img1, img2):\n",
        "    #img1 and img2 have range [0, 255]\n",
        "    #psnr = 20 * np.log10(255.0 / np.sqrt(np.mean((img1 - img2)**2)))\n",
        "    return tf.image.psnr(img1, img2, max_val=255)\n",
        "\n",
        "def calculate_ssim(hr, generated_hr):\n",
        "    #hr and generated_hr have range [0, 255]\n",
        "    return tf.image.ssim(hr, generated_hr, max_val=255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "WsyXyCB6I-v_",
        "outputId": "3683e704-a897-4e4c-f3af-23108f527b0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c07934a7ebfc>:61: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels(labels)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# lr_scheduler.py\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def MultiStepLR(initial_learning_rate, lr_steps, lr_rate, name='MultiStepLR'):\n",
        "    # \"\"\"Multi-steps learning rate scheduler.\"\"\"\n",
        "    lr_steps_value = [initial_learning_rate]\n",
        "    for _ in range(len(lr_steps)):\n",
        "        lr_steps_value.append(lr_steps_value[-1] * lr_rate)\n",
        "    return tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "        boundaries=lr_steps, values=lr_steps_value)\n",
        "\n",
        "\n",
        "# def CosineAnnealingLR_Restart(initial_learning_rate, t_period, lr_min):\n",
        "#     # \"\"\"Cosine annealing learning rate scheduler with restart.\"\"\"\n",
        "#     return tf.keras.experimental.CosineDecayRestarts(\n",
        "#         initial_learning_rate=initial_learning_rate,\n",
        "#         first_decay_steps=t_period, t_mul=1.0, m_mul=1.0,\n",
        "#         alpha=lr_min / initial_learning_rate)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # pretrain PSNR lr scheduler\n",
        "    lr_scheduler = MultiStepLR(2e-4, [2000, 4000, 6000, 8000], 0.5)\n",
        "\n",
        "    # ESRGAN lr scheduler\n",
        "    # lr_scheduler = MultiStepLR(1e-4, [50000, 100000, 200000, 300000], 0.5)\n",
        "\n",
        "    # Cosine Annealing lr scheduler\n",
        "    # lr_scheduler = CosineAnnealingLR_Restart(2e-4, 250000, 1e-7)\n",
        "\n",
        "    ##############################\n",
        "    # Draw figure\n",
        "    ##############################\n",
        "\n",
        "    N_iter = 10000\n",
        "    step_list = list(range(0, N_iter, 1000))\n",
        "    lr_list = []\n",
        "    for i in step_list:\n",
        "        current_lr = lr_scheduler(i).numpy()\n",
        "        lr_list.append(current_lr)\n",
        "\n",
        "    import matplotlib as mpl\n",
        "    from matplotlib import pyplot as plt\n",
        "    import matplotlib.ticker as mtick\n",
        "    mpl.style.use('default')\n",
        "    import seaborn\n",
        "    seaborn.set(style='whitegrid')\n",
        "    seaborn.set_context('paper')\n",
        "\n",
        "    plt.figure(1)\n",
        "    plt.subplot(111)\n",
        "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0, 0))\n",
        "    plt.title('Title', fontsize=16, color='k')\n",
        "    plt.plot(step_list, lr_list, linewidth=1.5, label='learning rate scheme')\n",
        "    legend = plt.legend(loc='upper right', shadow=False)\n",
        "    ax = plt.gca()\n",
        "    labels = ax.get_xticks().tolist()\n",
        "    for k, v in enumerate(labels):\n",
        "        labels[k] = str(int(v / 1000)) + 'K'\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.1e'))\n",
        "\n",
        "    ax.set_ylabel('Learning rate')\n",
        "    ax.set_xlabel('Iteration')\n",
        "    fig = plt.gcf()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PkuI8-mnHqVP"
      },
      "outputs": [],
      "source": [
        "# losses.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input, VGG19\n",
        "\n",
        "def get_pixel_loss(criterion='l1'):\n",
        "    \"\"\"pixel loss\"\"\"\n",
        "    if criterion == 'l1':\n",
        "        return tf.keras.losses.MeanAbsoluteError()\n",
        "    elif criterion == 'l2':\n",
        "        return tf.keras.losses.MeanSquaredError()\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Loss type {} is not recognized.'.format(criterion))\n",
        "\n",
        "def get_content_loss(criterion='l1', output_layer=54, before_act=True):\n",
        "    \"\"\"content loss\"\"\"\n",
        "    if criterion == 'l1':\n",
        "        loss_func = tf.keras.losses.MeanAbsoluteError()\n",
        "    elif criterion == 'l2':\n",
        "        loss_func = tf.keras.losses.MeanSquaredError()\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Loss type {} is not recognized.'.format(criterion))\n",
        "    vgg = VGG19(input_shape=(None, None, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "    if output_layer == 22:  # Low level feature\n",
        "        pick_layer = 5\n",
        "    elif output_layer == 54:  # Hight level feature\n",
        "        pick_layer = 20\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'VGG output layer {} is not recognized.'.format(criterion))\n",
        "\n",
        "    if before_act:\n",
        "        vgg.layers[pick_layer].activation = None\n",
        "\n",
        "    fea_extrator = tf.keras.Model(vgg.input, vgg.layers[pick_layer].output)\n",
        "    fea_extrator.trainable = False\n",
        "\n",
        "    @tf.function\n",
        "    def content_loss(real_hr, fake_hr):\n",
        "        # the input scale range is [0, 1] (vgg is [0, 255]).\n",
        "        # 12.75 is rescale factor for vgg featuremaps.\n",
        "        preprocess_fake_hr = preprocess_input(fake_hr * 255.) / 12.75\n",
        "        preprocess_real_hr = preprocess_input(real_hr * 255.) / 12.75\n",
        "        fake_hr_features = fea_extrator(preprocess_fake_hr)\n",
        "        real_hr_features = fea_extrator(preprocess_real_hr)\n",
        "\n",
        "        return loss_func(real_hr_features, fake_hr_features)\n",
        "\n",
        "    return content_loss\n",
        "\n",
        "def get_discriminator_loss(gan_type='ragan'):\n",
        "    \"\"\"discriminator loss\"\"\"\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    sigma = tf.sigmoid\n",
        "\n",
        "    def discriminator_loss_ragan(real_discriminator_logits, fake_discriminator_logits):\n",
        "        real_logits = sigma(real_discriminator_logits - tf.reduce_mean(fake_discriminator_logits))\n",
        "        fake_logits = sigma(fake_discriminator_logits - tf.reduce_mean(real_discriminator_logits))\n",
        "        return 0.5 * (\n",
        "            cross_entropy(tf.ones_like(real_logits), real_logits) +\n",
        "            cross_entropy(tf.zeros_like(fake_logits), fake_logits))\n",
        "\n",
        "    def discriminator_loss(real_discriminator_logits, fake_discriminator_logits):\n",
        "        real_loss = cross_entropy(tf.ones_like(real_discriminator_logits), sigma(real_discriminator_logits))\n",
        "        fake_loss = cross_entropy(tf.zeros_like(fake_discriminator_logits), sigma(fake_discriminator_logits))\n",
        "        return real_loss + fake_loss\n",
        "\n",
        "    if gan_type == 'ragan':\n",
        "        return discriminator_loss_ragan\n",
        "    elif gan_type == 'gan':\n",
        "        return discriminator_loss\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Discriminator loss type {} is not recognized.'.format(gan_type))\n",
        "\n",
        "def get_generator_loss(gan_type='ragan'):\n",
        "    \"\"\"generator loss\"\"\"\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    sigma = tf.sigmoid\n",
        "\n",
        "    def generator_loss_ragan(real_discriminator_logits, fake_discriminator_logits):\n",
        "        real_logits = sigma(real_discriminator_logits - tf.reduce_mean(fake_discriminator_logits))\n",
        "        fake_logits = sigma(fake_discriminator_logits - tf.reduce_mean(real_discriminator_logits))\n",
        "        return 0.5 * (\n",
        "            cross_entropy(tf.ones_like(fake_logits), fake_logits) +\n",
        "            cross_entropy(tf.zeros_like(real_logits), real_logits))\n",
        "\n",
        "    def generator_loss(real_discriminator_logits, fake_discriminator_logits):\n",
        "        return cross_entropy(tf.ones_like(fake_discriminator_logits), sigma(fake_discriminator_logits))\n",
        "\n",
        "    if gan_type == 'ragan':\n",
        "        return generator_loss_ragan\n",
        "    elif gan_type == 'gan':\n",
        "        return generator_loss\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Generator loss type {} is not recognized.'.format(gan_type))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UzYZSzR6HeQz"
      },
      "outputs": [],
      "source": [
        "# dataset.py\n",
        "\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "DATA_PATH = \"/content/HR\"\n",
        "\n",
        "def scale_input_image(img):\n",
        "    #img/ 255.\n",
        "    return tf.image.convert_image_dtype(img, dtype=tf.float32)\n",
        "\n",
        "# def unscale_output_image(img):\n",
        "#     #img * 255\n",
        "#     return tf.image.convert_image_dtype(img, dtype=tf.uint8, saturate=True)\n",
        "\n",
        "def random_crop_and_flip(img, random_crop_size):\n",
        "    assert img.shape[2] == 3\n",
        "    height, width = img.shape[0], img.shape[1]\n",
        "    dy, dx = random_crop_size\n",
        "    x = np.random.randint(0, width - dx + 1)\n",
        "    y = np.random.randint(0, height - dy + 1)\n",
        "    image = img[y:(y+dy), x:(x+dx), :]\n",
        "    flip_case = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
        "    if(tf.equal(flip_case, 0)):\n",
        "        image = tf.image.flip_left_right(image)\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_image(image_path, hr_height, hr_width, crop_per_image, ext):\n",
        "    assert ext in ['.png', '.jpg', '.jpeg', '.JPEG']\n",
        "    image = tf.io.read_file(image_path)\n",
        "    if ext == '.png':\n",
        "        image = tf.image.decode_png(image, channels=3)\n",
        "    else:\n",
        "        image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "    image = scale_input_image(image)\n",
        "    cropped_images = [ random_crop_and_flip(image, (hr_height, hr_width)) for _ in range(crop_per_image)]\n",
        "\n",
        "    return cropped_images\n",
        "\n",
        "\n",
        "\n",
        "def load_dataset(hr_height, hr_width, scale, crop_per_image=20, ext='.png'):\n",
        "    image_paths = []\n",
        "    for root, _, files in os.walk(DATA_PATH):\n",
        "        for file in files:\n",
        "            if f'{ext}' in file:\n",
        "                image_paths.append(os.path.join(root, file))\n",
        "\n",
        "    random.shuffle(image_paths)\n",
        "    images = []\n",
        "    for img_path in image_paths:\n",
        "        images += load_and_preprocess_image(img_path, hr_height, hr_width, crop_per_image, ext)\n",
        "\n",
        "    random.shuffle(images)\n",
        "    hr_images = []\n",
        "    lr_images = []\n",
        "    for img in images:\n",
        "        hr_image = img\n",
        "        lr_shape = [int(hr_image.shape[0]/scale), int(hr_image.shape[1]/scale)]\n",
        "        lr_image = tf.image.resize(hr_image, lr_shape, method=tf.image.ResizeMethod.BICUBIC)\n",
        "        #lr_image = lr_image / 255\n",
        "        lr_image = tf.clip_by_value(\n",
        "        lr_image, 0, 1, name=None\n",
        "        )\n",
        "        hr_images.append(hr_image)\n",
        "        lr_images.append(lr_image)\n",
        "\n",
        "    lr_dataset = tf.data.Dataset.from_tensor_slices(lr_images)\n",
        "    hr_dataset = tf.data.Dataset.from_tensor_slices(hr_images)\n",
        "\n",
        "    dataset = tf.data.Dataset.zip((lr_dataset, hr_dataset))\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yuxTzvTsHPrO"
      },
      "outputs": [],
      "source": [
        "# esrgan.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, PReLU, Dropout, Dense\n",
        "from tensorflow.keras.layers import BatchNormalization, Concatenate, Lambda, Add\n",
        "\n",
        "\n",
        "def residual_dense_block(input, filters):\n",
        "    x1 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(input)\n",
        "    x1 = LeakyReLU(0.2)(x1)\n",
        "    x1 = Concatenate()([input, x1])\n",
        "\n",
        "    x2 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(x1)\n",
        "    x2 = LeakyReLU(0.2)(x2)\n",
        "    x2 = Concatenate()([input, x1, x2])\n",
        "\n",
        "    x3 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(x2)\n",
        "    x3 = LeakyReLU(0.2)(x3)\n",
        "    x3 = Concatenate()([input, x1, x2, x3])\n",
        "\n",
        "    x4 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(x3)\n",
        "    x4 = LeakyReLU(0.2)(x4)\n",
        "    x4 = Concatenate()([input, x1, x2, x3, x4])\n",
        "\n",
        "    x5 = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(x4)\n",
        "    x5 = Lambda(lambda x: x * 0.2)(x5)\n",
        "    x = Add()([x5, input])\n",
        "\n",
        "    return x\n",
        "\n",
        "def rrdb(input, filters):\n",
        "    x = residual_dense_block(input, filters)\n",
        "    x = residual_dense_block(x, filters)\n",
        "    x = residual_dense_block(x, filters)\n",
        "    x = Lambda(lambda x: x * 0.2)(x)\n",
        "    out = Add()([x, input])\n",
        "    return out\n",
        "\n",
        "def sub_pixel_conv2d(scale_factor=2, **kwargs):\n",
        "    return Lambda(lambda  x: tf.nn.depth_to_space(x, scale_factor), **kwargs)\n",
        "\n",
        "def upsample(input_tensor, filters, scale_factor=2):\n",
        "    x = Conv2D(filters=filters*4, kernel_size=3, strides=1, padding='same')(input_tensor)\n",
        "    x = sub_pixel_conv2d(scale_factor=scale_factor)(x)\n",
        "    x = PReLU(shared_axes=[1,2])(x)\n",
        "    return x\n",
        "\n",
        "def rrdb_net(input_shape=(None, None, 3), filters=64, scale_factor=4, name='RRDB_model'):\n",
        "    lr_image = Input(shape=input_shape, name='input')\n",
        "\n",
        "    #Pre-residual\n",
        "    x_start = Conv2D(filters, kernel_size=3, strides=1, padding='same')(lr_image)\n",
        "    x_start = LeakyReLU(0.2)(x_start)\n",
        "\n",
        "    #Residual block\n",
        "    x = rrdb(x_start, filters)\n",
        "\n",
        "    #Post Residual block\n",
        "    x = Conv2D(filters,  kernel_size=3, strides=1, padding='same')(x)\n",
        "    x = Lambda(lambda x: x * 0.2)(x)\n",
        "    x = Add()([x, x_start])\n",
        "\n",
        "    #Upsampling\n",
        "    x = upsample(x, filters, scale_factor)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size=3, strides=1, padding='same')(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    out = Conv2D(filters=3, kernel_size=3, strides=1, padding='same')(x)\n",
        "\n",
        "    return Model(inputs=lr_image, outputs=out, name=name)\n",
        "\n",
        "def conv2d_block(input, filters, strides=1, bn=True):\n",
        "    x = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(input)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    if bn:\n",
        "        x = BatchNormalization(momentum=0.8)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def discriminator_net(input_shape=(None, None, 3), filters=64, name='Discriminator'):\n",
        "    img = Input(shape=input_shape)\n",
        "\n",
        "    x = conv2d_block(img, filters, bn=False)\n",
        "    x = conv2d_block(x, filters, strides=2)\n",
        "    x = conv2d_block(x, filters*2)\n",
        "    x = conv2d_block(x, filters*2, strides=2)\n",
        "    x = conv2d_block(x, filters*4)\n",
        "    x = conv2d_block(x, filters*4, strides=2)\n",
        "    x = conv2d_block(x, filters*8)\n",
        "    x = conv2d_block(x, filters*8, strides=2)\n",
        "    x = Dense(filters*16)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(1)(x)\n",
        "\n",
        "    return Model(inputs=img, outputs=x, name=name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "PXO_hLvkJw3E",
        "outputId": "6fc5385d-9004-47d3-ef73-97fc5d3dc8bd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Private W&B dashboard, no account required\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'HR_HEIGHT' referenced before assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2d0f8d44495e>\u001b[0m in \u001b[0;36m<cell line: 213>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-2d0f8d44495e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHR_HEIGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHR_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mleng\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'HR_HEIGHT' referenced before assignment"
          ]
        }
      ],
      "source": [
        "#train_psnr.py\n",
        "\n",
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "# from modules.esrgan import rrdb_net\n",
        "# from modules.lr_scheduler import MultiStepLR\n",
        "# from modules.data import load_dataset\n",
        "# from modules.losses import get_pixel_loss\n",
        "\n",
        "HAS_WANDB_ACCOUNT = False\n",
        "PROJECT = 'esrgan-tf2'\n",
        "import wandb\n",
        "if not HAS_WANDB_ACCOUNT:\n",
        "    wandb.login(anonymous='allow')\n",
        "else:\n",
        "    wandb.login()\n",
        "\n",
        "INITIAL_LR = 2e-4\n",
        "LR_RATE = 0.5\n",
        "LR_STEPS = [2000, 4000, 6000, 8000]\n",
        "ADAM_BETA1_G = 0.9\n",
        "ADAM_BETA2_G = 0.99\n",
        "W_PIXEL = 1.0\n",
        "PIXEL_CRITERION = 'l1'\n",
        "\n",
        "HR_HEIGHT = 128\n",
        "HR_WIDTH = 128\n",
        "SCALE = 4\n",
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 10240\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "\n",
        "NUM_ITER = 10000\n",
        "SAVE_STEPS = 500\n",
        "\n",
        "\n",
        "CHECK_POINT_PATH =  \"./saved/checkpoints/psnr\"\n",
        "Path(CHECK_POINT_PATH).mkdir(parents=True, exist_ok=True)\n",
        "SAVE_MODEL_PATH = \"./saved/models/psnr.h5\"\n",
        "Path(SAVE_MODEL_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def main():\n",
        "\n",
        "    num_epochs = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    dataset = load_dataset(HR_HEIGHT, HR_WIDTH, SCALE)\n",
        "    leng= len(dataset)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    model = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "    learning_rate = MultiStepLR(INITIAL_LR, LR_STEPS, LR_RATE)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate,\n",
        "                                        beta_1= ADAM_BETA1_G,\n",
        "                                        beta_2= ADAM_BETA2_G\n",
        "                                        )\n",
        "    pixel_loss = get_pixel_loss(PIXEL_CRITERION)\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(step=tf.Variable(0, name='step'),\n",
        "                                     optimizer=optimizer,\n",
        "                                     model=model,\n",
        "                                     learning_rate=learning_rate)\n",
        "    manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
        "                                         directory=CHECK_POINT_PATH,\n",
        "                                         max_to_keep=3)\n",
        "    if manager.latest_checkpoint:\n",
        "        checkpoint.restore(manager.latest_checkpoint)\n",
        "        print('[*] load ckpt from {} at step {}.'.format(\n",
        "            manager.latest_checkpoint, checkpoint.step.numpy()))\n",
        "\n",
        "      # Load configurations from JSON\n",
        "        config_load_path = f\"configs_step_{int(checkpoint.step.numpy())}.json\"\n",
        "        with open(config_load_path, 'r') as f:\n",
        "            configs = json.load(f)\n",
        "\n",
        "        # Update learning rate and other configurations if needed\n",
        "        global HR_HEIGHT, HR_WIDTH, SCALE, BATCH_SIZE, BUFFER_SIZE\n",
        "        INITIAL_LR = configs[\"INITIAL_LR\"]\n",
        "        LR_RATE = configs[\"LR_RATE\"]\n",
        "        LR_STEPS = configs[\"LR_STEPS\"]\n",
        "        ADAM_BETA1_G: configs[\"ADAM_BETA1_G\"]\n",
        "        ADAM_BETA2_G: configs[\"ADAM_BETA2_G\"]\n",
        "        W_PIXEL: configs[\"W_PIXEL\"]\n",
        "        PIXEL_CRITERION: configs[\"PIXEL_CRITERION\"]\n",
        "        HR_HEIGHT: configs[\"HR_HEIGHT\"]\n",
        "        HR_WIDTH: configs[\"HR_WIDTH\"]\n",
        "        SCALE: configs[\"SCALE\"]\n",
        "        BATCH_SIZE: configs[\"BATCH_SIZE\"]\n",
        "        BUFFER_SIZE: configs[\"BUFFER_SIZE\"]\n",
        "\n",
        "        # Recreate learning rate scheduler (if necessary)\n",
        "        learning_rate = MultiStepLR(INITIAL_LR, LR_STEPS, LR_RATE)\n",
        "        optimizer.learning_rate = learning_rate  # Update optimizer's learning rate\n",
        "\n",
        "    else:\n",
        "        print(\"[*] Training from scratch.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(lr, hr):\n",
        "        with tf.GradientTape() as tape:\n",
        "            generated_hr = model(lr, training=True)\n",
        "            loss = W_PIXEL * pixel_loss(hr, generated_hr)\n",
        "\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    wandb_run_id = \"psnr-training\" #@param {type:\"string\"}\n",
        "    if HAS_WANDB_ACCOUNT:\n",
        "        wandb.init(entity='ilab', project=PROJECT, id=wandb_run_id)\n",
        "    else:\n",
        "        wandb.init(id=wandb_run_id)\n",
        "\n",
        "    remain_steps = max(NUM_ITER - checkpoint.step.numpy(), 0)\n",
        "    pbar = tqdm(total=remain_steps, ncols=50)\n",
        "\n",
        "    available_epochs = get_available_epochs(SAVE_MODEL_PATH)\n",
        "    if available_epochs:\n",
        "        print(\"Available epochs:\", available_epochs)\n",
        "        resume_epoch = int(input(\"Enter epoch to resume from (or 0 to start fresh): \"))\n",
        "    else:\n",
        "        resume_epoch = 0  # No saved models found, start fresh\n",
        "\n",
        "    if resume_epoch > 0:\n",
        "        # Load model for the specified epoch\n",
        "        model = load_models_for_epoch(SAVE_MODEL_PATH, resume_epoch)\n",
        "        # Update the starting step based on the chosen epoch\n",
        "        checkpoint.step.assign(resume_epoch * leng)\n",
        "        print(f\"[*] Resuming training from epoch {resume_epoch}\")\n",
        "\n",
        "\n",
        "    for lr, hr in dataset.take(remain_steps):\n",
        "        checkpoint.step.assign_add(1)\n",
        "        steps = checkpoint.step.numpy()\n",
        "        loss = train_step(lr, hr)\n",
        "        learning_rate = optimizer.lr.numpy()  # Get the learning rate value\n",
        "        wandb.log({\"steps\": steps, \"loss\": loss, \"learning_rate\": learning_rate})\n",
        "        pbar.set_description(\"loss={:.4f}, lr={:.1e}\".format(loss, learning_rate))\n",
        "        pbar.update()\n",
        "        # sys.stdout.flush()\n",
        "\n",
        "        if steps % SAVE_STEPS == 0:\n",
        "            manager.save()\n",
        "            print(\"\\n[*] save ckpt file at {}\".format(manager.latest_checkpoint))\n",
        "\n",
        "            configs = {\n",
        "            \"INITIAL_LR\": INITIAL_LR,\n",
        "            \"LR_RATE\": LR_RATE,\n",
        "            \"LR_STEPS\": LR_STEPS,\n",
        "            \"ADAM_BETA1_G\": ADAM_BETA1_G,\n",
        "            \"ADAM_BETA2_G\": ADAM_BETA2_G,\n",
        "            \"W_PIXEL\": W_PIXEL,\n",
        "            \"PIXEL_CRITERION\": PIXEL_CRITERION,\n",
        "            \"HR_HEIGHT\": HR_HEIGHT,\n",
        "            \"HR_WIDTH\": HR_WIDTH,\n",
        "            \"SCALE\": SCALE,\n",
        "            \"BATCH_SIZE\": BATCH_SIZE,\n",
        "            \"BUFFER_SIZE\": BUFFER_SIZE,\n",
        "            }\n",
        "\n",
        "\n",
        "          # Save configurations as JSON\n",
        "            config_save_path = f\"configs_step_{steps}.json\"\n",
        "            with open(config_save_path, 'w') as f:\n",
        "                json.dump(configs, f, indent=4)\n",
        "            print(f\"[*] Saved configurations as {config_save_path}\")\n",
        "\n",
        "        num_epochs +=1\n",
        "        if num_epochs % 1000 == 0:\n",
        "          model_save_path = f\"{SAVE_MODEL_PATH}_epoch_{num_epochs}.h5\"\n",
        "          model.save(model_save_path)\n",
        "          print(f\"\\n[*] Saved model as {model_save_path}\")\n",
        "\n",
        "          # Save configurations as a JSON file\n",
        "          config_save_path = f\"configs_epoch_{num_epochs}.json\"\n",
        "          with open(config_save_path, 'w') as f:\n",
        "              json.dump(configs, f, indent=4)\n",
        "          print(f\"[*] Saved configurations as {config_save_path}\")\n",
        "\n",
        "\n",
        "          download_saved_folder(saved_folder_path=\"saved\", download_location=\"local\")\n",
        "          # files.download(\"saved.zip\")\n",
        "\n",
        "    model.save(SAVE_MODEL_PATH)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGW4Vmv_Jz69"
      },
      "outputs": [],
      "source": [
        "# train_esrgan.py\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "# from modules.esrgan import rrdb_net, discriminator_net\n",
        "# from modules.lr_scheduler import MultiStepLR\n",
        "# from modules.data import load_dataset\n",
        "# from modules.losses import get_pixel_loss, get_content_loss\n",
        "# from modules.losses import get_discriminator_loss, get_generator_loss\n",
        "\n",
        "HAS_WANDB_ACCOUNT = False\n",
        "PROJECT = 'esrgan-tf2'\n",
        "import wandb\n",
        "if not HAS_WANDB_ACCOUNT:\n",
        "    wandb.login(anonymous='allow')\n",
        "else:\n",
        "    wandb.login()\n",
        "\n",
        "INITIAL_LR_G = 1e-4\n",
        "INITIAL_LR_D = 1e-4\n",
        "LR_RATE = 0.5\n",
        "LR_STEPS = [5000, 10000, 20000, 30000]\n",
        "ADAM_BETA1_G = 0.9\n",
        "ADAM_BETA2_G = 0.99\n",
        "ADAM_BETA1_D = 0.9\n",
        "ADAM_BETA2_D = 0.99\n",
        "\n",
        "PIXEL_CRITERION = 'l1'\n",
        "FEATURE_CRITERION = 'l2'\n",
        "GAN_TYPE = 'ragan'\n",
        "WEIGHT_PIXEL = 1e-2\n",
        "WEIGHT_FEATURE = 1.0\n",
        "WEIGHT_GAN = 5e-3\n",
        "\n",
        "HR_HEIGHT = 128\n",
        "HR_WIDTH = 128\n",
        "SCALE = 4\n",
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 10240\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "\n",
        "NUM_ITER = 40000\n",
        "SAVE_STEPS =  500\n",
        "\n",
        "PRETRAIN_PATH =  \"./saved/checkpoints/psnr\"\n",
        "CHECK_POINT_PATH =  \"./saved/checkpoints/esrgan\"\n",
        "Path(CHECK_POINT_PATH).mkdir(parents=True, exist_ok=True)\n",
        "SAVE_GAN_PATH = \"./saved/models/esrgan.h5\"\n",
        "Path(SAVE_GAN_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "SAVE_DISC_PATH = \"./saved/models/disc_gan.h5\"\n",
        "Path(SAVE_DISC_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    num_epochs = 0\n",
        "\n",
        "    dataset = load_dataset(HR_HEIGHT, HR_WIDTH, SCALE)\n",
        "    leng = len(dataset)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    generator = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "    discriminator = discriminator_net(input_shape=INPUT_SHAPE)\n",
        "\n",
        "    learning_rate_G = MultiStepLR(INITIAL_LR_G, LR_STEPS, LR_RATE)\n",
        "    learning_rate_D = MultiStepLR(INITIAL_LR_D, LR_STEPS, LR_RATE)\n",
        "    optimizer_G = tf.keras.optimizers.Adam(learning_rate= learning_rate_G,\n",
        "                                        beta_1= ADAM_BETA1_G,\n",
        "                                        beta_2= ADAM_BETA2_G\n",
        "                                        )\n",
        "    optimizer_D = tf.keras.optimizers.Adam(learning_rate= learning_rate_D,\n",
        "                                        beta_1= ADAM_BETA1_D,\n",
        "                                        beta_2= ADAM_BETA2_D\n",
        "                                        )\n",
        "\n",
        "    pixel_loss = get_pixel_loss(PIXEL_CRITERION)\n",
        "    feature_loss = get_content_loss(FEATURE_CRITERION)\n",
        "    generator_loss = get_generator_loss(GAN_TYPE)\n",
        "    discriminator_loss = get_discriminator_loss(GAN_TYPE)\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(step=tf.Variable(0, name='step'),\n",
        "                                     optimizer_G=optimizer_G,\n",
        "                                     optimizer_D=optimizer_D,\n",
        "                                     model=generator,\n",
        "                                     discriminator=discriminator)\n",
        "    manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
        "                                         directory=CHECK_POINT_PATH,\n",
        "                                         max_to_keep=3)\n",
        "    if manager.latest_checkpoint:\n",
        "        checkpoint.restore(manager.latest_checkpoint)\n",
        "        print('[*] load ckpt from {} at step {}.'.format(\n",
        "            manager.latest_checkpoint, checkpoint.step.numpy()))\n",
        "    else:\n",
        "        if tf.train.latest_checkpoint(PRETRAIN_PATH):\n",
        "            checkpoint.restore(tf.train.latest_checkpoint(PRETRAIN_PATH))\n",
        "            checkpoint.step.assign(0)\n",
        "            print(\"[*] training from pretrain model {}.\".format(\n",
        "                    PRETRAIN_PATH ))\n",
        "        else:\n",
        "            print(\"[*] cannot find pretrain model {}.\".format(\n",
        "                PRETRAIN_PATH))\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(lr, hr):\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            generated_hr = generator(lr, training=True)\n",
        "            real_logits = discriminator(hr, training=True)\n",
        "            fake_logits = discriminator(generated_hr, training=True)\n",
        "            losses_G = {}\n",
        "            losses_D = {}\n",
        "            losses_G['pixel'] = WEIGHT_PIXEL * pixel_loss(hr, generated_hr)\n",
        "            losses_G['feature'] = WEIGHT_FEATURE * feature_loss(hr, generated_hr)\n",
        "            losses_G['gan'] = WEIGHT_GAN * generator_loss(real_logits, fake_logits)\n",
        "            losses_D['disc'] = discriminator_loss(real_logits, fake_logits)\n",
        "            total_loss_G = tf.add_n([l for l in losses_G.values()])\n",
        "            total_loss_D = tf.add_n([l for l in losses_D.values()])\n",
        "\n",
        "\n",
        "        grads_G = tape.gradient(\n",
        "            total_loss_G, generator.trainable_variables)\n",
        "        grads_D = tape.gradient(\n",
        "            total_loss_D, discriminator.trainable_variables)\n",
        "        optimizer_G.apply_gradients(\n",
        "            zip(grads_G, generator.trainable_variables))\n",
        "        optimizer_D.apply_gradients(\n",
        "            zip(grads_D, discriminator.trainable_variables))\n",
        "\n",
        "        return total_loss_G, total_loss_D, losses_G, losses_D\n",
        "\n",
        "\n",
        "    wandb_run_id = \"esrgan-training\" #@param {type:\"string\"}\n",
        "    if HAS_WANDB_ACCOUNT:\n",
        "        wandb.init(entity='ilab', project=PROJECT, id=wandb_run_id)\n",
        "    else:\n",
        "        wandb.init(id=wandb_run_id)\n",
        "    remain_steps = max(NUM_ITER - checkpoint.step.numpy(), 0)\n",
        "    pbar = tqdm(total=remain_steps, ncols=50)\n",
        "\n",
        "# Get available epochs and prompt user for epoch to resume from\n",
        "    available_epochs = get_available_epochs(SAVE_GAN_PATH)\n",
        "    if available_epochs:\n",
        "        print(\"Available epochs:\", available_epochs)\n",
        "        resume_epoch = int(input(\"Enter epoch to resume from (or 0 to start fresh): \"))\n",
        "    else:\n",
        "        resume_epoch = 0  # No saved models found, start fresh\n",
        "\n",
        "    if resume_epoch > 0:\n",
        "        # Load models for the specified epoch\n",
        "        generator, discriminator = load_models_for_epoch(SAVE_GAN_PATH, resume_epoch, is_gan=True)\n",
        "        # Update the starting step based on the chosen epoch\n",
        "        checkpoint.step.assign(resume_epoch * leng)\n",
        "        print(f\"[*] Resuming training from epoch {resume_epoch}\")\n",
        "\n",
        "\n",
        "    for lr, hr in dataset.take(remain_steps):\n",
        "        checkpoint.step.assign_add(1)\n",
        "        steps = checkpoint.step.numpy()\n",
        "        total_loss_G, total_loss_D, losses_G, losses_D = train_step(lr, hr)\n",
        "        learning_rate_G = optimizer_G.lr.numpy()\n",
        "        learning_rate_D = optimizer_D.lr.numpy()\n",
        "        wandb.log({**{\"steps\": steps},**losses_G, **losses_D,\n",
        "                    **{\"total_loss_G\": total_loss_G.numpy()},\n",
        "                    **{\"learning_rate_G\": learning_rate_G,\n",
        "                    \"learning_rate_D\": learning_rate_D}})\n",
        "\n",
        "        pbar.set_description(\"loss_G={:.4f}, loss_D={:.4f}, lr_G={:.1e}, lr_D={:.1e}\".format(\n",
        "            total_loss_G.numpy(), total_loss_D.numpy(),\n",
        "            learning_rate_G, learning_rate_D))\n",
        "        pbar.update()\n",
        "        if steps % SAVE_STEPS == 0:\n",
        "            manager.save()\n",
        "            print(\"\\n[*] save ckpt file at {}\".format(manager.latest_checkpoint))\n",
        "\n",
        "        num_epochs += 1\n",
        "        if num_epochs % 1000 == 0:\n",
        "            generator_save_path = f\"{SAVE_GAN_PATH}_epoch_{num_epochs}.h5\"\n",
        "            discriminator_save_path = f\"{SAVE_DISC_PATH}_epoch_{num_epochs}.h5\"\n",
        "            generator.save(generator_save_path)\n",
        "            discriminator.save(discriminator_save_path)\n",
        "            print(f\"\\n[*] Saved models at epoch {num_epochs}\")\n",
        "            download_saved_folder(saved_folder_path=\"saved\", download_location=\"local\")\n",
        "\n",
        "    generator.save(SAVE_GAN_PATH)\n",
        "    discriminator.save(SAVE_DISC_PATH)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP9SuiyEzmle"
      },
      "outputs": [],
      "source": [
        "# net_interp.py\n",
        "\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "# from modules.esrgan import rrdb_net\n",
        "\n",
        "\n",
        "SCALE = 4\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "ALPHA = 0.8\n",
        "\n",
        "CHECKPOINT_PATH_PSNR = \"./saved/checkpoints/psnr\"\n",
        "CHECKPOINT_PATH_ESRGAN = \"./saved/checkpoints/esrgan\"\n",
        "SAVE_MODEL_PATH = \"./saved/models/interp_esr.h5\"\n",
        "Path(SAVE_MODEL_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def main():\n",
        "\n",
        "    # define network\n",
        "    model = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "\n",
        "    # load checkpoint\n",
        "    checkpoint_psnr = tf.train.Checkpoint(model=model)\n",
        "    if tf.train.latest_checkpoint(CHECKPOINT_PATH_PSNR):\n",
        "        status = checkpoint_psnr.restore(tf.train.latest_checkpoint(CHECKPOINT_PATH_PSNR))\n",
        "        status.expect_partial()\n",
        "        print(\"[*] load ckpt psnr from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH_PSNR)))\n",
        "    else:\n",
        "        print(\"[*] Cannot find ckpt psnr from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH_PSNR)))\n",
        "        exit()\n",
        "    vars_psnr = [v.numpy() for v in checkpoint_psnr.model.trainable_variables]\n",
        "\n",
        "    checkpoint_esrgan = tf.train.Checkpoint(model=model)\n",
        "    if tf.train.latest_checkpoint(CHECKPOINT_PATH_ESRGAN):\n",
        "        status = checkpoint_esrgan.restore(tf.train.latest_checkpoint(CHECKPOINT_PATH_ESRGAN))\n",
        "        status.expect_partial()\n",
        "        print(\"[*] load ckpt edsr from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH_ESRGAN)))\n",
        "    else:\n",
        "        print(\"[*] Cannot find ckpt edsr from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH_ESRGAN)))\n",
        "        exit()\n",
        "    vars_edsr = [v.numpy() for v in checkpoint_esrgan.model.trainable_variables]\n",
        "\n",
        "    # network interpolation\n",
        "    for i, var in enumerate(model.trainable_variables):\n",
        "        var.assign((1 - ALPHA) * vars_psnr[i] + ALPHA * vars_edsr[i])\n",
        "\n",
        "    model.save(SAVE_MODEL_PATH)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbbvgasNgDT-"
      },
      "outputs": [],
      "source": [
        "#demo.py (esrgan evaluate)\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "# from modules.esrgan import rrdb_net\n",
        "# from modules.utils import read_image, scale_image_0_1_range, tensor2img\n",
        "# from modules.utils import save_image_grid\n",
        "\n",
        "\n",
        "\n",
        "SCALE = 4\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "\n",
        "FROM_CHECKPOINT = True\n",
        "#MODEL_PATH = \"./saved/models/psnr.h5\"\n",
        "MODEL_PATH = \"./saved/models/esrgan.h5\"\n",
        "#CHECKPOINT_PATH = \"./saved/checkpoints/psnr\"\n",
        "CHECKPOINT_PATH = \"./saved/checkpoints/esrgan\"\n",
        "\n",
        "IMG_DIR = \"./images/input\"  # Path to the directory containing LR images\n",
        "GT_DIR = \"./images/ground_truth\"  # Path to the directory containing ground truth HR images (optional)\n",
        "SAVE_DIR = \"./images/results\"  # Directory to save the upscaled images\n",
        "\n",
        "Path(SAVE_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def main():\n",
        "\n",
        "    model = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(model=model)\n",
        "\n",
        "    if tf.train.latest_checkpoint(CHECKPOINT_PATH) and FROM_CHECKPOINT:\n",
        "            status = checkpoint.restore(tf.train.latest_checkpoint(CHECKPOINT_PATH))\n",
        "            status.expect_partial()  # Add this line to suppress warnings\n",
        "            print(\"[*] load ckpt from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH)))\n",
        "    else:\n",
        "        if os.path.isfile(MODEL_PATH):\n",
        "            h5_model = load_model(MODEL_PATH, custom_objects={'tf': tf})\n",
        "            weights = h5_model.get_weights()\n",
        "            model.set_weights(weights)\n",
        "            print(\"[*] load model weights from {}.\".format(\n",
        "            MODEL_PATH))\n",
        "        else:\n",
        "            print(\"[*] Cannot find ckpt or h5 model file.\")\n",
        "            exit()\n",
        "\n",
        "    if os.path.isdir(IMG_DIR):  # Check if it's a directory\n",
        "        for img_path in glob.glob(os.path.join(IMG_DIR, \"*.png\")):  # Assuming PNG images\n",
        "            # Extract filename without extension\n",
        "            filename = os.path.splitext(os.path.basename(img_path))[0]\n",
        "\n",
        "             # Load LR image\n",
        "            lr_image = read_image(img_path)\n",
        "            lr_image = scale_image_0_1_range(lr_image)\n",
        "            lr_image = tf.expand_dims(lr_image, axis=0)\n",
        "\n",
        "            base_filename = filename[2:]\n",
        "\n",
        "            # Load ground truth HR image (if available)\n",
        "            hr_filename = f\"hr{base_filename}.png\"  # Add \"hr\" prefix and extension\n",
        "            hr_img_path = os.path.join(GT_DIR, hr_filename)\n",
        "            if os.path.exists(hr_img_path):\n",
        "                hr_image = read_image(hr_img_path)\n",
        "            else:\n",
        "                hr_image = None\n",
        "\n",
        "            # Generate HR image\n",
        "            generated_hr = model(lr_image)\n",
        "            generated_hr_image = tensor2img(generated_hr)\n",
        "            unscale_lr_image = tensor2img(lr_image)\n",
        "\n",
        "            # Calculate metrics (if ground truth is available)\n",
        "            if hr_image is not None:\n",
        "                psnr = calculate_psnr(hr_image, generated_hr_image)\n",
        "                ssim = calculate_ssim(hr_image, generated_hr_image)\n",
        "                print(f\"[***] Image: {filename}, PSNR: {psnr}, SSIM: {ssim}\")\n",
        "\n",
        "            # Save image grid with LR, generated HR, and optionally ground truth\n",
        "            save_path = os.path.join(SAVE_DIR, f\"{filename}_upscaled.png\")\n",
        "            save_image_grid(unscale_lr_image, generated_hr_image, hr_image, save_path=save_path)\n",
        "\n",
        "    else:\n",
        "        print(f\"[!] Invalid image directory: {IMG_DIR}\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IWMT3VRzwNn"
      },
      "outputs": [],
      "source": [
        "#test.py (interp_esr)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "# from modules.esrgan import rrdb_net\n",
        "# from modules.utils import create_lr_hr_pair, scale_image_0_1_range, tensor2img\n",
        "# from modules.utils import save_image_grid\n",
        "# from modules.metrics import calculate_psnr, calculate_ssim\n",
        "\n",
        "\n",
        "SCALE = 4\n",
        "INPUT_SHAPE=(None, None, 3)\n",
        "\n",
        "FROM_CHECKPOINT = False\n",
        "#MODEL_PATH = \"./saved/models/psnr.h5\"\n",
        "# MODEL_PATH = \"./saved/models/esrgan.h5\"\n",
        "MODEL_PATH = \"./saved/models/interp_esr.h5\"\n",
        "#CHECKPOINT_PATH = \"./saved/checkpoints/psnr\"\n",
        "CHECKPOINT_PATH = \"./saved/checkpoints/esrgan\"\n",
        "\n",
        "IMG_DIR = \"./images/input\"  # Path to the directory containing LR images\n",
        "GT_DIR = \"./images/ground_truth\"  # Path to the directory containing ground truth HR images\n",
        "SAVE_DIR = \"./images/results\"  # Directory to save the upscaled images\n",
        "\n",
        "Path(SAVE_DIR).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def main():\n",
        "\n",
        "    model = rrdb_net(input_shape=INPUT_SHAPE,scale_factor=SCALE)\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(model=model)\n",
        "    if tf.train.latest_checkpoint(CHECKPOINT_PATH) and FROM_CHECKPOINT:\n",
        "        checkpoint.restore(tf.train.latest_checkpoint(CHECKPOINT_PATH))\n",
        "        print(\"[*] load ckpt from {}.\".format(\n",
        "            tf.train.latest_checkpoint(CHECKPOINT_PATH)))\n",
        "    else:\n",
        "        if os.path.isfile(MODEL_PATH):\n",
        "            h5_model = load_model(MODEL_PATH, custom_objects={'tf': tf})\n",
        "            weights = h5_model.get_weights()\n",
        "            model.set_weights(weights)\n",
        "            print(\"[*] load model weights from {}.\".format(\n",
        "            MODEL_PATH))\n",
        "        else:\n",
        "            print(\"[*] Cannot find ckpt or h5 model file.\")\n",
        "            exit()\n",
        "\n",
        "    if os.path.isdir(IMG_DIR):  # Check if it's a directory\n",
        "        for img_path in glob.glob(os.path.join(IMG_DIR, \"*.png\")):  # Assuming PNG images\n",
        "            # Extract filename without extension\n",
        "            filename = os.path.splitext(os.path.basename(img_path))[0]\n",
        "\n",
        "            # Load LR image\n",
        "            lr_image = read_image(img_path)\n",
        "            lr_image = scale_image_0_1_range(lr_image)\n",
        "            lr_image = tf.expand_dims(lr_image, axis=0)\n",
        "\n",
        "            base_filename = filename[2:]\n",
        "\n",
        "            # Load ground truth HR image\n",
        "            hr_filename = f\"hr{base_filename}.png\"  # Add \"hr\" prefix and extension\n",
        "            hr_img_path = os.path.join(GT_DIR, hr_filename)\n",
        "            hr_image = read_image(hr_img_path)\n",
        "\n",
        "\n",
        "            # Generate HR image\n",
        "            generated_hr = model(lr_image)\n",
        "            generated_hr_image = tensor2img(generated_hr)\n",
        "            unscale_lr_image = tensor2img(lr_image)\n",
        "\n",
        "            # Calculate metrics\n",
        "            psnr = calculate_psnr(hr_image, generated_hr_image)\n",
        "            ssim = calculate_ssim(hr_image, generated_hr_image)\n",
        "            print(f\"[***] Image: {filename}, PSNR: {psnr}, SSIM: {ssim}\")\n",
        "\n",
        "            # Save image grid\n",
        "            save_path = os.path.join(SAVE_DIR, f\"{filename}_upscaled.png\")\n",
        "            save_image_grid(unscale_lr_image, generated_hr_image,  hr_image)\n",
        "\n",
        "    else:\n",
        "        print(f\"[!] Invalid image directories: {IMG_DIR}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxe8GnZAXOix"
      },
      "outputs": [],
      "source": [
        "# !pip install zipfile\n",
        "# import os\n",
        "# import zipfile\n",
        "# from google.colab import files\n",
        "\n",
        "# def zip_folder(folder_path, output_path):\n",
        "#     \"\"\"Zip the contents of an entire folder (with that folder included\n",
        "#     in the archive). Empty subfolders will be included in the archive\n",
        "#     as well.\n",
        "#     \"\"\"\n",
        "#     parent_folder = os.path.dirname(folder_path)\n",
        "#     # Retrieve the paths of the folder contents.\n",
        "#     contents = os.walk(folder_path)\n",
        "#     try:\n",
        "#         zip_file = zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED)\n",
        "#         for root, folders, files in contents:\n",
        "#             # Include all subfolders, including empty ones.\n",
        "#             for folder_name in folders:\n",
        "#                 absolute_path = os.path.join(root, folder_name)\n",
        "#                 relative_path = absolute_path.replace(parent_folder + '/', '')\n",
        "#                 print(\"Adding {} to archive.\".format(absolute_path))\n",
        "#                 zip_file.write(absolute_path, relative_path)\n",
        "#             for file_name in files:\n",
        "#                 absolute_path = os.path.join(root, file_name)\n",
        "#                 relative_path = absolute_path.replace(parent_folder + '/', '')\n",
        "#                 print(\"Adding {} to archive.\".format(absolute_path))\n",
        "#                 zip_file.write(absolute_path, relative_path)\n",
        "#         print(\"'{0}' created successfully.\".format(output_path))\n",
        "#     except IOError as message:\n",
        "#         print(message)\n",
        "#         sys.exit(1)\n",
        "#     except OSError as message:\n",
        "#         print(message)\n",
        "#         sys.exit(1)\n",
        "#     finally:\n",
        "#         zip_file.close()\n",
        "\n",
        "# zip_folder(\"saved\", \"saved.zip\")\n",
        "\n",
        "# files.download(\"saved.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIwmGBMy8dIt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2_jGTegXYy7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}